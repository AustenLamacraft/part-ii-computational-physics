[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Part II Computational Physics",
    "section": "",
    "text": "Preface\nThere are the materials for the Part II Physics course Computational Physics, taught in Lent Term 2023 at the University of Cambridge.\nThanks to David Buscher for the earlier version\nTo learn more about Quarto books visit https://quarto.org/docs/books.\nTopics\nTrebstâ€™s applications: ODE, Monte Carlo simulation, data analysis, QM scattering, Linear algebra, Neural Nets\nRefer to French book for more examples.\nPCA as application of linear algebra and quantum mechanics\nRandom matrix theory Linear regression\nLinear programming.\nGarth Wells has nice material about algos and complexity\nHashing\nNumpy. Basics of ufuncs and vectorization 2. Loading and saving data 3. Data types. Floating point. Machine precision 4. Implementing algos using vectorization (ODEs) 5. Numerical techniques: ODS, optimization 6. Computational complexity 1. Complexity of simple algos. Division algorithm as binary search (Ryan Oâ€™Donnell tweet) 2. Euler algorithm 3. Complexity of linear algebra operations. Matrix-matrix and matrix-vector. Solving equations can be easier if matrices have structure see e.g.Â https://martin-thoma.com/solving-equations-of-upper-triangular-matrices/. This is forward / backward substitution. 4. Strategies: divide and conquer (examples: exponentiation, Strassen, FFT) 5. Monte Carlo and probabilistic methods 6. Dynamic programming 7. Version control. GitHub. Pull requests. Code review. Look up some code in scipy\nA note about the format of the notes. Each chapter should be thought of as a notebook, so youâ€™ll only see import numpy as np once in each chapter, for example."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1Â  Introduction",
    "section": "",
    "text": "Not a course on numerical analysis but computational physics\nComputation is important for experimental physicists for analysing data. For theoretical physics, computation is used to deal with the awkward fact that physical theories are generally not tractable. You canâ€™t solve Maxwellâ€™s equations, the Navierâ€“Stokes equation, or SchrÃ¶dingerâ€™s equation in any but the simplest situations.\nTo be blunt, this means that your knowledge of physics, while very nice, is of no use whatsoever unless you can write a program to solve more complicated problems. Sorry.\nItâ€™s important to understand that this need to apply our mathematical descriptions of nature in more general settings was the principal driving force behind the invention of the computer.\nMore than this,\nChurch Turing hypothesis\nTuringâ€™s cathedral\nBooks\nPart IB notes are very good\nGarth Wells\nhttps://github.com/CambridgeEngineering/PartIA-Computing-Michaelmas/\nRougier\nhttps://www.labri.fr/perso/nrougier/from-python-to-numpy/ https://github.com/rougier/scientific-visualization-book"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7Â  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. â€œLiterate Programming.â€ Comput.\nJ. 27 (2): 97â€“111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "setup.html#setting-up-an-environment",
    "href": "setup.html#setting-up-an-environment",
    "title": "2Â  Getting Going",
    "section": "2.1 Setting up an environment",
    "text": "2.1 Setting up an environment\nYou will need\n\nprint(\"Hello world!\")\n1 + 2\n\nHello world!\n\n\n3\n\n\nPython version. Make sure itâ€™s Python3\nIPython code highlighting, help and so on.\nRunning a python program"
  },
  {
    "objectID": "setup.html#notebooks",
    "href": "setup.html#notebooks",
    "title": "2Â  Getting Going",
    "section": "2.8 Notebooks",
    "text": "2.8 Notebooks\nWhile software developers write .py files, modules and packages, scientists and others doing more exploratory work tend to favour a Notebook format that mixes code, text, and plots. The dominant option is the Jupyter notebook, which comes with the Anaconda distribution and can be started from the command line with jupyter notebook (or from the Anaconda Navigator application). This will open the notebook as a web page in your browser, where it can be edited and saved. The default extension is .ipynb.\nJupyter notebooks can actually run code in different languages (the processes running a particular language is called a kernel), but the default process is IPython with all the benefits described above.\nThe text cells can be formatted using Markdown and also support \\(\\LaTeX\\) equations, which is pretty handy for us.\nGoogle has their own cloud version of the Jupyter notebook called Colab. You can try it out for free, though you have to pay for significant compute. The â€œnext generationâ€ of the Jupyter notebook is called JupyterLab and can be started with jupyter lab. Notebook files can be opened in either Jupyter Lab or Jupyter Notebook"
  },
  {
    "objectID": "setup.html#plotting",
    "href": "setup.html#plotting",
    "title": "2Â  Getting Going",
    "section": "2.9 Plotting",
    "text": "2.9 Plotting\nWithout introducing numpy explicitly at this stageâ€¦\n\\(\\alpha = \\beta\\)"
  },
  {
    "objectID": "numpy.html",
    "href": "numpy.html",
    "title": "4Â  Introduction to NumPy",
    "section": "",
    "text": "NumPy is the key building block of the Python scientific ecosystem\nUfuncs"
  },
  {
    "objectID": "setup.html#the-python-language",
    "href": "setup.html#the-python-language",
    "title": "2Â  Getting Going",
    "section": "2.10 The Python Language",
    "text": "2.10 The Python Language\nObjects\ntwo language problem\nGotchas"
  },
  {
    "objectID": "setup.html#your-coding-environment",
    "href": "setup.html#your-coding-environment",
    "title": "2Â  Getting Going",
    "section": "2.2 Your coding environment",
    "text": "2.2 Your coding environment\nTo run Python code on your computer you will need to have installed the Python language. I recommend the Anaconda distribution as it comes with all the parts of the toolkit weâ€™ll need such as Jupyter notebooks and the major libraries NumPy and SciPy.\nTry running python at the command line. You should get something like\nPython 3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ] :: Anaconda, Inc. on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \nYou should confirm that you are using Python 3 (the command python3 will also work and guarantee this if you happen to have Python 2 as the default). The prompt >>> indicates that you have started the Python interactive shell or REPL and are good to go:\n\nprint(\"Hello world!\")\n1 + 2\n\nHello world!\n\n\n3\n\n\nTo leave and return to the command line, you can run quit() or exit()."
  },
  {
    "objectID": "setup.html#editors",
    "href": "setup.html#editors",
    "title": "2Â  Getting Going",
    "section": "2.7 Editors",
    "text": "2.7 Editors\nModern editors come with a huge number of tools that make writing code much easier, and you would be crazy not to take advantage of them. These range from the visual cues provided by syntax highlighting â€“ which weâ€™ve already met â€“ to code completion, parameter information and documentation popups as you type. These go under the general heading IntelliSense. The latest hotness is GitHub Copilot, which uses AI to make code suggestions. In my view, these are all part of a continuum of productivity enhancements that enable people to write better code faster. Use them (wisely).\nI use Visual Studio Code."
  },
  {
    "objectID": "setup.html#installing-libraries",
    "href": "setup.html#installing-libraries",
    "title": "2Â  Getting Going",
    "section": "2.6 Installing libraries",
    "text": "2.6 Installing libraries\n99% of the code 1 you run will have been written by somebody else in the form of a library (a collection of modules or packages). Package installation is handled by the command line utilities pip or conda, the latter being the package manager for the Anaconda distribution. If you have NumPy and SciPy installed you wonâ€™t need to worry about this too much in this course."
  },
  {
    "objectID": "setup.html#running-a-python-program",
    "href": "setup.html#running-a-python-program",
    "title": "2Â  Getting Going",
    "section": "2.4 Running a Python program",
    "text": "2.4 Running a Python program\nPython code in a file with a .py extension can be run from the command line with python hello_world.py or python -m hello_world. In the latter case the -m option tells the interpreter to look for a module called hello_world. More on modules below.\nFrom the IPython shell you can instead use run hello_world.py or just run hello_world.\nTODO: These magics are normally documented with a %. When is it necessary?"
  },
  {
    "objectID": "setup.html#importing-code",
    "href": "setup.html#importing-code",
    "title": "2Â  Getting Going",
    "section": "2.5 Importing code",
    "text": "2.5 Importing code\nA Python module is just a file containing definition and statements. Breaking long code into modules is good practice for writing clear and reusable software. Users may not want to delve into the details of some function you have written in order to be able to us it, and separating the corresponding code into a separate file is a hygienic way to handle this.\nThus if I make the file hello_world.py containing the function:\n\ndef hello():\n    print(\"Hello world!\")\n\nI can run this function by first importing the module:\n\nimport hello_world\nhello_world.hello()\n\nHello world!\n\n\nNotice that the function hello is accessed from the hello_world namespace. This is to avoid any confusion that may arise if more that one imported module has a function of the same name. If you are confident thatâ€™s not an issue and want more concise code you can do this:\n\nfrom hello_world import hello\nhello()\n\nHello world!\n\n\nor even:\n\nfrom hello_world import *\nhello()\n\nHello world!\n\n\nThe issue with the latter is that it may introduce a whole bunch of names that may interfere with things you already defined.\nA collection of modules in a folder is called a package. You can import a package in the same way and access all the modules using the same . notation i.e.Â package.module1, package.module2, etc..\nSince explicit namespaces are preferred to avoid ambiguity itâ€™s common to introduce shorthand names for the package or module you are importing, hence the ubiquitous:\n\nimport numpy as np\nnp.arange(10)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n(You can call it what you like, of course!)\nFor details about where the interpreter looks to find modules you try to import are in the documentation."
  },
  {
    "objectID": "setup.html#finding-your-way",
    "href": "setup.html#finding-your-way",
    "title": "2Â  Getting Going",
    "section": "2.1 Finding your way",
    "text": "2.1 Finding your way\nEveryone finds their own workflow for coding, depending on their preferred language, editor, how they run their code, and so on. The aim of the sections below is to give a roundup of some popular tools in the Python ecosystem."
  },
  {
    "objectID": "setup.html#codespaces",
    "href": "setup.html#codespaces",
    "title": "2Â  Getting Going",
    "section": "2.9 Codespaces",
    "text": "2.9 Codespaces\nNew from Githubâ€¦"
  },
  {
    "objectID": "setup.html#ipython",
    "href": "setup.html#ipython",
    "title": "2Â  Getting Going",
    "section": "2.3 IPython",
    "text": "2.3 IPython\nIf you ran the above command from within python you may have noticed that the nice colour scheme that you see above was absent. This is called syntax highlighting and provides a visual guide to the syntax of the language.\nIPython is an interactive shell that provides syntax highlighting and much more. If you have installed IPython (it comes with Anaconda) you can start it from the command line with ipython.\nAmong the most helpful features of IPython are:\n\nTab completion: hit tab to autocomplete. This is particularly useful for viewing all properties or methods of an object: \nTyping ?word or word? prints detailed information about an object (?? provides additional detail).\nCertain magic commands prefixed by % that provide certain additional functionality. For example, %timeit finds the executation time of a single line statement, which is useful when profiling the performance of code:\n\n\n%timeit L = [n ** 2 for n in range(1000)]\n\n227 Âµs Â± 3.97 Âµs per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n\n\n%timeit automatically runs several times to give some statistics on the execution time. For multiple lines you can use the %%timeit magic.\nYou can find much more exploring the documentation."
  },
  {
    "objectID": "numbers.html",
    "href": "numbers.html",
    "title": "5Â  Floating point and all that",
    "section": "",
    "text": "Include RNGs here?\nSince physics is all about numbers we had better develop some understanding of how computers represent numbers, and what limitations this representations has.\nAs a motivating example\n\n0.1  + 0.2 == 0.3\n\nFalse"
  },
  {
    "objectID": "numpy.html#plotting",
    "href": "numpy.html#plotting",
    "title": "5Â  Introduction to NumPy and friends",
    "section": "5.4 Plotting",
    "text": "5.4 Plotting\nAnimation"
  },
  {
    "objectID": "numpy.html#dealing-with-data",
    "href": "numpy.html#dealing-with-data",
    "title": "5Â  Introduction to NumPy and friends",
    "section": "5.5 Dealing with data",
    "text": "5.5 Dealing with data\nSaving etcâ€¦."
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "3Â  The Python Language",
    "section": "",
    "text": "Extensive intro in Part IB\nObjects\ntwo language problem\nGotchas\nMutable and immutable\nPython pass by reference\nhttps://docs.python-guide.org/writing/gotchas/"
  },
  {
    "objectID": "numpy.html#arrays",
    "href": "numpy.html#arrays",
    "title": "4Â  NumPy and friends",
    "section": "4.2 Arrays",
    "text": "4.2 Arrays\nThe fundamental object in NumPy is the Array, which you can think of as a multidimensional version of a list. Letâ€™s start with two dimensions to demonstrate:\n\nimport numpy as np\nmy_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\n\ntype(my_array)\n\nnumpy.ndarray\n\n\nArrays can be indexed, similar to lists\n\nprint(my_array[0], my_array[1], my_array[3][1])\n\n[1 2 3] [4 5 6] 11\n\n\nbut â€“ different from a ordinary list of lists â€“ the last one can be much more pleasantly achieved with the syntax\n\nmy_array[3,1]\n\n11\n\n\nWe also have a generalization of the slice syntax\n\nmy_array[1:, 1:]\n\narray([[ 5,  6],\n       [ 8,  9],\n       [11, 12]])\n\n\nSlicing can be mixed with integer indexing\n\nmy_array[1:, 1]\n\narray([ 5,  8, 11])\n\n\nNumPy offers all sorts of fancy indexing options for slicing and dicing your data: see the documentation for details.\nA fundamental property of an array is its shape:\n\n# [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\nmy_array.shape\n\n(4, 3)\n\n\nThe way to read off the shape of an array is as follows. To begin with you encounter a number of [ corresponding to the rank of the array (two in the above example). You then scan over a number of entries that give the rightmost (innermost) dimension in the shape tuple before closing ] (3 here). After a number of 1D arrays [...] equal to the next innermost dimension (4 here), we have another closing ], and so on.\nItâ€™s definitely something that will take a bit of time getting used to!\nNotice that slicing does not change the rank of the array\n\nmy_array[1:, 1:].shape\n\n(3, 2)\n\n\nbut integer indexing does\n\nmy_array[1:, 1].shape\n\n(3,)\n\n\nNumPy has lots of methods to create arrays with a given shape and populated in different ways:\n\na = np.zeros((2,2))\nprint(a)\n\nb = np.ones((2,2))\nprint(b)\n\nc = np.full((2,2), 5)\nprint(c)\n\nd = np.random.random((2,2)) # random numbers uniformly in [0.0, 1.0)\nprint(d)\n\n[[0. 0.]\n [0. 0.]]\n[[1. 1.]\n [1. 1.]]\n[[5 5]\n [5 5]]\n[[0.46469028 0.98971998]\n [0.9271342  0.90003656]]\n\n\nThere are also lots of methods to change the shape of arrays, for example\n\nnumpy.reshape to change the shape of an array.\nnumpy.expand_dims to insert new axes of length one.\nnumpy.squeeze (the opposite) to remove new axes of length one.\n\nA NumPy array has a dtype property that gives the datatype. If the array was created from data, this will be inferred\n\nmy_array.dtype\n\ndtype('int64')\n\n\nFunctions that construct arrays also have an optional argument to specify the datatype\n\nmy_float_array = np.array([1,2,3], dtype=np.float64)\nmy_float_array.dtype\n\ndtype('float64')"
  },
  {
    "objectID": "numpy.html#objects-in-python",
    "href": "numpy.html#objects-in-python",
    "title": "5Â  Introduction to NumPy and friends",
    "section": "5.1 Objects in Python",
    "text": "5.1 Objects in Python\nEverything in Python is an object. For example [1,2,3] is a list:\n\ntype([1,2,3])\n\nlist\n\n\n\ndir([1,2,3])\n\n['__add__',\n '__class__',\n '__class_getitem__',\n '__contains__',\n '__delattr__',\n '__delitem__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rmul__',\n '__setattr__',\n '__setitem__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\ndunder"
  },
  {
    "objectID": "numpy.html#preamble-objects-in-python",
    "href": "numpy.html#preamble-objects-in-python",
    "title": "4Â  NumPy and friends",
    "section": "4.1 Preamble: objects in Python",
    "text": "4.1 Preamble: objects in Python\nEverything in Python is an object. For example [1,2,3] is a list:\n\nmy_list = [1, 2, 3]\ntype(my_list)\n\nlist\n\n\nYou can think of an object as a container for properties and methods, the latter being functions associated with the object. Properties and methods are accessed with the . syntax. For example, lists have the append method, which adds an element to the end of the list:\n\nmy_list.append(\"boop\")\nmy_list\n\n[1, 2, 3, 'boop']\n\n\nWith IPython you can see all the available methods by hitting tab:\n\n\n\n\n\n\n\nDunder methods\n\n\n\n\n\nYou can list all of an objects properties and methods using dir:\n\ndir(my_list)\n\n['__add__',\n '__class__',\n '__class_getitem__',\n '__contains__',\n '__delattr__',\n '__delitem__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rmul__',\n '__setattr__',\n '__setitem__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\nNotice that lots of these are methods have a name sandwiched between double underscores and for this reason are called dunder methods (or magic methods, or just special methods). This is to indicate that they are not to be used by you, but by the Python interpreter to implement certain standard functions that apply to many different classes of objects. For instance, when you write len(my_list) to find the length of my_list Python is actually calling the dunder method my_list.__len__ which does the job of actually finding the length.\n\nmy_list.__len__()\n\n4\n\n\nIn this way the same function (len in this case) can operate on many different objects, an example of what is called polymorphism in object oriented programming."
  },
  {
    "objectID": "numpy.html#mathematical-operations-with-arrays",
    "href": "numpy.html#mathematical-operations-with-arrays",
    "title": "4Â  NumPy and friends",
    "section": "4.3 Mathematical operations with arrays",
    "text": "4.3 Mathematical operations with arrays\nNow here comes the payoff. On lists, multiplication by an integer concatentates multiple copies\n\n2 * [1, 2, 3]\n\n[1, 2, 3, 1, 2, 3]\n\n\nwhich is sometimes useful. But in numerical applications what we really want is this\n\n2 * np.array([1, 2, 3])\n\narray([2, 4, 6])\n\n\nThis illustrates a general feature of NumPy that all mathematical operations are performed elementwise on arrays!\n\nprint(np.array([1, 2, 3]) + np.array([4, 5, 6]))\nprint(np.array([1, 2, 3])**2)\nprint(np.sqrt(np.array([1, 2, 3])))\n\n[5 7 9]\n[1 4 9]\n[1.         1.41421356 1.73205081]\n\n\nThis avoids the need to write nested loops to perform some operation on each element of some multidimensional data. Of course, the loops are still there, itâ€™s just that NumPy handles them in highly optimized C rather than Python. Code which operates in this way â€“ rather than with explicit loops â€“ is often described as vectorized, and in NumPy-speak vectorized functions are called ufuncs, short for universal functions (you can write your own if you need to). As a basic principle you should never use a Python loop to access your data in NumPy code. Loops may appear at a high level in stepping through time steps in a simulation, for example.\n\n4.3.1 Broadcasting\nVectorization is even more versatile than the above examples might suggest. Broadcasting is a powerful protocol that allows us to combine arrays of different shapes. Thus we can add a number to an array\n\nnp.array([1, 2, 3]) + 2.3\n\narray([3.3, 4.3, 5.3])\n\n\nMore generally, elementwise operations can be performed on two arrays of the same rank if in each dimension the sizes either match or one array has size 1.\n\n# These have shape (2, 3) and (1, 3)\nnp.array([[1, 2, 3], [4, 5, 6]]) + np.array([[4, 3, 2]])\n\narray([[5, 5, 5],\n       [8, 8, 8]])\n\n\nIn fact, we can simplify this last example\n\n# These have shape (2, 3) and (3,)\nnp.array([[1, 2, 3], [4, 5, 6]]) + np.array([4, 3, 2])\n\narray([[5, 5, 5],\n       [8, 8, 8]])\n\n\nBroadcasting two arrays follows these rules:\n\nIf the arrays do not have the same rank, prepend the shape of the lower rank array with 1s until both shapes have the same length.\nThe two arrays are said to be compatible in a dimension if they have the same size in the dimension, or if one of the arrays has size 1 in that dimension.\nThe arrays can be broadcast together if they are compatible in all dimensions. After broadcasting, each array behaves as if it had shape equal to the elementwise maximum of shapes of the two input arrays.\nIn any dimension where one array had size 1 and the other array had size greater than 1, the first array behaves as if it were copied along that dimension.\n\nThe documentation has more detail.\n\n\n4.3.2 Example: playing with images\nNice example of a 2D array?\nTODO"
  },
  {
    "objectID": "numpy.html#plotting-with-matplotlib",
    "href": "numpy.html#plotting-with-matplotlib",
    "title": "4Â  NumPy and friends",
    "section": "4.4 Plotting with Matplotlib",
    "text": "4.4 Plotting with Matplotlib\nThere are various specialized Python plotting libraries but the entry-level option is the catchily named Matplotlib. The pyplot module provides a plotting system that is similar to MATLAB (Iâ€™m told)\n\nimport matplotlib.pyplot as plt\n\nHereâ€™s a simple example of the plot function, used to plot 2D data\n\n# Compute the x and y coordinates for points on a sine curve\nx = np.arange(0, 3 * np.pi, 0.1)\ny = np.sin(x)\n\n# Plot the points using matplotlib\nplt.plot(x, y)\nplt.show()\n\n\n\n\nNote: you must call plt.show() to make graphics appear. Hereâ€™s a fancier example with some labelling\n\n# Compute the x and y coordinates for points on sine and cosine curves\nx = np.arange(0, 3 * np.pi, 0.1)\ny_sin = np.sin(x)\ny_cos = np.cos(x)\n\n# Plot the points using matplotlib\nplt.plot(x, y_sin)\nplt.plot(x, y_cos)\nplt.xlabel('x axis label')\nplt.ylabel('y axis label')\nplt.title('Sine and Cosine')\nplt.legend(['Sine', 'Cosine'])\nplt.show()\n\n\n\n\nOften youâ€™ll want to make several related plots and present them together, which can be achieved using the subplot function\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Compute the x and y coordinates for points on sine and cosine curves\nx = np.arange(0, 3 * np.pi, 0.1)\ny_sin = np.sin(x)\ny_cos = np.cos(x)\n\n# Set up a subplot grid that has height 2 and width 1,\n# and set the first such subplot as active.\nplt.subplot(2, 1, 1)\n\n# Make the first plot\nplt.plot(x, y_sin)\nplt.title('Sine')\n\n# Set the second subplot as active, and make the second plot.\nplt.subplot(2, 1, 2)\nplt.plot(x, y_cos)\nplt.title('Cosine')\n\n# Show the figure.\nplt.show()"
  },
  {
    "objectID": "numpy.html#saving-and-loading-data",
    "href": "numpy.html#saving-and-loading-data",
    "title": "4Â  NumPy and friends",
    "section": "4.5 Saving and loading data",
    "text": "4.5 Saving and loading data\nIn the course of your work you are likely to produce, as well as consume lots of data. While itâ€™s good practice to keep notebooks capable of reproducing any of your analyses, this could be time consuming and resource heavy for larger computations. Thus at some point youâ€™ll probably want to save and load data. For example, after saving the data of a large scale simulation youâ€™d like to load it and perform some analysis.\nNumPy comes with its own save and load functions and associated binary format .npy. The benefit of using these is that after loading you get back a NumPy array ready to be used.\nA related function savez allows several arrays to be saved and then loaded as a dictionary-like object."
  },
  {
    "objectID": "ode.html",
    "href": "ode.html",
    "title": "6Â  Solving differential equations with SciPy",
    "section": "",
    "text": "Newtonâ€™s fundamental discovery, the one which he considered necessary to keep secret and published only in the form of an anagram, consists of the following: Data aequatione quotcunque jluentes quantitae involvente jluxiones invenire et vice versa. In contemporary mathematical language, this means: â€œIt is useful to solve differential equationsâ€.\nVladimir Arnold, Geometrical Methods in the Theory of Ordinary Differential Equations\n\nWhile Arnold (and Newton) are of course right the problem is that solving differential equations is not possible in general. Even the simplest example of a first order ordinary differential equation (ODE) in a single variable\n\\[\n\\frac{dx}{dt} = f(x, t)\n\\tag{6.1}\\]\ncannot be solved for general \\(f(x,t)\\). Of course, formulating a physical (or whatever) system in terms of differential equations represents a nontrivial step on the road to understanding it, but a lot remains to be done.\nNumerical analysis of differential equations is a colossal topic in applied maths and we are barely going to scratch the surface. The important thing is to be able to access existing solvers (and implement your own if necessary) and crucially to understand their limitations.\n\n7 Eulerâ€™s method\nThe basic idea behind all ODE solves is to introduce a discretization of the equation and its solution \\(x_j\\equiv x(t_j)\\) at time points \\(t_j = hj\\) for some step size \\(h\\) and \\(j=0, 1, \\ldots\\). The very simplest is called the Euler method and approximates the derivative on the right hand side of EquationÂ 6.1 as\n\\[\n\\frac{dx}{dt} \\approx \\frac{x_{j+1} - x_j}{h}\n\\]\nLorenz attractor following Trebst notebooks\nChaos and discretization\nhttps://stackoverflow.com/questions/60338471/lyapunov-spectrum-for-known-odes-python-3\nThere is already some discussion in Part IB. There is an exercise based on planets\nOf practical value: Experimentally demonstrate order of integration\nFundamental Anagram of Calculus"
  },
  {
    "objectID": "numbers.html#integers",
    "href": "numbers.html#integers",
    "title": "5Â  Floating point and all that",
    "section": "5.1 Integers",
    "text": "5.1 Integers\nLetâ€™s begin with something simpler\n\n1 + 1 == 2\n\nTrue\n\n\nwhich is a bit more reassuring. Integers can be represented in binary\n\n3 == 0b11\n\nTrue\n\n\nor octal or hexadecimal (with a prefix 0o or 0h). You can get the binary string representing an integer using the bin function\n\nbin(-2)\n\n'-0b10'\n\n\nPython allows for arbitrarily large integers, so there is no possibility of overflow or rounding error\n\n2**100\n\n1267650600228229401496703205376\n\n\nThe only limitation is the memory required to store it.\nNumpy integers are a different story\n\nimport numpy as np\nnp.int64(2**100)\n\nOverflowError: Python int too large to convert to C long\n\n\nSince NumPy is using C the types have to play nicely. The range of integers that can be represented with 32 bit numpy.int32s is \\(\\approx\\pm 2^{31} \\approx \\pm 2.1 Ã— 10^9\\) (one bit is for the sign) and 64 bit numpy.int64s is \\(\\approx\\pm 2^{63} \\approx \\pm 9.2 Ã— 10^{18}\\). Apart from the risk of overflow when working NumPyâ€™s integers there are not other gotchas to worry about."
  },
  {
    "objectID": "numbers.html#floating-point-numbers",
    "href": "numbers.html#floating-point-numbers",
    "title": "5Â  Floating point and all that",
    "section": "5.2 Floating point numbers",
    "text": "5.2 Floating point numbers\nThe reason why \\(0.1 + 0.2 \\neq 0.3\\) in Python is that specifying a real number exactly would involve an infinite number of bits, so that any finite representation is necessarily approximate.\nThe representation computers use for the reals is called floating point arithmetic. It is essentially a form of scientific notation, in which a significand (it contains the significant figures) is multiplied by an exponent. The name floating point reflects the fact that the number of digits after the decimal point is not fixed (Iâ€™m using the base ten terms for convenience)\nThis representation requires the choice of a base, and Pythonâ€™s floating point numbers use binary. Numbers with finite binary representations therefore behave nicely\n\n0.125 + 0.25 == 0.375\n\nTrue\n\n\nFor decimal numbers to be represented exactly weâ€™d have to use base ten. This can be achieved with the decimal module. Our \\(0.1+0.2\\) example then works as expected\n\nfrom decimal import *\nDecimal('0.1') + Decimal('0.2')\n\nDecimal('0.3')\n\n\nSince there is nothing to single out the decimal representation in physics (as opposed to, say, finance) we wonâ€™t have any need for it.\nA specification for floating point numbers must give\n\nA base (or radix) \\(b\\)\nA precision \\(p\\), the number of digits in the significand \\(c\\). Thus \\(0\\leq c \\leq b^{p}-1\\).\nA range of exponents \\(q\\) specifed by \\(\\text{emin}\\) and \\(\\text{emax}\\) with \\(\\text{emin}\\leq q+p-1 \\leq \\text{emax}\\).\n\nIncluding one bit \\(s\\) for the overall sign, a number then has the form \\((-1)^s\\times c \\times b^q\\). The smallest positive nonzero number that can be represented is therefore \\(b^{1 + \\text{emin} - p}\\) (corresponding to the smallest value of the exponent) and the largest is \\(b^{1 + \\text{emax}} - 1\\).\nThe above representation isnâ€™t unique: for some numbers you could make the significand smaller and the exponent bigger. A unique representation is fixed by choosing the exponent to be as small as possible.\nRepresenting numbers smaller than \\(b^{\\text{emin}}\\) involves a loss of precision, as the number of digits in the significand falls below \\(p\\) and the exponent has taken its minimum value . These are called subnormal numbers. For binary floats, if we stick with the normal numbers and a \\(p\\)-bit significand the leading bit will be 1 and so can be dropped from the representation, which then only requires \\(p-1\\) bits.\nThe specification for the floating point numbers used by Python (and many other languages) is contained in the IEEE Standard for Floating Point Arithmetic IEEE 754. The default Python float uses the 64 bit binary64 representation (often called double precision). Hereâ€™s how those 64 bits are used\n\n\\(p=53\\) for the significand, encoded in 52 bits\n11 bits for the exponent\n1 bit for the sign\n\nAnother common representation is the 32 bit binary32 (single precision) with\n\n\\(p=24\\) for the significand, encoded in 23 bits\n8 bits for the exponent\n1 bit for the sign\n\n\n5.2.1 Floating point numbers in NumPy\nIf this all a bit theoretical you can just get NumPyâ€™s finfo function to tell all about the machine precision\n\nnp.finfo(np.float64)\n\nfinfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)\n\n\nNote that \\(2^{-52}=2.22\\times 10^{-16}\\) which accounts for the value \\(10^{-15}\\) of the resolution. This can be checked by finding when a number is close enough to treated as 1.0.\n\nx=1.0\nwhile 1.0 + x != 1.0:\n    x /= 1.01 \nprint(x)\n\n1.099427563084686e-16\n\n\nFor binary32 we have a resolution of \\(10^{-6}\\).\n\nnp.finfo(np.float32)\n\nfinfo(resolution=1e-06, min=-3.4028235e+38, max=3.4028235e+38, dtype=float32)\n\n\nOne lesson from this is that taking small differences between numbers is a potential source of rounding error, as in this somewhat mean exam question\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolution: \\(x-x'=x(1-\\gamma^{-1})\\sim x\\beta^2/2\\sim 4.2\\text{mm}\\).\n\nimport numpy as np\nfrom scipy.constants import c\nbeta = 384400e3 / (76 * 3600) / c\ngamma = 1/np.sqrt(1 - beta**2)\nprint(1 - np.float32(1/gamma), 1 - np.float64(1/gamma))\n\n0.0 1.0981660025777273e-11\n\n\n\n\n\n\n\n5.2.2 The dreaded NaN\nAs well as a floating point system, IEEE 754 defines Infinity and NaN (Not a Number)\n\nnp.array([1, -1, 0]) / 0\n\n/var/folders/xs/y8sn45v943s2_62flnxw0p940000gn/T/ipykernel_45328/2604490398.py:1: RuntimeWarning:\n\ndivide by zero encountered in true_divide\n\n/var/folders/xs/y8sn45v943s2_62flnxw0p940000gn/T/ipykernel_45328/2604490398.py:1: RuntimeWarning:\n\ninvalid value encountered in true_divide\n\n\n\narray([ inf, -inf,  nan])\n\n\nThey behave as you might guess\n\n2 * np.inf, 0 * np.inf, np.inf > np.nan\n\n(inf, nan, False)\n\n\nNaNs propagate through subsequent operations\n\n2 * np.nan\n\nnan\n\n\nwhich means that if you get a NaN somewhere in your calculation, youâ€™ll probably end up seeing it somewhere in the output (which is the idea)."
  },
  {
    "objectID": "random.html",
    "href": "random.html",
    "title": "7Â  Random algorithms",
    "section": "",
    "text": "Simplest examplesâ€¦"
  },
  {
    "objectID": "linear.html",
    "href": "linear.html",
    "title": "9Â  Linear algebra",
    "section": "",
    "text": "Krylov subspaces\nSVD and quantum mechanics. Quantum entanglement.\nImage compression using SVD\nhttp://timbaumann.info/svd-image-compression-demo/\nTrebst has nice Einstein example"
  },
  {
    "objectID": "complexity.html",
    "href": "complexity.html",
    "title": "8Â  Computational complexity",
    "section": "",
    "text": "Simple example from Leetcode\nAnalaysis of algorithms\nNice examples from Garth Wells\nhttps://github.com/CambridgeEngineering/PartIA-Computing-Michaelmas/blob/main/11%20Complexity.ipynb"
  },
  {
    "objectID": "numbers.html#practical-matters",
    "href": "numbers.html#practical-matters",
    "title": "5Â  Floating point and all that",
    "section": "5.3 Practical matters",
    "text": "5.3 Practical matters\nChecking for equality in NumPy"
  },
  {
    "objectID": "monte-carlo.html",
    "href": "monte-carlo.html",
    "title": "7Â  Monte Carlo methods",
    "section": "",
    "text": "Simplest examplesâ€¦\nHow to estimate errors\nSome curve fitting here to extract something?\nGoogle pagerank\nMCMC in Bayesian inference\nRelation to Ising models. Community detection. Why not?"
  },
  {
    "objectID": "numbers.html#main-takeaways",
    "href": "numbers.html#main-takeaways",
    "title": "5Â  Floating point and all that",
    "section": "5.3 Main takeaways",
    "text": "5.3 Main takeaways\n\nFloating point numbers are a necessarily imperfect model of the real numbers. You should not expect facts about real numbers to be true of their floating point representations in general."
  },
  {
    "objectID": "ode.html#eulers-method",
    "href": "ode.html#eulers-method",
    "title": "6Â  Solving differential equations with SciPy",
    "section": "6.1 Eulerâ€™s method",
    "text": "6.1 Eulerâ€™s method\nThe basic idea behind all ODE solvers is to introduce a discretization of the equation and its solution \\(x_j\\equiv x(t_j)\\) at time points \\(t_j = hj\\) for some step size \\(h\\) and \\(j=0, 1, \\ldots\\). The very simplest approach is called Eulerâ€™s method 2 and approximates the derivative on the right hand side of EquationÂ 6.1 as\n\\[\n\\frac{dx}{dt}\\Bigg|_{t=t_j} \\approx \\frac{x_{j+1} - x_j}{h}.\n\\tag{6.2}\\]\nRearranging the ODE then gives the update rule\n\\[\nx_{j+1} = x_j + hf(x_j, t_j).\n\\tag{6.3}\\]\nOnce an initial condition \\(x_0\\) is specified, subsequent values can be obtained by iteration.\nNotice that EquationÂ 6.2 involved a forward finite difference: the derivative at time \\(t_j\\) was approximated in terms of \\(x_j\\) and \\(x_{j+1}\\) (i.e.Â one step forward in time). Why do this? So that the update rule EquationÂ 6.3 is an explicit formula for \\(x_{j+1}\\) in terms of \\(x_j\\). This is called an explicit method. If we had used the backward derivative we would end up with backward Euler method \\[\nx_{j+1} = x_j + hf(x_{j+1}, t_{j+1})\n\\tag{6.4}\\]\nwhich is implicit. This means that the update requires an additional step to numerically solve for \\(x_{j+1}\\). Although this is more costly, there are benefits to the backward method associated with stability.\n\n6.1.1 Truncation error\nIn making the approximation EquationÂ 6.2 we make an \\(O(h^2)\\) local truncation error. To integrate for a fixed time the number of steps required is proportional to \\(h^{-1}\\), which means that the worst case error at fixed time (the global truncation error) is \\(O(h)\\). For this reason Eulerâ€™s method is called first order. More sophisticated methods are typically higher order: the SciPy function scipy.integrate.solve_ivp uses a fifth order method by default.\nTODO discuss midpoint method?\n\n\n6.1.2 Rounding error\nIf you had unlimited computer time you might think you could make the step size \\(h\\) ever smaller in order to make the updates more accurate. This ignores the machine precision \\(\\epsilon\\), discussed in SectionÂ 5.2.1. The rounding error is roughly \\(\\epsilon x_j\\), and if the \\(N\\propto h^{-1}\\) errors in successive steps can be treated as independent random variables, the relative total rounding error will be \\(\\propto \\sqrt{N}\\epsilon=\\frac{\\epsilon}{\\sqrt{h}}\\) and will dominate for \\(h\\) small.\n\n\n6.1.3 Stability\nApart from the relatively low accuracy that comes from using a first order method, the Euler method may additionally be unstable, depending on the equation. This can be demonstrated for the linear equation\n\\[\n\\frac{dx}{dt} = kx\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef euler(h, t_max, k=1):\n    \"\"\"\n    Solve the equation x' = k x, with x(0) = 1 using\n    the Euler method. \n\n    Integrate from t=0 to t=t_max using stepsize h for\n    num_steps = t_max / h.\n    \n    Returns two arrays of length num_steps: t, the time coordinate, and x_0, the position.\n    \"\"\"\n    num_steps = int(t_max / h)\n    # Allocate return arrays\n    x = np.zeros(num_steps, dtype=np.float32)\n    t = np.zeros(num_steps, dtype=np.float32)\n    x[0] = 1.0  # Initial condition\n    for i in range(num_steps - 1):\n        x[i+1] = x[i] + k * x[i] * h\n        t[i+1] = t[i] + h  # Time step\n    return t, x\n\nk = -2.3\nt_max = 5\nt, x = euler(1, t_max, k)\nplt.plot(t, x, label=\"h=1 Euler\")\nt, x = euler(0.7, t_max, k)\nplt.plot(t, x, label=\"h=0.7 Euler\")\nt = np.linspace(0, t_max, 100)\nplt.plot(t, np.exp(k * t), label=\"exact solution\")\nplt.title(\"k=-2.3\")\nplt.legend()\nplt.show()\n\n\n\n\nFor a linear equation the Euler update EquationÂ 6.3 is a simple rescaling\n\\[\nx_{j+1} = x_j(1 + hk)\n\\]\nso the region of stability is \\(|1 + hk|\\leq 1\\). You can check that the backward Euler method EquationÂ 6.4 eliminates the instability for \\(k<0\\)."
  },
  {
    "objectID": "ode.html#using-scipy",
    "href": "ode.html#using-scipy",
    "title": "6Â  Solving differential equations with SciPy",
    "section": "6.2 Using SciPy",
    "text": "6.2 Using SciPy\nComing up with integration schemes is best left to the professionals. Your first port of call for solving ODEs in Python should probably be the integrate module of the SciPy scientific computing library. The function scipy.integrate.solve_ivp provides a versatile API.\nOne important thing to understand is that all these integration schemes apply to systems of first order differential equations. Higher order equations can always be presented as a first order system, at the expense of introducing more equations. For example, in physics we are often concerned with Newtonâ€™s equation\n\\[\nm\\frac{d^2 \\mathbf{x}}{dt^2} = \\mathbf{f}(\\mathbf{x},t),\n\\]\nwhich is three second order equations. We turn this into a first order system by introducing the velocity \\(\\mathbf{v}=\\dot{\\mathbf{x}}\\), giving the six equations\n\\[\n\\begin{align}\n\\frac{d\\mathbf{x}}{dt} &= \\mathbf{v}\\\\\nm\\frac{d \\mathbf{v}}{dt} &= \\mathbf{f}(\\mathbf{x},t).\n\\end{align}\n\\]\nAs a simple example, letâ€™s consider the pendulum equation\n\\[\n\\ddot \\theta = -\\sin\\theta\n\\]\nwhich can be cast as\n\\[\n\\begin{align}\n\\dot\\theta &= l\\\\\n\\dot l &= -\\sin\\theta\n\\end{align}\n\\]\nSolving the equation using SciPy just requires us to define a function giving the right hand side of these equations\n\ndef pendulum(t, y): return [y[1], -np.sin(y[0])]\n# The pendulum equation: y[0] is theta and y[1] is l\n\nand then calling solve_ivp\n\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\n\nt_max = 1000\npendulum_motion = solve_ivp(pendulum, [0, t_max], [2, 0], dense_output=True)\n\nThe option dense_output=True is used to specify that a continuous solution should be found. What this means in practice is that the returned object pendulum_motion has a sol property that is an instance of OdeSolution. sol(t) returns the computed solution at \\(t\\) (this involves interpolation). We can use this to plot the pendulumâ€™s trajectory in the \\(\\theta- l\\) phase plane, along with the contours of the conserved energy function\n\\[\nE(\\theta, l) = \\frac{1}{2}l^2 - \\cos\\theta\n\\]\n\n\nCode for plot\nfig, ax = plt.subplots()\n\ntheta = np.linspace(-1.1 * np.pi, 1.1 * np.pi, 60)\nl = np.linspace(-2, 2, 60)\nE = -np.cos(theta[np.newaxis,:]) + (l[:,np.newaxis])**2 / 2\n# Note the use of broadcasting to obtain the energy as a function of the phase space coordinates\n\nxx, yy = np.meshgrid(theta, l)\n\nax.contourf(xx, yy, E, cmap='Reds')\nt = np.linspace(0, t_max, 10000)\nax.plot(*pendulum_motion.sol(t))\nplt.xlabel(r'$\\theta$')\nplt.ylabel(r'$l$')\nplt.show()\n\n\n\n\n\nThe thickness of the blue line is due to the variation of the energy over the \\(t=1000\\) trajectory (measured in units where the frequency of linear oscillation is \\(2\\pi\\)). Notice that we did not have to specify a time step: this is determined adaptively by the solver to keep the estimate of the local error below atol + rtol * abs(y), where atol and rtol are optional arguments that correspond to the absolute and relative tolerances, with default values of \\(10^{-6}\\) and \\(10^{-3}\\) respectively. The global error is of course much larger. In general, monitoring conserved quantities is a good experimental method for assessing the accuracy of integration.\nThe alternative to dense_output=True is to track â€œeventsâ€, which are user-defined points of interest on the trajectory. We supply solve_ivp with functions event(t, x) whose zeros define the events. We can use events to take a â€œcross sectionâ€ of higher dimensional motion. As an example letâ€™s consider the HÃ©nonâ€“Heiles system, a model chaotic system with origins in stellar dynamics\n\\[\n\\begin{align}\n\\dot x &= p_x \\\\\n\\dot p_x &= -x -2\\lambda xy \\\\\n\\dot y &= p_y \\\\\n\\dot p_y &=  - y -\\lambda(x^2-y^2).\n\\end{align}\n\\]\nThese coupled first order systems for the \\(N\\) coordinates and \\(N\\) momenta of a mechanical system with \\(N\\) degrees of freedom are an example of Hamiltonâ€™s equations. The phase space is now four dimensional and impossible to visualize.\nThe conserved energy is\n\\[\nE = \\frac{1}{2}\\left(p_x^2+p_y^2 + x^2 + y^2\\right) + \\lambda\\left(x^2y-\\frac{1}{3}y^3\\right)\n\\]\nIf we take a PoincarÃ© section with \\(x=0\\) a system with energy \\(E\\) must lie within the curve defined by\n\\[\nE = \\frac{1}{2}\\left(p_y^2 + y^2\\right) -\\frac{\\lambda}{3}y^3.\n\\]\nStarting from \\(x=0\\) we can generate a section of given \\(E\\) by solving for \\(p_x\\)\n\\[\np_x = \\sqrt{2E-y^2-p_y^2 + \\frac{2\\lambda}{3}y^3}\n\\]\n\ndef henon_heiles(t, z, ðœ†): \n    x, px, y, py = z\n    return [px, -x - 2 * ðœ† * x * y, py, -y - ðœ† * (x**2 - y**2)]\n\ndef px(E, y, py, ðœ†):\n    return np.sqrt(2 * E - y**2 - py**2 + 2 * ðœ† * y**3 / 3)\n\ndef section(t, y, ðœ†): return y[0] # The section with x=0\n\nt_max = 10000\nðœ† = 1\nhh_motion = []\nfor E in [1/12, 1/8, 1/6]:\n    hh_motion.append(solve_ivp(henon_heiles, [0, t_max], [0, px(E, 0.1, 0.1, ðœ†), 0.1, 0.1], events=section, args=[ðœ†], atol=1e-7, rtol=1e-7))\n\nWe can then plot a section of the phase space with increasing energy, showing the transition from regular to chaotic dynamics.\n\n\nCode for plot\nfig, ax = plt.subplots(1, 3)\nenergies = [\"1/12\", \"1/8\", \"1/6\"]\nfor idx, data in enumerate(hh_motion): \n        ax[idx].scatter(*data.y_events[0][:, 2:].T, s=0.1)\n        ax[idx].title.set_text(f\"E={energies[idx]}\")        \n        ax[idx].set_xlabel(r'$y$')\n\nax[0].set_ylabel(r'$p_y$')\nplt.show()\n\n\n\n\n\nTODO Leapfrog?\nSymplectic integrator see e.g.Â \nLook at leapfrog?\nhttps://github.com/scipy/scipy/issues/12690\nProblem is that itâ€™s hard to do in scipy\nhttps://stackoverflow.com/questions/60338471/lyapunov-spectrum-for-known-odes-python-3"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Part II Computational Physics",
    "section": "Schedule",
    "text": "Schedule\nThe course of eight Lectures will take place at 10:00 on Mondays and Fridays in the Pippard Lecture Theatre.\n\nFirst lecture: Monday 23th January\nLast lecture: Friday 17th February\nFirst assignment: Friday 17th February â€“ Friday 24th February\nSecond assignment: Friday 24th February â€“ Friday 3rd March\nThird assignment: Friday 3rd March â€“ Friday 10th March\nFourth assignment: Friday 10th March â€“ Friday 17th March (last day of full Lent term)"
  },
  {
    "objectID": "divide.html",
    "href": "divide.html",
    "title": "10Â  Divide and Conquer",
    "section": "",
    "text": "FFT. Use split step as illustration Matrix multiplication"
  },
  {
    "objectID": "monte-carlo.html#random-number-generators",
    "href": "monte-carlo.html#random-number-generators",
    "title": "7Â  Monte Carlo methods",
    "section": "7.1 Random number generators",
    "text": "7.1 Random number generators\nDoes recompile go slow? No itâ€™s fast"
  }
]