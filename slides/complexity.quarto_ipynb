{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "number-sections: false\n",
        "format:\n",
        "  revealjs: \n",
        "    theme: [default, reveal_custom.scss]\n",
        "    slide-number: true\n",
        "    hash: true\n",
        "    center: true\n",
        "    auto-stretch: false\n",
        "    html-math-method: mathjax\n",
        "    preview-links: true\n",
        "---\n",
        "\n",
        "\n",
        "# Algorithms and computational complexity\n",
        "\n",
        "## First example: multiplication\n",
        "\n",
        "- Big numbers harder than small numbers. How much harder? \n",
        "\n",
        "+---+---+---+---+---+\n",
        "|   |   | 1 | 2 | 3 |\n",
        "|   |   |   |   |   |\n",
        "|   | × | 3 | 2 | 1 |\n",
        "+===+===+===+===+===+\n",
        "| _ | _ | 1 | 2 | 3 |\n",
        "|   |   |   |   |   |\n",
        "| _ | 2 | 4 | 6 |   |\n",
        "|   |   |   |   |   |\n",
        "| 3 | 6 | 9 |   |   |\n",
        "|   |   |   |   |   |\n",
        "+---+---+---+---+---+\n",
        "| 3 | 9 | 4 | 8 | 3 |\n",
        "|   |   |   |   |   |\n",
        "+---+---+---+---+---+\n",
        "\n",
        "---\n",
        "\n",
        "- For $n$ digits have to perform $n^2$ single digit multiplications\n",
        "\n",
        "- Add together $n$ resulting $n$-digit numbers\n",
        "\n",
        " - Overall number of operations is proportional to $n^2$: $\\times 2$ number of digits will make problem four times harder\n",
        "\n",
        "- Exactly how long this takes will depend on many things, but you can't get away from the basic quadratic scaling law of this algorithm\n",
        "\n",
        "## Defining complexity\n",
        "\n",
        "- The __complexity__ of a problem refers to this _scaling of the number of steps involved_\n",
        "\n",
        "- Difficulty of particular task (or calculation) may vary considerably —  $100\\times 100$ is easy, for example\n",
        "\n",
        "- Instead ask about how a particular _general_ algorithm performs on a _class_ of tasks\n",
        "\n",
        "- In CS multiplication of $n$ digit numbers is a __problem__. _Particular pair_ of $n$ digit numbers is an __instance__\n",
        "\n",
        "-  Above algorithm for multiplication that has __quadratic complexity__, or \"$O(n^2)$ complexity\" (say \"order $n$ squared\"). \n",
        "\n",
        "---\n",
        "\n",
        "- Description only keeps track of how the difficulty scales with the size of the problem\n",
        "\n",
        "    1. Allows us to gloss over what exactly we mean by a _step_. Are we working in base ten or binary? Looking the digit multiplications up in a table or doing them from scratch?\n",
        "\n",
        "    2. Don't have to worry about how the algorithm is implemented exactly in software or hardware, what language used, and so on\n",
        "\n",
        "    3. It is important to know whether our code is going to run for twice as long, four times as long, or $2^{10}$ times as long\n",
        "\n",
        "## Best / worst / average case\n",
        "\n",
        "- Consider _search_: finding an item in an (unordered) list of length $n$. How hard is this? \n",
        "\n",
        "- Have to check every item until you find the one you are looking for, so this suggests the complexity is $O(n)$\n",
        "\n",
        "- Could be lucky and get it first try (or in first ten tries). The _best case complexity_ of search is $O(1)$.\n",
        "\n",
        "- Worst thing that could happen is that the sought item is last: the _worst case complexity_ is $O(n)$\n",
        "\n",
        "- On average, find your item near the middle of the list on attempt $\\sim n/2$, so the _average case complexity_ is $O(n/2)$. This is the same as $O(n)$ (constants don't matter)\n",
        "\n",
        "---\n",
        "\n",
        "- Thus for _linear search_ we have:\n",
        "\n",
        "|              | Complexity |\n",
        "|--------------|------------|\n",
        "| Best case    |   $O(1)$   |\n",
        "| Worst case   |   $O(n)$   |\n",
        "| Average case |   $O(n)$   |\n",
        "\n",
        "---\n",
        "\n",
        "We can check the average case performance experimentally by using randomly chosen lists:\n"
      ],
      "id": "b78bb5fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def linear_search(x, val):\n",
        "    \"Return True if val is in x, otherwise return False\"\n",
        "    for item in x:\n",
        "        if item == val:\n",
        "            return True\n",
        "    return False"
      ],
      "id": "10365383",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ],
      "id": "e40118e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "# Create array of problem sizes n we want to test (powers of 2)\n",
        "N = 2**np.arange(2, 20)\n",
        "\n",
        "# Generate the array of integers for the largest problem to use in plotting times\n",
        "x = np.arange(N[-1])\n",
        "\n",
        "# Initialise an empty array to stores times for plotting\n",
        "times = []\n",
        "\n",
        "# Time the search for each problem size\n",
        "for n in N:\n",
        "\n",
        "    # Time search function (repeating 3 times) to find a random integer in x[:n]\n",
        "    t = %timeit -q -n4 -r1 -o linear_search(x[:n], np.random.randint(0, n))\n",
        "\n",
        "    # Store best case time (best on a randomly chosen problem)\n",
        "    times.append(t.best)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot and label the time taken for linear search\n",
        "plt.loglog(N, times, marker='o')\n",
        "plt.xlabel('$n$')\n",
        "plt.ylabel('$t$ (s)')\n",
        "\n",
        "# Show a reference line of O(n)\n",
        "plt.loglog(N, 1e-6*N, label='$O(n)$')\n",
        "\n",
        "# Add legend\n",
        "plt.legend(loc=0)\n",
        "plt.title(\"Experimental complexity of linear search\")\n",
        "\n",
        "plt.show()"
      ],
      "id": "4aef1b19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "- \"Experimental noise\" arises because don't have full control over exactly what computer is doing at any moment: lots of other processes running. \n",
        "\n",
        "- Takes a while to reach the linear regime: overhead associated with starting the program\n",
        "\n",
        "---\n",
        "\n",
        "## Polynomial complexity\n",
        "\n",
        "- You've already learnt a lot of algorithms in mathematics (even if you don't think of them this way) \n",
        "\n",
        "- Let's revisit some them through lens of computational complexity\n",
        "\n",
        "---\n",
        "\n",
        "## Matrix-vector multiplication\n",
        "\n",
        "- Multiplying a $n$-dimensional vector by a $n\\times n$ matrix? \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\sum_{j=1}^n M_{ij}v_j\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "- Sum contains $n$ terms, and have to perform $n$ such sums\n",
        "\n",
        "- Thus the complexity of this operation is $O(n^2)$. \n",
        "\n",
        "---\n",
        "\n",
        "## Matrix-matrix multiplication\n",
        "\n",
        "$$\n",
        "\\sum_{j} A_{ij}B_{jk}\n",
        "$$\n",
        "\n",
        "- $n$ terms for each of the $n^2$ assignments of $i$ and $k$. Complexity: $O(n^3)$\n",
        "\n",
        "--- \n",
        "\n",
        "- To calculate $M_1 M_2\\cdots M_n \\mathbf{v}$, do _not_ calculate the matrix product first, but instead\n",
        "\n",
        "$$\n",
        " M_1\\left(M_2\\cdots \\left(M_n \\mathbf{v}\\right)\\right)\n",
        "$$\n",
        "\n",
        "[Wikipedia has a nice summary](https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations) of computational complexity of common mathematical operations\n",
        "\n",
        "---\n",
        "\n",
        "- If algorithm has complexity $O(n^p)$ for some $p$ it has _polynomial complexity_\n",
        "\n",
        "- Useful heuristic is that if you have $p$ nested loops that range over $\\sim n$, the complexity is $O(n^p)$ \n",
        "\n",
        "## Better than linear?\n",
        "\n",
        "- Seems obvious that for search you can't do better than linear\n",
        "\n",
        "- What if the list is _ordered_? (numerical for numbers, or lexicographic for strings)\n",
        "\n",
        "- Extra structure allows gives [binary search](https://en.wikipedia.org/wiki/Binary_search_algorithm) that you may have seen before\n",
        "\n",
        "- Look in middle of list and see if item you seek should be in the top half or bottom half\n",
        "\n",
        "- Take the relevant half and divide it in half again to determine which quarter of the list your item is in, and so on\n",
        "\n",
        "---\n"
      ],
      "id": "7a7acce8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def binary_search(x, val):\n",
        "    \"\"\"Peform binary search on x to find val. If found returns position, otherwise returns None.\"\"\"\n",
        "\n",
        "    # Intialise end point indices\n",
        "    lower, upper = 0, len(x) - 1\n",
        "\n",
        "    # If values is outside of interval, return None \n",
        "    if val < x[lower] or val > x[upper]:\n",
        "        return None\n",
        "\n",
        "    # Perform binary search\n",
        "    while True:\n",
        "                \n",
        "        # Compute midpoint index (integer division)\n",
        "        midpoint = (upper + lower)//2\n",
        "\n",
        "        # Check which side of x[midpoint] val lies, and update midpoint accordingly\n",
        "        if val < x[midpoint]:\n",
        "            upper = midpoint - 1\n",
        "        elif val > x[midpoint]:\n",
        "            lower = midpoint + 1\n",
        "        elif val == x[midpoint]:  # found, so return\n",
        "            return midpoint\n",
        "       \n",
        "        # In this case val is not in list (return None)\n",
        "        if upper < lower:\n",
        "            return None"
      ],
      "id": "1ff38dd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n"
      ],
      "id": "56041fc6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create array of problem sizes we want to test (powers of 2)\n",
        "N = 2**np.arange(2, 24)\n",
        "\n",
        "# Creat array and sort\n",
        "x = np.arange(N[-1])\n",
        "x = np.sort(x)\n",
        "\n",
        "# Initlise an empty array to capture time taken\n",
        "times = []\n",
        "\n",
        "# Time search for different problem sizes\n",
        "for n in N:\n",
        "    # Time search function for finding '2'\n",
        "    t = %timeit -q -n5 -r2 -o binary_search(x[:n], 2)\n",
        "\n",
        "    # Store average\n",
        "    times.append(t.best)\n",
        "\n",
        "# Plot and label the time taken for binary search\n",
        "plt.semilogx(N, times, marker='o')\n",
        "plt.xlabel('$n$')\n",
        "plt.ylabel('$t$ (s)')\n",
        "\n",
        "# Change format on y-axis to scientific notation\n",
        "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
        "plt.title(\"Experimental complexity of binary search\")\n",
        "plt.show()"
      ],
      "id": "54b2915c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "- If length is a power of 2 i.e. $n=2^p$, we are going to need $p$ bisections to locate our value\n",
        "\n",
        "- Complexity is $O(\\log n)$ (we don't need to specify the base as overall constants don't matter)\n",
        "\n",
        "---\n",
        "\n",
        "## Exponentiation by squaring\n",
        "\n",
        "- _Exponentiation_ is problem of raising a number $b$ (the base) to the $n$th power\n",
        "\n",
        "- Multiply the number by itself $n$ times: linear scaling\n",
        "\n",
        "- There's a quicker way, since\n",
        "$$\n",
        "\\begin{align}\n",
        "b^2 &= b\\cdot b\\\\\n",
        "b^4 &= b^2\\cdot b^2\\\\\n",
        "b^8 &= b^4\\cdot b^4\n",
        "\\end{align}\n",
        "$$\n",
        "- Only have to do _three_ multiplications! \n",
        "\n",
        "---\n",
        "\n",
        "- Exponentiation by this method (called [exponentiation by squaring](https://en.wikipedia.org/wiki/Exponentiation_by_squaring)) is $O(\\log n)$\n",
        "\n",
        "- To handle powers that aren't a power of $2$\n",
        "\n",
        "$$\n",
        "b^n = \\begin{cases}\n",
        "    b^{n/2} \\cdot b^{n/2} & \\text{if $n$ even} \\\\\n",
        "    b \\cdot b^{n-1} & \\text{if $n$ odd}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "---\n"
      ],
      "id": "ade955ff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def exp(b, n):\n",
        "    if n == 0:\n",
        "        return 1\n",
        "    elif n % 2 == 0:\n",
        "        return exp(b, n // 2)**2\n",
        "    else:\n",
        "        return b * exp(b, n - 1) \n",
        "\n",
        "exp(2, 6)"
      ],
      "id": "e1c80308",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Implementation is _recursive_: `exp(b, n)` _calls itself_\n",
        "\n",
        "- Only calls itself with _lower values of the exponent $n$_\n",
        "\n",
        "- Process continues until we hit $n=0$, and 1 is returned by the first part of the `if ... else`\n",
        "\n",
        "---\n",
        "\n",
        "- Any recursive function has to have a _base case_ to avoid an infinite regress\n"
      ],
      "id": "9c878682"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| error: true\n",
        "#| echo: true\n",
        "def exp_no_base_case(b, n):\n",
        "    if n % 2 == 0:\n",
        "        return exp_no_base_case(b, n // 2)**2\n",
        "    else:\n",
        "        return b * exp_no_base_case(b, n - 1) \n",
        "\n",
        "exp_no_base_case(2, 6)"
      ],
      "id": "6a440777",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "- Exponentiation can be done efficiently\n",
        "\n",
        "- Finding the logarithm can't!\n",
        "\n",
        "- More precisely, work with modular arithmetic e.g. do all operations modulo some prime $p$\n",
        "\n",
        "- Then for $b, y=0,\\ldots p-1$ we are guaranteed that there is some number $x$ such that $b^x=y$: [discrete logarithm](https://en.wikipedia.org/wiki/Discrete_logarithm)\n",
        "\n",
        "- Finding this number is hard: no known method for computing it efficiently\n",
        "\n",
        "- Certain [public-key cryptosystems](https://en.wikipedia.org/wiki/Public-key_cryptography) are based on the difficulty of the discrete log (for carefully chosen $b$, $p$ and $y$)\n",
        "\n",
        "## Exponential complexity\n",
        "\n",
        "- [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number)\n",
        "$$\n",
        " 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233 ...\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Fib}(n) = \\text{Fib}(n-1) + \\text{Fib}(n-2)\n",
        "$$\n",
        "\n",
        "- $\\text{Fib}(n)$ is defined in terms of lower values of $n$, so a recursive definition possible\n",
        "\n",
        "---\n"
      ],
      "id": "3b663392"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def fib(n):\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return fib(n - 1) + fib(n - 2)\n",
        "\n",
        "fib(13)"
      ],
      "id": "613a5411",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- First two terms are base cases\n",
        "\n",
        "- Actually a terrible way of calculating $\\text{Fib}(n)$!\n",
        "\n",
        "---\n",
        "\n",
        "![Recursive tree for calculating Fibonacci numbers](../assets/fibonacci.png)\n",
        "\n",
        "- There are huge amounts of duplication! \n",
        "\n",
        "---\n",
        "\n",
        "- Complexity of this algorithm actually grows _exponentially_ with $n$: because of branching structure algorithm is $O(2^n)$. \n",
        "\n",
        "- Calculating Fibonacci numbers the sensible way (i.e. the way you do it in your head) gives an $O(n)$ algorithm\n",
        "\n",
        "---\n",
        "\n",
        "- Exp complexity not just down to poor algos!\n",
        "\n",
        "- Possible to come up with problems that definitely _can't_ be solved faster than exponentially \n",
        "\n",
        "- [Towers of Hanoi](https://en.wikipedia.org/wiki/Tower_of_Hanoi) is one famous example\n",
        "\n",
        "---\n",
        "\n",
        "- Simulation of quantum system with $n$ qubits believed to have complexity $O(2^n)$\n",
        "\n",
        "- Big part of hype surrounding quantum computers\n",
        "\n",
        "---\n",
        "\n",
        "- $\\exists$ problems whose solution, once found, is easy to check\n",
        "\n",
        "- Discrete logarithm is one example\n",
        "\n",
        "- Checking involves exponentiation, and exponentiation is $O(\\log n)$ in size of numbers, or $O(n)$ in number of digits\n",
        "\n",
        "- Question of whether efficient (i.e. polynomial) algorithms _always_ exist for problems which are easy to check _the_ outstanding problem in computer science: [P _vs_ NP](https://en.wikipedia.org/wiki/P_versus_NP_problem)\n",
        "\n",
        "- P is class of problems with polynomial time algorithms and NP is class with solutions checkable in polynomial time\n",
        "\n",
        "- Are these two classes the same or do they differ? \n",
        "\n",
        "---\n",
        "\n",
        "- Computer scientists obsess about P vs. NP, but finding an algorithm that changes the exponent e.g. from cubic to quadratic, is still a big deal!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Sorting\n",
        "\n",
        "- Turning a list or array into a sorted list (conventionally in _ascending_ order):\n"
      ],
      "id": "4ca327b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "random_array = np.random.randint(0,100, 10)\n",
        "sorted(random_array)"
      ],
      "id": "26f65563",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- What is Python actually _doing_? \n",
        "\n",
        "- _Many_ sorting algorithms. See [Wikipedia](https://en.wikipedia.org/wiki/Sorting_algorithm) for an extensive list\n",
        "\n",
        "---\n",
        "\n",
        "## Bubble sort\n",
        "\n",
        "- Repeatedly pass through array, comparing neighbouring pairs of elements and switching them if they are out of order\n",
        "\n",
        "- After first pass the largest element is in the rightmost position (largest index)\n",
        "\n",
        "- Second pass can finish before reaching last element, as it is already in place\n",
        "\n",
        "- After second pass final two elements are correctly ordered\n",
        "\n",
        "- Continue until array is sorted\n",
        "\n",
        "- [Animation of bubble sort](https://www.sortvisualizer.com/bubblesort/)\n",
        "\n",
        "---\n"
      ],
      "id": "4da8205e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def bubble_sort(A):\n",
        "    \"Sort A and return\"\n",
        "    A = A.copy()\n",
        "    n = len(A)\n",
        "    while n > 0:\n",
        "        for i in range(n - 1):\n",
        "            # Swap data if in wrong order\n",
        "            if A[i] > A[i + 1]:\n",
        "                A[i + 1], A[i] = A[i], A[i + 1]\n",
        "        n = n - 1\n",
        "\n",
        "    return A"
      ],
      "id": "f43e5ece",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "What is complexity of bubble sort? \n",
        "\n",
        "- There are two nested loops: one to implement each pass and one to loop over the $n-1$ passes\n",
        "\n",
        "- Suggests that complexity is quadratic i.e. $O(n^2)$. A numerical check verifies this:\n",
        "\n",
        "---\n"
      ],
      "id": "4c262eef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Code for plot\"\n",
        "# Create array of problem sizes we want to test (powers of 2)\n",
        "N = 2**np.arange(2, 10)\n",
        "\n",
        "# Create an array of random numbers\n",
        "x = np.random.rand(N[-1])\n",
        "\n",
        "# Time bubble sort on arrays of different lengths  \n",
        "times = []\n",
        "for n in N:\n",
        "    t = %timeit -q -n2 -r2 -o bubble_sort(x[:n])\n",
        "    times.append(t.best)\n",
        "\n",
        "# Plot bubble sort timing\n",
        "plt.loglog(N, times, marker='o', label='bubble sort')\n",
        "\n",
        "# Show reference line of O(n^2)\n",
        "plt.loglog(N, 1e-6*N**2, label='$O(n^2)$')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('$n$')\n",
        "plt.ylabel('$t$ (s)')\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.show()"
      ],
      "id": "c46b46e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "- If you watch the [animation of bubble sort](https://www.sortvisualizer.com/bubblesort/) you might get a bit bored, as it _slowly_ carries the next largest element to the end\n",
        "\n",
        "- Can we do better? \n",
        "\n",
        "---\n",
        "\n",
        "- How fast _could_ a sorting algorithm be? \n",
        "\n",
        "- Can't be faster than $O(n)$: at the very least one has to look at each element\n",
        "\n",
        "- While one can't actually achieve linear scaling, many algorithms which achieve the next best thing: $O(n\\log n)$\n",
        "\n",
        "---\n",
        "\n",
        "## Quicksort\n",
        "\n",
        "- Uses two key ideas:\n",
        "\n",
        "    1. Possible in $O(n)$ steps to partition an array into those elements larger (or equal) and those elements smaller than a given value (called the _pivot_).\n",
        "    2. Acting recursively on each partition requires only $O(\\log n)$ partitions to completely sort array\n",
        "\n",
        "---\n"
      ],
      "id": "f12cedb8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "def quicksort(A, lo=0, hi=None):\n",
        "    \"Sort A and return sorted array\"\n",
        "\n",
        "    # Initialise data the first time function is called    \n",
        "    if hi is None:\n",
        "        hi = len(A) - 1\n",
        "        A = A.copy()\n",
        "\n",
        "    # Sort    \n",
        "    if lo < hi:\n",
        "        p = partition(A, lo,  hi)\n",
        "        quicksort(A, lo, p - 1)\n",
        "        quicksort(A, p + 1, hi)\n",
        "    return A\n",
        "\n",
        "\n",
        "def partition(A, lo, hi):\n",
        "    \"Partitioning function for use in quicksort\"\n",
        "    pivot = A[hi]\n",
        "    i = lo\n",
        "    for j in range(lo,  hi):\n",
        "        if A[j] <= pivot:\n",
        "            A[i], A[j] = A[j], A[i]\n",
        "            i += 1\n",
        "    A[i], A[hi] = A[hi], A[i]\n",
        "    return i"
      ],
      "id": "18bc0c5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- See [this discussion](https://en.wikipedia.org/wiki/Quicksort#Lomuto_partition_scheme) of the partitioning scheme for more\n",
        "\n",
        "---\n"
      ],
      "id": "ba6453ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create array of problem sizes we want to test (powers of 2)\n",
        "N = 2**np.arange(2, 14)\n",
        "\n",
        "# Create an array of random numbers\n",
        "x = np.random.rand(N[-1])\n",
        "\n",
        "# Time quicksort on arrays of different lengths\n",
        "times = []\n",
        "for n in N:\n",
        "    t = %timeit -n1 -r1 -o -q quicksort(x[:n])\n",
        "    times.append(t.best)\n",
        "\n",
        "# Plot quicksort timings\n",
        "plt.loglog(N, times, marker='o', label='quicksort')\n",
        "\n",
        "# Show reference line of O(n*log(n))\n",
        "plt.loglog(N, 1e-6*N*np.log(N), label='$O(n\\log\\, n)$')\n",
        "\n",
        "# Add labels\n",
        "plt.xlabel('$n$')\n",
        "plt.ylabel('$t$ (s)')\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.show()"
      ],
      "id": "c61ddef0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "- Interesting example of differences between best, worst and average case complexities\n",
        "\n",
        "    1. Best case: $O(n\\log n)$\n",
        "    2. Worst case: $O(n^2)$\n",
        "    3. Average case: $O(n\\log n)$\n",
        "\n",
        "- Worst case occurs when the array is _already sorted_\n",
        "\n",
        "- Pivot is chosen as the last element of the array, so one partition is always empty in this case\n",
        "\n",
        "- Instead of problem being cut roughly in half at each stage, it is only reduced in size by 1\n",
        "\n",
        "---\n",
        "\n",
        "NumPy's `sort` uses quicksort, whereas Python's `sorted` uses a hybrid algorithm called [Timsort](https://en.wikipedia.org/wiki/Timsort), which also has $O(n\\log n)$ average case performance\n"
      ],
      "id": "800cbf79"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create array of problem sizes we want to test (powers of 2)\n",
        "N = 2**np.arange(2, 14)\n",
        " \n",
        "# Create an array of random numbers, and make read-only so we don't accidentally sort it    \n",
        "x = np.random.rand(N[-1])\n",
        "x.flags.writeable = False\n",
        "\n",
        "# Time the different implementations\n",
        "py_times = []\n",
        "np_times = []\n",
        "for n in N:\n",
        "    # Time Python built-in sort\n",
        "    t = %timeit -n3 -q -o sorted(x[:n])\n",
        "    py_times.append(t.best)\n",
        "\n",
        "    # Time NumPy sort\n",
        "    t = %timeit -n3 -q -o np.sort(x[:n], kind='quicksort')\n",
        "    np_times.append(t.best)\n",
        "\n",
        "\n",
        "# Plot time taken for built-in sort\n",
        "plt.loglog(N, py_times, marker='o', label='Python (timsort)')\n",
        "plt.loglog(N, np_times, marker='o', label='NumPy (quicksort)')\n",
        "\n",
        "# Show reference lines of O(n*log(n)) and  O(n^2)\n",
        "plt.loglog(N, 1e-6*N*np.log(N), '--', label=r'$O(n\\log n)$')\n",
        "plt.loglog(N, 1e-6*N**2, '--', label=r'$O(n^2$)')\n",
        "\n",
        "# Show legend\n",
        "plt.legend(loc=0);\n",
        "\n",
        "# Add label and legend\n",
        "plt.xlabel('$n$')\n",
        "plt.ylabel('$t$ (s)')\n",
        "\n",
        "plt.show()"
      ],
      "id": "b1f4075b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Divide and conquer  \n",
        "\n",
        "- Quicksort, binary search, and exponentiation by squaring are all examples of [divide and conquer algorithms](https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm)\n",
        "\n",
        "- Achieve performance by breaking task into two (or more) sub-problems of same type\n",
        "\n",
        "---\n",
        "\n",
        "## Karatsuba algorithm\n",
        "\n",
        "- Recall \"obvious\" method for multiplication has quadratic complexity\n",
        "\n",
        "- Try a divide and conquer type approach by splitting an $n$-digit number as follows\n",
        "$$\n",
        "x = x_1 B^m + x_0\n",
        "$$\n",
        "- $B$ is base and $m=\\lceil n / 2\\rceil$ works best (as we'll see)\n",
        "\n",
        "- In base 10 $x=12345$ is written as $12 * 1000 + 345$\n",
        "\n",
        "---\n",
        "\n",
        "- Do this for two  $n$-digit numbers $x$ and $y$, then\n",
        "\n",
        "$$\n",
        "xy = x_1 y_1 B^{2m} + (x_1 y_0 + x_0 y_1) B^{m} + x_0 y_0,\n",
        "$$\n",
        "\n",
        "- Requires computation of four products\n",
        "\n",
        "- Now divide and conquer, splitting up $x_0$, $x_1$, $y_0$, $y_1$ in the same way\n",
        "\n",
        "-  Continues to a depth of $\\sim\\log_2 n$ until we end up with single digit numbers. What's the complexity?\n",
        "\n",
        "$$\n",
        "4^{\\log_2 n} = n^2\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "- So we gained nothing by being fancy! \n",
        "\n",
        "- _But_ Karatsuba noticed that since\n",
        "$$\n",
        "x_1 y_0 + x_0 y_1 = (x_1 + x_0)(y_1 + y_0) - x_y y_0 - x_1 y_1\n",
        "$$\n",
        "you can in fact get away with _three_ multiplications instead of four (together with some additions)\n",
        "\n",
        "- Divide and conquer approach; end up with complexity\n",
        "\n",
        "$$\n",
        "3^{\\log_2 n} = n^{\\log_2 3} \\approx n^{1.58}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- Simple example from Leetcode\n",
        "\n",
        "Analaysis of algorithms\n",
        "\n",
        "Example of finding a unique item in list\n",
        "\n",
        "Breadth first and depth first\n",
        "\n",
        "Importance of choosing a data structure to match algorithm\n",
        "\n",
        "Examples: queue in Wolff. Was there a Numpy-ish way to do this faster? Priority queue in waiting time algo\n",
        "\n",
        "FFT uses\n",
        "\n",
        "https://en.wikipedia.org/wiki/Orthogonal_frequency-division_multiplexing\n",
        "\n",
        "Needleman-Wunsch \n",
        "\n",
        "Examples\n",
        "\n",
        "1. Multiplication [Karatsuba](https://en.wikipedia.org/wiki/Multiplication_algorithm#Karatsuba_multiplication)\n",
        "\n",
        "3. Linear algebra\n",
        "5. FFT\n",
        "7. Euclidean algorithm (GCD) (SICP)\n",
        "\n",
        "References. Nature of computation, grokking algos\n",
        "\n",
        "Insertion in a list etc. -->\n",
        "\n",
        "<!-- # Space vs. time complexity -->"
      ],
      "id": "f36c0433"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}