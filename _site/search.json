[
  {
    "objectID": "exercises/exercises.html",
    "href": "exercises/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "There are four computing exercises to be completed in the last four weeks of full Lent term; one per week. The exercises count for 0.2 units or further work, or roughly 2% of your final mark for the year. Thus each exercise should only take you a few hours. Each of the four exercises is marked out of 5 for a total of 20 marks. Marks will be awarded in proportion to the amount of each exercise you successfully complete. Successfully complete means that at the very least the relevant code should run!\n\nFirst exercise: Friday 17th February – Friday 24th February\nSecond exercise: Friday 24th February – Friday 3rd March\nThird exercise: Friday 3rd March – Friday 10th March\nFourth exercise: Friday 10th March – Friday 17th March (last day of full Lent term)\n\nYou will receive a link to the exercise via email on the first day before noon (i.e. Friday 17th February for the first exercise). The deadline for every exercise is 12 noon on the final day (i.e. Friday 24th February for the first exercise).\n\n1 How to submit\nYou will be using GitHub classroom to submit your work, so you will need a GitHub account if you don’t already have one.\nIf you’ve never used GitHub before, you can try out the starter course. On clicking this link you will be asked to pick your identifier (CRSid) in order to join the classroom. Let me know if your id is missing.\nEach week I will email you a link to a new exercise. Once you accept the assignment, GitHub will create a repository called &lt;exercise-name&gt;-&lt;your-username&gt; in the Part-II-Computational-Physics organization on GitHub. This repository will contain the exercise description. Please change the name of the repo to &lt;exercise-name&gt;-&lt;CRSid&gt; for ease of marking. Only you and the course admins (the demonstrators and me) can see this repo.\nNote that there is no explicit “submit” button. You submit your work by making changes (“commits”) to the repository on GitHub (if you make commits to a copy of the repository on your computer, you must “push” them to GitHub). You can make as many commits as you like up until the deadline. Note that you can continue to add commits to the repo after the deadline, but only the last commit before the deadline is counted as the submission.\nPlease use the discussions section to ask questions to your demonstrators (about the exercises) and me (about everything else). Treat the discussions as if they are a real life examples class where others can learn from your questions and the answers to them.\nIf you’re using VS Code, there is a GitHub Classroom extension that allows you to view, work on, and submit assignments directly within the editor.\n\n\n2 First exercise: PDEs\nThe first exercise concerns solving a simple PDE using different methods. Your demonstrator for this exercise is Nathan Magnan, a PhD student from DAMTP.\n\n\n3 Second exercise: exact diagonalization\nThe second exercise is about using some of the linear algebra techniques from the linear algebra lecture to study spin chains. Your demonstrator is Jonathan Hallén, a PhD student from TCM. You can read about some of Joanthan’s recent research here.\n\n\n4 Third exercise: Monte Carlo\nThe third exercise is about Monte Carlo techniques applied to the Ising model. You demonstrator is Danny van der Haven, a PhD student from Materials Science.\n\n\n5 Fourth exercise: automatic differentiation\nThe fourth exercise is about using automatic differentiation to train a simple neural network. Your demonstrator is Cecilie Glittum, a PhD student from TCM.",
    "crumbs": [
      "Exercises and Projects",
      "Exercises"
    ]
  },
  {
    "objectID": "notes/numpy.html",
    "href": "notes/numpy.html",
    "title": "NumPy and friends",
    "section": "",
    "text": "The NumPy package is the key building block of the Python scientific ecosystem.\nIn this chapter we introduce a few of the key concepts. You should refer to the documentation for details. As with any mature software ecosystem, you should first assume that what you want to achieve can be achieved in a highly optimised way within the existing framework, and only resort to creating your own solution if and when you satisfy yourself that this is not the case.\nThere are a huge number of resources for learning NumPy online. Here are a couple of good ones:",
    "crumbs": [
      "Notes",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "notes/numpy.html#example-playing-with-images",
    "href": "notes/numpy.html#example-playing-with-images",
    "title": "NumPy and friends",
    "section": "6.1 Example: playing with images",
    "text": "6.1 Example: playing with images\nPixels in an image are encoded as a triple of RGB values in the range [0,255] i.e. 8 bits of type uint8 (the “u” is for “unsigned”). Tinting an image gives us a nice example of broadcasting\n\nimg = plt.imread('../assets/lucian.jpeg')\n\nimg_tinted = img * [1, 0.55, 1]\n\n# Show the original image\nplt.subplot(1, 2, 1)\nplt.imshow(img)\nplt.title(\"Lucian\")\n\n# Show the tinted image\nplt.subplot(1, 2, 2)\nplt.title(\"Pink Panther\")\n# Having multiplied by floats, \n# we must cast the image to uint8 before displaying it.\nplt.imshow(np.uint8(img_tinted))\n\nplt.show()\nimg.shape, img.dtype\n\n\n\n\n\n\n\n\n((4032, 3024, 3), dtype('uint8'))\n\n\nThis is a standard 12 megapixel image.",
    "crumbs": [
      "Notes",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "notes/fourier.html",
    "href": "notes/fourier.html",
    "title": "Fast Fourier transform",
    "section": "",
    "text": "You’ve met Fourier in the context of Fourier series, where a periodic function is represented as an infinite series, and Fourier transforms, where a non-periodic function is represented as an integral. Both representations are infinite, involving all the points on a real interval or an infinite number of terms in a series, so not really suitable for representation on a computer. For that we need a third thing: the discrete Fourier transform (DFT). After defining it, we’ll see there is a divide and conquer type algorithm for calculating it efficiently called the fast Fourier transform (FFT), which opened up an enormous number of applications across science and engineering.",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#ntoinfty-limit",
    "href": "notes/fourier.html#ntoinfty-limit",
    "title": "Fast Fourier transform",
    "section": "1.1 \\(N\\to\\infty\\) limit",
    "text": "1.1 \\(N\\to\\infty\\) limit\nIn this limit the \\(\\eta_n\\) values become dense in the range \\((-\\pi,\\pi]\\), with separation \\(\\Delta \\eta = 2\\pi/N\\), and we replace the sum in the inverse DFT Equation 3 by an integral according to the prescription \\[\n\\sum_{n=0}^{N-1} \\left(\\cdots\\right) \\xrightarrow{N\\to\\infty} N \\int_{0}^{2\\pi} \\frac{d\\eta}{2\\pi}\\left(\\cdots\\right),\n\\] giving \\[\nf_j = \\int_{0}^{2\\pi} \\frac{d\\eta}{2\\pi}\\,F(\\eta) e^{i\\eta j}.\n\\]",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#ntoinfty-with-f_j-fjln",
    "href": "notes/fourier.html#ntoinfty-with-f_j-fjln",
    "title": "Fast Fourier transform",
    "section": "1.2 \\(N\\to\\infty\\) with \\(f_j = f(jL/N)\\)",
    "text": "1.2 \\(N\\to\\infty\\) with \\(f_j = f(jL/N)\\)\nAlternatively, regard the \\(N\\to\\infty\\) limit as sampling a function \\(f(x)\\) ever more finely in the range (0,L]. Now it’s the DFT, rather than the inverse, that becomes an integral \\[\n\\hat f(k) \\equiv \\int_0^L f(x) e^{-ik_n x}\\,dx,\n\\] where \\(k_n =2\\pi n/L\\). Note that \\(k_n x = \\eta_n j\\). The pair of transformations is now \\[\n\\begin{align}\n\\hat f_k &= \\int_0^L f(x) e^{-ik_n x}\\,dx\\nonumber\\\\\nf(x) &= \\frac{1}{L}\\sum_k \\hat f_k e^{ik_n x}\n\\end{align}\n\\tag{4}\\] This is the conventional form of the Fourier series for a function with period \\(L\\).\nWith this definition \\(\\hat f_k\\) has an extra dimension of distance (on account of the integral), which gets removed by the \\(1/L\\) in the inverse transform.\nThe analog of the identity Equation 2 is \\[\n\\frac{1}{L}\\sum_k e^{ik x} = \\delta_L(x),\n\\] where \\(\\delta_L(x)\\) is an \\(L\\)-periodic version of the \\(\\delta\\)-function.",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#ltoinfty",
    "href": "notes/fourier.html#ltoinfty",
    "title": "Fast Fourier transform",
    "section": "1.3 \\(L\\to\\infty\\)",
    "text": "1.3 \\(L\\to\\infty\\)\nFinally we arrive at the Fourier transform, where we take \\(L\\to\\infty\\), so that the inverse transform in Equation 4 becomes an integral too \\[\n\\begin{align}\n\\hat{f}(k) & = \\int_{-\\infty}^\\infty f(x) e^{-ik_n x}\\,dx\\nonumber\\\\\nf(x) &= \\int_{-\\infty}^\\infty \\hat f(k) e^{ik_n x}\\,\\frac{dk}{2\\pi}.\n\\label{coll_FTTrans}\n\\end{align}\n\\]",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#sec-properties",
    "href": "notes/fourier.html#sec-properties",
    "title": "Fast Fourier transform",
    "section": "1.4 Some important properties",
    "text": "1.4 Some important properties\nHere are some properties that hold for all of the above.\n\nIf \\(f_j\\) is real then \\(F_n = \\left[F_{-n}\\right]^*\\).\nIf \\(f_j\\) is even (odd) 2 , \\(F_n\\) is even (odd).\n(Ergo) if \\(f_j\\) is real and even, so is \\(F_n\\).",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#higher-dimensions",
    "href": "notes/fourier.html#higher-dimensions",
    "title": "Fast Fourier transform",
    "section": "1.5 Higher dimensions",
    "text": "1.5 Higher dimensions\nThe DFT generalizes to higher dimensions straightforwardly. Suppose we have data living in \\(d\\) dimensions with \\(N_i\\) datapoints along dimension \\(i=1,\\dots d\\), then the DFT is \\[\nF_{\\mathbf{n}} = \\sum_{\\mathbf{n}} f_\\mathbf{j}e^{-i \\boldsymbol{\\eta}_\\mathbf{n}\\cdot \\mathbf{j}},\n\\] where \\(\\mathbf{j}=(j_1,\\ldots j_{d})\\) with \\(j_i = 0,\\ldots N_i - 1\\) and likewise \\(\\boldsymbol{\\eta}_\\mathbf{n} = 2\\pi (n_1 / N_1, \\ldots n_d/ N_d)\\) \\(n_i = 0,\\ldots N_i - 1\\)",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#complexity",
    "href": "notes/fourier.html#complexity",
    "title": "Fast Fourier transform",
    "section": "2.1 Complexity",
    "text": "2.1 Complexity\nIt should be clear that the FFT is going to beat the naive approach, but let’s analyze the complexity more carefully. If \\(T(N)\\) is time (or number of steps) required to compute the DFT for size \\(N\\) inputs, then calculating \\(F^\\text{e}_{n'}\\) and \\(F^\\text{0}_{n'}\\) takes time \\(2T(N/2)\\). Using Equation 5 to evaluate \\(F_n\\) is a further \\(N\\) steps, so we have 3\n\\[\nT(N) = 2T(N/2) +\\alpha N\n\\]\nfor some \\(\\alpha\\). This implies \\(T(N)=\\Theta(N\\log N)\\).\nWhat happens when \\(N\\) isn’t a power of 2? You can still use the divide and conquer strategy for any other factor \\(p\\) of \\(N\\). If the largest prime factor of \\(N\\) is bounded i.e. doesn’t grow with \\(N\\) 4, then this still yields \\(T(N)=\\Theta(N\\log N)\\). If \\(N\\) is prime you have to use something else.\nAs a practical matter it’s probably best to try and ensure that \\(N\\) is a power of two e.g. by choosing the size of your simulation appropriately or padding your data with zeros until its length is a power of 2.",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#history",
    "href": "notes/fourier.html#history",
    "title": "Fast Fourier transform",
    "section": "2.2 History",
    "text": "2.2 History\nThe modern invention of the FFT is credited to Cooley and Tukey (1965). Certainly they were the first to discuss its complexity. The divide and conquer approach was however anticipated by Danielson and Lanczos (1942), who had applications in crystallography in mind, and by unpublished work of Carl Friedrich Gauss in 1805 (predating even Fourier) in his astronomical studies. See Cooley, Lewis, and Welch (1967) for more on the historical background.",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#fft-in-python",
    "href": "notes/fourier.html#fft-in-python",
    "title": "Fast Fourier transform",
    "section": "2.3 FFT in Python",
    "text": "2.3 FFT in Python\nAs usual, you don’t have to go implementing this yourself. The FFT is available in both NumPy (in the numpy.fft module) and SciPy (in scipy.fft), the latter with a more comprehensive set of functions.\nEquation 1 and Equation 3 are the default definitions used in these modules, though you should always check the conventions used in any library implementation. The NumPy documentation provides a careful discussion of the positive and negative frequency components and there are several helper functions available to make your life easier, such as:\n\nnp.fft.fftfreq(n, d), which returns the frequencies (not the angular frequencies) for input size \\(n\\) and sample spacing \\(d\\).\nnp.fft.fftshift(A) shifts data so that the zero frequency is in the centre.\nnp.fft.ifftshift(A) inverts this.\n\nHere are some simple examples of their use, applied to a very simple signal consisting of two sinusoids at 12 Hz and 34 Hz:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\ndt=0.01\nfftsize=256\nt=np.arange(fftsize)*dt\n#Generate some fake data at 12 Hz and 34 Hz\ny=np.cos(2*np.pi*12*t)+0.5*np.sin(2*np.pi*34*t)\nplt.plot(t,y)\nplt.xlabel(\"Time\")\n\nText(0.5, 0, 'Time')\n\n\n\n\n\n\n\n\n\nNow we can take the FFT and plot vs array index, or against the real frequency (with the given sample spacing of \\(dt=0.01\\))\n\nY=np.fft.fft(y)\n# Plot FFT modulus versus array index\nplt.subplot(2,1,1); plt.plot(abs(Y))\n# Now use the correct frequency coordinates\nf=np.fft.fftfreq(fftsize, dt)\n# Reordering makes a tidier plot...\nY=np.fft.fftshift(Y)\nf=np.fft.fftshift(f)\nplt.subplot(2,1,2); plt.plot(f, abs(Y))\nplt.xlabel(\"Frequency / Hz\")\nplt.show()\n\n\n\n\n\n\n\n\nAs we discussed in Section 1.4, the Fourier transform of real valued data has the property \\(F_n = \\left[F_{-n}\\right]^*\\):\n\nplt.subplot(2,1,1); plt.plot(f,Y.real)\nplt.subplot(2,1,2); plt.plot(f,Y.imag)\nplt.xlabel(\"Frequency / Hz\")\nplt.show()",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#windowing",
    "href": "notes/fourier.html#windowing",
    "title": "Fast Fourier transform",
    "section": "2.4 Windowing",
    "text": "2.4 Windowing\nNote that, even though our signal consists of just a pair of sinusoids, the FFT does not just consist of \\(\\delta\\)-functions, which is more obvious on a log-scale:\n\nplt.magnitude_spectrum(y, Fs=100, scale='dB')\nplt.show()\n\n\n\n\n\n\n\n\nThe reason, as you may guess from your knowledge of Fourier transforms, is that our data is of finite length. This windowing causes the FFT to have non-zero values outside the frequencies present in the signal, a phenomenon called spectral leakage. In our case a sharp window means that the FFT is effectively convolved with the Fourier transform of a top hat function i.e. a sinc function. If the window happens to contain a whole number of wavelengths of the signals present, spectral leakage does not occur.\nThe effects of windowing can be mitigated by choosing different window functions — with smooth edges for example — to multiply our data, depending on what you are looking for. The rectangular / top hat window has low dynamic range: it is not great at distinguishing contributions of different amplitude even when their frequencies differ, as leakage from the large peak may obscure the other, smaller ones. On the other hand it has high resolution, meaning that it is good at resolving peaks of similar amplitude that are close in frequency. Expect to be presented with several options (Hamming, Tukey (him again), etc.) when using library functions that perform spectral analysis.\n\n\n\nImportance of windowing LIGO data, from Abbott et al. (2020). Without appropriate windowing, the entire power spectrum is dominated by spectral leakage following a \\(1/f^2\\) scaling.",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#signal-processing",
    "href": "notes/fourier.html#signal-processing",
    "title": "Fast Fourier transform",
    "section": "3.1 Signal processing",
    "text": "3.1 Signal processing\nAs an example, let’s look at some of the stages in the analysis of time series data from the LIGO and Virgo experiments on gravitational wave detection that led to the 2017 Nobel prize in physics. I’m following Abbott et al. (2020) closely here, and you should check it out for further details, as well as the accompanying notebook that describes how the analysis is performed in Python.\nAs illustrated in Figure 1 uncovering the signal in the raw data involves a number of processing steps designed to eliminate noise, mostly carried out in the Fourier domain. The guiding principle is that the noise is stationary — meaning that it is described by a random process that does not change in time — while the signal is transient. This idea can be used to reduce noise in the data even though low frequency noise completely dominates the raw measurement (top panel).\n\n\n\n\n\n\nFigure 1: Stages in the analysis of LIGO strain data,from Abbott et al. (2020). Note the scale on the \\(y\\)-axis!\n\n\n\nThe first step is windowing, which we have already discussed, designed to reduce spectral leakage. Next, the data is whitened, meaning that the Fourier spectrum is normalized by the spectral density (the power spectrum is made to resemble the power spectrum of white noise) \\[\n\\tilde d(f)\\longrightarrow \\frac{\\tilde d(f)}{S_n^{1/2}(f)}.\n\\]\nThe idea behind this step is to prevent high amplitude noise in certain parts of the spectrum from swamping the signal. After this step (third panel, red trace), the low frequency noise has been greatly reduced.\nFinally, the data are bandpass filtered with a pass band [35 Hz, 350 Hz], which removes low frequency seismic noise and high frequency (quantum) noise from the detector. Filtering is the Fourier analog of windowing i.e. multiplying by a function to discard certain parts of the signal. At this point, a transient is revealed in the data (bottom panel).\nThe next step is to fit this transient with a model that describes the graviational wave physics. An important check on the correctness of this approach is to then analyze the residual — the difference between the data and the model — and to check whether it is described by a stationary noise process (see Figure 2). In such a process the phases of the Fourier components are random and uncorrelated, for example.\n\n\n\n\n\n\nFigure 2: Residuals from the modelled signal, from Abbott et al. (2020)\n\n\n\nHopefully this short summary has emphasized the vital role played throughout by the processing of signals in the Fourier domain, and therefore the importance of the FFT in analyzing time series data.",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#partial-differential-equations",
    "href": "notes/fourier.html#partial-differential-equations",
    "title": "Fast Fourier transform",
    "section": "3.2 Partial differential equations",
    "text": "3.2 Partial differential equations\nWe’ll illustrate the role of the FFT in the numerical solution of partial differential equations (PDEs) using one that you all know well: the time-dependent Schrödinger equation\n\\[\ni\\hbar \\frac{\\partial \\psi}{\\partial t} = -\\frac{\\hbar^2}{2m}\\nabla^2 \\psi + V(\\mathbf{r})\\psi.\n\\tag{6}\\]\nWhen the potential is absent, the solutions are plane waves\n\\[\n\\Psi(\\mathbf{r}, t) = \\exp\\left[-i\\frac{\\hbar^2 \\mathbf{k}^2 t}{2m} +i\\mathbf{k}\\cdot\\mathbf{r}\\right].\n\\tag{7}\\]\nOn the other hand, if the first term on the right hand side of Equation 6 — representing the kinetic energy — were absent, then the evolution of the wavefunction would be\n\\[\n\\Psi(\\mathbf{r}, t) = \\Psi(\\mathbf{r}, 0)\\exp\\left[-iV(\\mathbf{r})t/\\hbar\\right].\n\\tag{8}\\]\nThe idea behind the split-step method is that the time evolution can be approximated by alternating the two kinds of time evolution represented by Equation 7 and Equation 8. In more formal terms, write Equation 6 in operator form as\n\\[\ni\\hbar \\frac{\\partial \\ket{\\psi}}{\\partial t} = H\\ket{\\psi} = (T+V)\\ket{\\psi}\n\\]\nThe solution is \\(\\ket{\\psi(t)} = \\exp(-iHt/\\hbar)\\ket{\\psi}(0)\\). The exponential of an operator sum \\(A+B\\) obeys the Lie product formula\n\\[\ne^{A+B} = \\lim_{n\\to\\infty}\\left( e^{A/n}e^{B/n}\\right)^n.\n\\]\nThe logic behind this formula is that when the exponent is small, the failure of \\(A\\) and \\(B\\) to commute can be neglected. More precisely, \\[\ne^{xA}e^{xB} = e^{x(A+B) + O(x^2)}.\n\\]\nIt turns out that a more accurate approximation is given by the Suzuki—Trotter formula\n\\[\ne^{xA/2}e^{xB}e^{xA/2} = e^{x(A+B) + O(x^3)}.\n\\]\nIn any case, the practical algorithm suggested by these formulas is implemented for the Schrödinger equation by switching between real space and Fourier space, where the two kinds of evolution are implemented. Here’s a simple 1D example:\n\ndef split_step_schrodinger(psi_0, dx, dt, V, N, x_0 = 0., k_0 = None, m = 1.0, non_linear = False):\n\n    len_x = psi_0.shape[0]\n\n    x = x_0 + dx*np.arange(len_x)\n\n    dk_x = (2*np.pi)/(len_x*dx)\n    if k_0 == None:\n        k_0 = -np.pi/dx\n    k_x = k_0+dk_x*np.arange(len_x)\n\n    psi_x = np.zeros((len_x,N), dtype = np.complex128)\n    psi_k = np.zeros((len_x,N), dtype = np.complex128)\n    psi_mod_x = np.zeros((len_x), dtype = np.complex128)\n    psi_mod_k = np.zeros((len_x), dtype = np.complex128)\n    psi_x[:,0] = psi_0\n\n    if not non_linear:\n        V_n = V(x)\n    else:\n        V_n = V(x,psi_0)\n\n    def _compute_psi_mod(j):\n        return (dx/np.sqrt(2*np.pi))*psi_x[:,j]*np.exp(-1.0j*k_x[0]*x)\n\n    def _compute_psi(j):\n        psi_x[:,j] = (np.sqrt(2*np.pi)/dx)*psi_mod_x*np.exp(1.0j*k_x[0]*x)\n        psi_k[:,j] = psi_mod_k*np.exp(-1.0j*x[0]*dk_x*np.arange(len_x))\n\n    def _x_half_step(j,ft = True):\n        if ft == True:\n            psi_mod_x[:] = np.fft.ifft(psi_mod_k[:])\n        if non_linear:\n            V_n[:] = V(x,psi_x[:,j])\n        psi_mod_x[:] = psi_mod_x[:]*np.exp(-1.0j*(dt/2.)*V_n)   \n\n    def _k_full_step():\n        psi_mod_k[:] = np.fft.fft(psi_mod_x[:])\n        psi_mod_k[:] = psi_mod_k[:]*np.exp(-1.0j*k_x**2*dt/(2.*m))      \n\n    def _main_loop():\n        psi_mod_x[:] = _compute_psi_mod(0)\n\n        for i in range(N-1):\n            _x_half_step(i,ft = False)\n            _k_full_step()\n            _x_half_step(i)\n            _compute_psi(i+1)\n\n    _main_loop()\n\n    return psi_x,psi_k,k_x\n\n\ndef oneD_gaussian(x,mean,std,k0):\n    return np.exp(-((x-mean)**2)/(4*std**2)+ 1j*x*k0)/(2*np.pi*std**2)**0.25\n\ndef V(x):\n    V_x = np.zeros_like(x)\n    V_x[np.where(abs(x) &lt; 0.5)] = 1.5\n    return V_x\n\n\nN_x = 2**11\ndx = 0.05\nx = dx * (np.arange(N_x) - 0.5 * N_x)\n\ndt = 0.01\nN_t = 2000\n\np0 = 2.0\nd = np.sqrt(N_t*dt/2.)\n\npsi_0 = oneD_gaussian(x,x.max()-10.*d, d, -p0)\n\npsi_x,psi_k,k = split_step_schrodinger(psi_0, dx, dt, V, N_t, x_0 = x[0])\n\n\n\nAnimation code\nfrom matplotlib.animation import FuncAnimation\n\nreal_psi = np.real(psi_x)\nimag_psi = np.imag(psi_x)\nabsl_psi = np.absolute(psi_x)\nabs_psik = np.absolute(psi_k)\n\nfig = plt.figure(figsize = (10,10))\nax1 = plt.subplot(211)\nline1_R = ax1.plot(x,real_psi[:,0],'b')[0]\nline1_I = ax1.plot(x,imag_psi[:,0],'r')[0]\nline1_A = ax1.plot(x,absl_psi[:,0],'k')[0]\nline_V = ax1.plot(x,0.5*V(x),'k',alpha=0.5)[0]\nax1.set_ylim((real_psi.min(),real_psi.max()))\nax1.set_xlim((x.min(),x.max()))\n\nax2 = plt.subplot(212)\nline2 = ax2.plot(k,abs_psik[:,1],'k')[0]\nax2.set_ylim((abs_psik.min(),abs_psik.max()))\nax2.set_xlim((-10,10))\n\ndef nextframe(arg):\n    line1_R.set_data(x,real_psi[:,10*arg])\n    line1_I.set_data(x,imag_psi[:,10*arg])\n    line1_A.set_data(x,absl_psi[:,10*arg])\n    line2.set_data(k,abs_psik[:,10*arg])\n    \nanimate = FuncAnimation(fig, nextframe, frames = int(N_t/10), interval = 50, repeat = False)\nplt.show()\n\n\n\n\nVideo\n(top) Wavepacket colliding with a top hat barrier. Black line is the modulus, while red and blue are the real and imaginary parts. (bottom) Absolute value of the Fourier transform",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/fourier.html#footnotes",
    "href": "notes/fourier.html#footnotes",
    "title": "Fast Fourier transform",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOrthonormality follows from Equation 2.↩︎\nwith respect to the middle of the data.↩︎\nStrictly we should write \\(T(N) = 2T(N/2) +\\Theta(N)\\), where \\(f(N)=\\Theta(g(N))\\) means \\(\\lim_{N\\to \\infty} \\frac{f(N)}{g(N)}\\) is a finite nonzero number. Thus \\(\\Theta(N)\\) means “proportional to \\(N\\) in the large \\(N\\) limit”.↩︎\nSuch numbers are called smooth.↩︎",
    "crumbs": [
      "Notes",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "notes/complexity.html",
    "href": "notes/complexity.html",
    "title": "Algorithms and computational complexity",
    "section": "",
    "text": "How hard is it to multiply numbers? The bigger they are, the harder it is, as you well know. You also know that computers are very good at multiplying, so once you’ve switched from multiplying numbers yourself to multiplying them on a computer, you may well be tempted to forget about how hard it is. Nevertheless, computers find big numbers harder than small numbers. How much harder?\nIf you remember how you learnt to multiply numbers at school, it probably went something like this: 1\n\nMultiplying two 3 digit numbers\n\n\n\n\n\n\n\n\n\n\n×\n1\n3\n2\n2\n3\n1\n\n\n\n\n_\n_\n3\n_\n2\n6\n1\n4\n9\n2\n6\n3\n\n\n3\n9\n4\n8\n3\n\n\n\nFor \\(n\\) digits we have to perform \\(n^2\\) single digit multiplications. We then have to add together the \\(n\\) resulting \\(n\\)-digit numbers. This is another \\(n^2\\) operations. Thus the overall number of operations is proportional to \\(n^2\\): doubling the number of digits will make the problem four times harder.\nExactly how long this takes to perform in your head or on a computer will depend on many things, such as how long it takes you to multiply two digits, or get the previous values out of memory (or read them of the page), but you can’t get away from the basic quadratic scaling law of this algorithm.",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#best-worst-average",
    "href": "notes/complexity.html#best-worst-average",
    "title": "Algorithms and computational complexity",
    "section": "2.1 Best / worst / average",
    "text": "2.1 Best / worst / average\nEven when we focus on a problem in the above sense we still have to be careful in defining the complexity of an algorithm. In general we can characterize three complexities: best case, worse case, and average case. To see the difference between these three consider search, the very simple problem of finding an item in an (unordered) list of length \\(n\\). How hard is this? You have to check every item until you find the one you are looking for, so this suggests the complexity is \\(O(n)\\). You could be lucky and get it first try, however, or within the first ten tries. This means the best case complexity of search is \\(O(1)\\): it doesn’t increase with the size of the problem. The worst thing that could happen is that the sought item is last: the worst case complexity is \\(O(n)\\). On average, you’ll find your item in the middle of the list on attempt \\(\\sim n/2\\), so the average case complexity is \\(O(n/2)\\). But this is the same as \\(O(n)\\) (constants don’t matter)\nThus for linear search we have:\n\n\n\n\nComplexity\n\n\n\n\nBest case\n\\(O(1)\\)\n\n\nWorst case\n\\(O(n)\\)\n\n\nAverage case\n\\(O(n)\\)\n\n\n\nWe can check the average case performance experimentally by using randomly chosen lists: 2\n\ndef linear_search(x, val):\n    \"Return True if val is in x, otherwise return False\"\n    for item in x:\n        if item == val:\n            return True\n    return False\n\n\nimport numpy as np\n# Create array of problem sizes n we want to test (powers of 2)\nN = 2**np.arange(2, 20)\n\n# Generate the array of integers for the largest problem to use in plotting times\nx = np.arange(N[-1])\n\n# Initialise an empty array to stores times for plotting\ntimes = []\n\n# Time the search for each problem size\nfor n in N:\n\n    # Time search function (repeating 3 times) to find a random integer in x[:n]\n    t = %timeit -q -n4 -r1 -o linear_search(x[:n], np.random.randint(0, n))\n\n    # Store best case time (best on a randomly chosen problem)\n    times.append(t.best)\n\n\n\nCode for plot\nimport matplotlib.pyplot as plt\n# Plot and label the time taken for linear search\nplt.loglog(N, times, marker='o')\nplt.xlabel('$n$')\nplt.ylabel('$t$ (s)')\n\n# Show a reference line of O(n)\nplt.loglog(N, 1e-6*N, label='$O(n)$')\n\n# Add legend\nplt.legend(loc=0)\nplt.title(\"Experimental complexity of linear search\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\nThe “experimental noise” in these plots arises because we don’t have full control over exactly what our computer is doing at any moment: there are lots of other processes running. Also, it takes a while to reach the linear regime: there is an overhead associated with starting the program that represents a smaller fraction of the overall run time as \\(n\\) increases.",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#polynomial-complexity",
    "href": "notes/complexity.html#polynomial-complexity",
    "title": "Algorithms and computational complexity",
    "section": "2.2 Polynomial complexity",
    "text": "2.2 Polynomial complexity\nSince you’ve already learnt a lot of algorithms in mathematics (even if you don’t think of them this way) it’s very instructive to revisit them through the lens of computational complexity.\nMultiplying a \\(n\\)-dimensional vector by a \\(n\\times n\\) matrix?\n\\[\n\\begin{align}\n\\sum_{j=1}^n M_{ij}v_j\n\\end{align}\n\\]\nThe sum contains \\(n\\) terms, and we have to perform \\(n\\) such sums. Thus the complexity of this operation is \\(O(n^2)\\).\nLikewise, multiplying two \\(n\\times n\\) matrices\n\\[\n\\sum_{j} A_{ij}B_{jk}\n\\]\ninvolves \\(n\\) terms for each of the \\(n^2\\) assignments of \\(i\\) and \\(k\\). Complexity: \\(O(n^3)\\)\nThus, if you have to calculate something like \\(M_1 M_2\\cdots M_n \\mathbf{v}\\), you should not calculate the matrix products first, but instead do it like this\n\\[\nM_1\\left(M_2\\cdots \\left(M_n \\mathbf{v}\\right)\\right)\n\\]\nWikipedia has a nice summary of computational complexity of common mathematical operations.\nIf an algorithm has complexity \\(O(n^p)\\) for some \\(p\\) it is generally described as having polynomial complexity. A useful heuristic (which is not 100% reliable) is that if you have \\(p\\) nested loops that range over \\(\\sim n\\), the complexity is \\(O(n^p)\\) (think how you would implement matrix-vector and matrix-matrix multiplication).",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#better-than-linear",
    "href": "notes/complexity.html#better-than-linear",
    "title": "Algorithms and computational complexity",
    "section": "2.3 Better than linear?",
    "text": "2.3 Better than linear?\nIt seems obvious that for search you can’t do better than linear: you have to look at roughly half the items before you should expect to find the one you’re looking for 3. What if the list is ordered? Any order will do: numerical for numbers, or lexicographic for strings. This extra structure allows us to use an algorithm called binary search that you may have seen before 4. The idea is pretty intuitive: look in the middle of the list and see if the item you seek should be in the top half or bottom half. Take the relevant half and divide it in half again to determine which quarter of the list your item is in, and so on. Here’s how it looks in code:\n\ndef binary_search(x, val):\n    \"\"\"Peform binary search on x to find val. If found returns position, otherwise returns None.\"\"\"\n\n    # Intialise end point indices\n    lower, upper = 0, len(x) - 1\n\n    # If values is outside of interval, return None \n    if val &lt; x[lower] or val &gt; x[upper]:\n        return None\n\n    # Perform binary search\n    while True:\n                \n        # Compute midpoint index (integer division)\n        midpoint = (upper + lower)//2\n\n        # Check which side of x[midpoint] val lies, and update midpoint accordingly\n        if val &lt; x[midpoint]:\n            upper = midpoint - 1\n        elif val &gt; x[midpoint]:\n            lower = midpoint + 1\n        elif val == x[midpoint]:  # found, so return\n            return midpoint\n       \n        # In this case val is not in list (return None)\n        if upper &lt; lower:\n            return None\n\nAnd here’s the performance\n\n\nCode for plot\n# Create array of problem sizes we want to test (powers of 2)\nN = 2**np.arange(2, 24)\n\n# Creat array and sort\nx = np.arange(N[-1])\nx = np.sort(x)\n\n# Initlise an empty array to capture time taken\ntimes = []\n\n# Time search for different problem sizes\nfor n in N:\n    # Time search function for finding '2'\n    t = %timeit -q -n5 -r2 -o binary_search(x[:n], 2)\n\n    # Store average\n    times.append(t.best)\n\n# Plot and label the time taken for binary search\nplt.semilogx(N, times, marker='o')\nplt.xlabel('$n$')\nplt.ylabel('$t$ (s)')\n\n# Change format on y-axis to scientific notation\nplt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\nplt.title(\"Experimental complexity of binary search\")\nplt.show()\n\n\n\n\n\n\n\n\n\nNote the axes: the plot is linear-log, so the straight line indicates logarithmic growth of complexity. This makes sense: if the length is a power of 2 i.e. \\(n=2^p\\), we are going to need \\(p\\) bisections to locate our value. The complexity is \\(O(\\log n)\\) (we don’t need to specify the base as overall constants don’t matter).\nHere’s another example of logarithm scaling. Exponentiation is the problem of raising a number \\(b\\) (the base) to the \\(n\\)th power. The obvious way is to multiply the number by itself \\(n\\) times. Linear scaling, right? But there’s a quicker way, since\n\\[\n\\begin{align}\nb^2 &= b\\cdot b\\\\\nb^4 &= b^2\\cdot b^2\\\\\nb^4 &= b^4\\cdot b^4\n\\end{align}\n\\]\nWe only have to do three multiplications! Exponentiation by this method (called exponentiation by squaring) is \\(O(\\log n)\\). To handle powers that aren’t a power of \\(2\\), we do the following\n\\[\nb^n = \\begin{cases}\n    b^{n/2} \\cdot b^{n/2} & \\text{if $n$ even} \\\\\n    b \\cdot b^{n-1} & \\text{if $n$ odd}\n\\end{cases}\n\\]\nHere’s a way to implement this in code.\n\ndef exp(b, n):\n    if n == 0:\n        return 1\n    elif n % 2 == 0:\n        return exp(b, n // 2)**2\n    else:\n        return b * exp(b, n - 1) \n\nexp(2, 6)\n\n64\n\n\nThis implementation is recursive: the function exp(b, n) calls itself. If this seems a bit self-referential, notice that it only calls itself with lower values of the exponent \\(n\\). This process continues until we hit \\(n=0\\), and 1 is returned by the first part of the if ... else. Any recursive function has to have such a base case to avoid an infinite regress. You’ll know if you haven’t provided one correctly:\n\ndef exp_no_base_case(b, n):\n    if n % 2 == 0:\n        return exp_no_base_case(b, n // 2)**2\n    else:\n        return b * exp_no_base_case(b, n - 1) \n\nexp_no_base_case(2, 6)\n\nRecursionError: maximum recursion depth exceeded in comparison\n\n\nOne interesting thing about exponentiation is that while it can be done efficiently, the inverse — finding the logarithm — cannot. To make this more precise one has to work with modular arithmetic e.g. do all operations modulo some prime number \\(p\\). Then for \\(b, y=0,\\ldots p-1\\) we are guaranteed that there is some number \\(x\\) such that \\(b^x=y\\) (this is called the discrete logarithm). Finding this number is hard: there is no known method for computing it efficiently. Certain public-key cryptosystems are based on the difficulty of the discrete log (for carefully chosen \\(b\\), \\(p\\) and \\(y\\)).",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#exponential-complexity",
    "href": "notes/complexity.html#exponential-complexity",
    "title": "Algorithms and computational complexity",
    "section": "2.4 Exponential complexity",
    "text": "2.4 Exponential complexity\nWhile we’re on the subject of recursion, here’s an example that’s often used to introduce the topic: calculating the Fibonacci numbers. Remember that the Fibonacci numbers are this sequence\n\\[\n0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233 ...\n\\]\nwhere each new term is obtained by adding together the previous two\n\\[\n\\text{Fib}(n) = \\text{Fib}(n-1) + \\text{Fib}(n-2)\n\\]\nThe fact that the value \\(\\text{Fib}(n)\\) is defined in terms of lower values of \\(n\\) makes a recursive definition possible\n\ndef fib(n):\n    if n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fib(n - 1) + fib(n - 2)\n\nfib(13)\n\n233\n\n\nThe first two terms are the base cases (we need two because the recursion refers to two earlier values). While this looks quite cool it’s actually a terrible way of calculating \\(\\text{Fib}(n)\\). Look at the picture below which illustrates the function calls that are made during the evaluation of \\(\\text{Fib}(5)\\). There are huge amounts of duplication!\n\n\n\nThe recursive tree for calculating Fibonacci numbers. Source: SICP\n\n\nThe complexity of this algorithm actually grows exponentially with \\(n\\). Because of the branching structure the algorithm is \\(O(2^n)\\). Calculating the Fibonacci number the sensible way (i.e. the way you do it in your head) gives an \\(O(n)\\) algorithm. Formalizing this approach gives rise to the matrix recurrence relation:\n\\[\n\\begin{pmatrix}\n\\text{Fib}(n+2) \\\\\n\\text{Fib}(n+1)\n\\end{pmatrix} =\n\\begin{pmatrix}\n1 & 1 \\\\\n1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n\\text{Fib}(n+1) \\\\\n\\text{Fib}(n)\n\\end{pmatrix}.\n\\]\nThis suggests an even better way of calculating the Fibonacci numbers, since\n\\[\n\\begin{pmatrix}\n\\text{Fib}(n+1) \\\\\n\\text{Fib}(n)\n\\end{pmatrix} =\n\\begin{pmatrix}\n1 & 1 \\\\\n1 & 0\n\\end{pmatrix}^n\n\\begin{pmatrix}\n1 \\\\\n0\n\\end{pmatrix},\n\\]\nfinding the \\((n+1)\\)th number involves the \\(n\\)th power of a matrix. But now we could use exponentiation by squaring, yielding an \\(O(\\log n)\\) algorithm!\nIt would be nice if exponential complexity were only ever the result of poor choices of algorithm. Unfortunately, this is not the case. It’s possible to come up with problems that definitely can’t be solved faster than exponentially: the Towers of Hanoi is one famous example. Closer to the hearts of physicists, the simulation of a quantum system with \\(n\\) qubits (a qubit — or quantum bit — is just a computer sciencey word for a spin-1/2) is believed to have complexity \\(O(2^n)\\), which is a big part of the hype surrounding quantum computers.\nThere are problems whose solution, once found, is easy to check. The discrete logarithm we mentioned above is one example. Checking involves exponentiation, and exponentiation is \\(O(\\log n)\\) in the size of the numbers, or \\(O(n)\\) in the number of digits. The question of whether efficient (i.e. polynomial) algorithms always exist for problems which are easy to check is in fact the outstanding problem in computer science: it’s called P vs NP, where P is the class of problems with polynomial time algorithms and NP is the class whose solution can be checked in polynomial time. The question is: are these two classes the same or do they differ? That is, are there problems in NP that aren’t in P? I think it’s fair to say that most people with an opinion on the matter think so, but the proof is lacking (and worth a million dollars).",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#bubble-sort",
    "href": "notes/complexity.html#bubble-sort",
    "title": "Algorithms and computational complexity",
    "section": "3.1 Bubble sort",
    "text": "3.1 Bubble sort\nThis one is very simple: repeatedly pass through the array, comparing neighbouring pairs of elements and switching them if they are out of order. After the first pass the largest element is in the rightmost position (largest index). That means the second pass can finish before reaching the last element, as we know that it is already in place. After the second pass the final two elements are correctly ordered. Continue in this way, stopping one place earlier each time, until the array is sorted.\nHere’s a simple implementation: 5\n\ndef bubble_sort(A):\n    \"Sort A and return\"\n    A = A.copy()\n    n = len(A)\n    while n &gt; 0:\n        for i in range(n - 1):\n            # Swap data if in wrong order\n            if A[i] &gt; A[i + 1]:\n                A[i + 1], A[i] = A[i], A[i + 1]\n        n = n - 1\n\n    return A\n\nWhat is the complexity of this algorithm? From the code we can see immediately that there are two nested loops: one to implement each pass and one to loop over the \\(n-1\\) passes. This suggests that the complexity is quadratic i.e. \\(O(n^2)\\). A numerical check verifies this:\n\n\nCode for plot\n# Create array of problem sizes we want to test (powers of 2)\nN = 2**np.arange(2, 10)\n\n# Create an array of random numbers\nx = np.random.rand(N[-1])\n\n# Time bubble sort on arrays of different lengths  \ntimes = []\nfor n in N:\n    t = %timeit -q -n2 -r2 -o bubble_sort(x[:n])\n    times.append(t.best)\n\n# Plot bubble sort timing\nplt.loglog(N, times, marker='o', label='bubble sort')\n\n# Show reference line of O(n^2)\nplt.loglog(N, 1e-6*N**2, label='$O(n^2)$')\n\n# Add labels and legend\nplt.xlabel('$n$')\nplt.ylabel('$t$ (s)')\nplt.legend(loc=0)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nIf you watch the animation of bubble sort you might get a bit bored, as it slowly carries the next largest element to the end. Can we do better?",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#quicksort",
    "href": "notes/complexity.html#quicksort",
    "title": "Algorithms and computational complexity",
    "section": "3.2 Quicksort",
    "text": "3.2 Quicksort\nYes! It turns out that there are number of algorithms that do considerably better than quadratic. How fast could a sorting algorithm be? It’s clear that it can’t be faster than \\(O(n)\\): at the very least one has to look at each element. While one can’t actually achieve linear scaling, there are many algorithms which achieve the next best thing: \\(O(n\\log n)\\).\nQuicksort is one such algorithm. It uses two key ideas:\n\nIt is possible in \\(O(n)\\) steps to partition an array into those elements larger (or equal) and those elements smaller than a given value (called the pivot).\nActing recursively on each partition requires only \\(O(\\log n)\\) partitions to completely sort the array.\n\nHere’s an implementation. See this discussion of the partitioning scheme for more information.\n\ndef quicksort(A, lo=0, hi=None):\n    \"Sort A and return sorted array\"\n\n    # Initialise data the first time function is called    \n    if hi is None:\n        hi = len(A) - 1\n        A = A.copy()\n\n    # Sort    \n    if lo &lt; hi:\n        p = partition(A, lo,  hi)\n        quicksort(A, lo, p - 1)\n        quicksort(A, p + 1, hi)\n    return A\n\n\ndef partition(A, lo, hi):\n    \"Partitioning function for use in quicksort\"\n    pivot = A[hi]\n    i = lo\n    for j in range(lo,  hi):\n        if A[j] &lt;= pivot:\n            A[i], A[j] = A[j], A[i]\n            i += 1\n    A[i], A[hi] = A[hi], A[i]\n    return i\n\nAnd here’s a demonstration of the \\(O(n\\log n)\\) performance\n\n\nCode for plot\n# Create array of problem sizes we want to test (powers of 2)\nN = 2**np.arange(2, 14)\n\n# Create an array of random numbers\nx = np.random.rand(N[-1])\n\n# Time quicksort on arrays of different lengths\ntimes = []\nfor n in N:\n    t = %timeit -n1 -r1 -o -q quicksort(x[:n])\n    times.append(t.best)\n\n# Plot quicksort timings\nplt.loglog(N, times, marker='o', label='quicksort')\n\n# Show reference line of O(n*log(n))\nplt.loglog(N, 1e-6*N*np.log(N), label='$O(n\\log\\, n)$')\n\n# Add labels\nplt.xlabel('$n$')\nplt.ylabel('$t$ (s)')\nplt.legend(loc=0)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nQuicksort provides an interesting example of the differences between best, worst and average case complexities. They are:\n\nBest case: \\(O(n\\log n)\\)\nWorst case: \\(O(n^2)\\)\nAverage case: \\(O(n\\log n)\\)\n\nFunnily enough, the worst case occurs when the array is already sorted. Because the pivot is chosen as the last element of the array, one of the partitions is always empty. Thus, instead of the problem being cut roughly in half at each stage, it is merely reduced in size by 1.\nNumPy’s sort uses quicksort, whereas Python’s sorted uses a hybrid algorithm called Timsort, which also has \\(O(n\\log n)\\) average case performance.\n\n\nCode for plot\n# Create array of problem sizes we want to test (powers of 2)\nN = 2**np.arange(2, 14)\n \n# Create an array of random numbers, and make read-only so we don't accidentally sort it    \nx = np.random.rand(N[-1])\nx.flags.writeable = False\n\n# Time the different implementations\npy_times = []\nnp_times = []\nfor n in N:\n    # Time Python built-in sort\n    t = %timeit -n3 -q -o sorted(x[:n])\n    py_times.append(t.best)\n\n    # Time NumPy sort\n    t = %timeit -n3 -q -o np.sort(x[:n], kind='quicksort')\n    np_times.append(t.best)\n\n\n# Plot time taken for built-in sort\nplt.loglog(N, py_times, marker='o', label='Python (timsort)')\nplt.loglog(N, np_times, marker='o', label='NumPy (quicksort)')\n\n# Show reference lines of O(n*log(n)) and  O(n^2)\nplt.loglog(N, 1e-6*N*np.log(N), '--', label=r'$O(n\\log n)$')\nplt.loglog(N, 1e-6*N**2, '--', label=r'$O(n^2$)')\n\n# Show legend\nplt.legend(loc=0);\n\n# Add label and legend\nplt.xlabel('$n$')\nplt.ylabel('$t$ (s)')\n\nplt.show()",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/complexity.html#footnotes",
    "href": "notes/complexity.html#footnotes",
    "title": "Algorithms and computational complexity",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSticking with integers↩︎\nI’ve borrowed this example from Garth Wells’ course↩︎\nGrover’s algorithm for search has \\(O(\\sqrt{n})\\) complexity, but there’s a catch: you need a quantum computer, and even then a \\(\\sqrt{n}\\) speedup is not going to get you a billion dollars in this economy.↩︎\nNot everyone has↩︎\nI’ve borrowed these implementations from Garth Wells’ excellent lectures↩︎",
    "crumbs": [
      "Notes",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "notes/numbers.html",
    "href": "notes/numbers.html",
    "title": "Floating point and all that",
    "section": "",
    "text": "Since physics is all about numbers we had better develop some understanding of how computers represent them, and the limitations of this representation. Hopefully this example is sufficiently motivating:\n0.1  + 0.2 == 0.3\n\nFalse\nAh…",
    "crumbs": [
      "Notes",
      "Floating point and all that"
    ]
  },
  {
    "objectID": "notes/numbers.html#sec-fp-numpy",
    "href": "notes/numbers.html#sec-fp-numpy",
    "title": "Floating point and all that",
    "section": "2.1 Floating point numbers in NumPy",
    "text": "2.1 Floating point numbers in NumPy\nIf this all a bit theoretical you can just get NumPy’s finfo function to tell all about the machine precision\n\nnp.finfo(np.float64)\n\nfinfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)\n\n\nNote that \\(2^{-52}=2.22\\times 10^{-16}\\) which accounts for the value \\(10^{-15}\\) of the resolution. This can be checked by finding when a number is close enough to treated as 1.0.\n\nx=1.0\nwhile 1.0 + x != 1.0:\n    x /= 1.01 \nprint(x)\n\n1.099427563084686e-16\n\n\nFor binary32 we have a resolution of \\(10^{-6}\\).\n\nnp.finfo(np.float32)\n\nfinfo(resolution=1e-06, min=-3.4028235e+38, max=3.4028235e+38, dtype=float32)\n\n\nOne lesson from this is that taking small differences between numbers is a potential source of rounding error, as in this somewhat mean exam question\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSolution: \\(x-x'=x(1-\\gamma^{-1})\\sim x\\beta^2/2\\sim 4.2\\text{mm}\\).\n\nimport numpy as np\nfrom scipy.constants import c\nbeta = 384400e3 / (76 * 3600) / c\ngamma = 1/np.sqrt(1 - beta**2)\nprint(1 - np.float32(1/gamma), 1 - np.float64(1/gamma))\n\n0.0 1.0981660025777273e-11",
    "crumbs": [
      "Notes",
      "Floating point and all that"
    ]
  },
  {
    "objectID": "notes/numbers.html#the-dreaded-nan",
    "href": "notes/numbers.html#the-dreaded-nan",
    "title": "Floating point and all that",
    "section": "2.2 The dreaded NaN",
    "text": "2.2 The dreaded NaN\nAs well as a floating point system, IEEE 754 defines Infinity and NaN (Not a Number)\n\nnp.array([1, -1, 0]) / 0\n\n/var/folders/xs/y8sn45v943s2_62flnxw0p940000gn/T/ipykernel_38352/2604490398.py:1: RuntimeWarning:\n\ndivide by zero encountered in true_divide\n\n/var/folders/xs/y8sn45v943s2_62flnxw0p940000gn/T/ipykernel_38352/2604490398.py:1: RuntimeWarning:\n\ninvalid value encountered in true_divide\n\n\n\narray([ inf, -inf,  nan])\n\n\nThey behave as you might guess\n\n2 * np.inf, 0 * np.inf, np.inf &gt; np.nan\n\n(inf, nan, False)\n\n\nNaNs propagate through subsequent operations\n\n2 * np.nan\n\nnan\n\n\nwhich means that if you get a NaN somewhere in your calculation, you’ll probably end up seeing it somewhere in the output (which is the idea).",
    "crumbs": [
      "Notes",
      "Floating point and all that"
    ]
  },
  {
    "objectID": "notes/getting-going.html",
    "href": "notes/getting-going.html",
    "title": "Getting going",
    "section": "",
    "text": "Everyone finds their own workflow for coding, depending on their preferred language, editor, how they run their code, and so on. The aim of the sections below is to give a roundup of some popular tools in the Python ecosystem.",
    "crumbs": [
      "Notes",
      "Getting going"
    ]
  },
  {
    "objectID": "notes/getting-going.html#footnotes",
    "href": "notes/getting-going.html#footnotes",
    "title": "Getting going",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a conservative estimate↩︎",
    "crumbs": [
      "Notes",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#integers",
    "href": "slides/numbers-and-odes.html#integers",
    "title": "Part II Computational Physics",
    "section": "Integers",
    "text": "Integers\n\nSomething simpler\n\n\n1 + 1 == 2\n\nTrue\n\n\n\nIntegers can be represented in binary\n\n\n3 == 0b11 # Ooctal `0o` or hexadecimal `0h`\n\nTrue\n\n\n\nBinary string representation using bin function\n\n\nbin(-2)\n\n'-0b10'",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#floating-point-numbers",
    "href": "slides/numbers-and-odes.html#floating-point-numbers",
    "title": "Part II Computational Physics",
    "section": "Floating point numbers",
    "text": "Floating point numbers\n\n\\(0.1 + 0.2 \\neq 0.3\\) in Python is that specifying a real number exactly would involve an infinite number of bits\nAny finite representation necessarily approximate\nRepresentation for reals is called floating point arithmetic\nEssentially scientific notation\n\n\\[\\text{significand}  \\times \\text{exponent}\n\\]\n\nNamed floating point because number of digits after decimal point not fixed",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#sec-fp-numpy",
    "href": "slides/numbers-and-odes.html#sec-fp-numpy",
    "title": "Part II Computational Physics",
    "section": "Floating point numbers in NumPy",
    "text": "Floating point numbers in NumPy\n\nNumPy’s finfo function tells all machine precision\n\n\nnp.finfo(np.float64)\n\nfinfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)\n\n\n\nNote that \\(2^{-52}=2.22\\times 10^{-16}\\) which accounts for resolution \\(10^{-15}\\)\nThis can be checked by finding when a number is close enough to treated as 1.0.\n\n\nx=1.0\nwhile 1.0 + x != 1.0:\n    x /= 1.01 \nprint(x)\n\n1.099427563084686e-16",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#the-dreaded-nan",
    "href": "slides/numbers-and-odes.html#the-dreaded-nan",
    "title": "Part II Computational Physics",
    "section": "The dreaded NaN",
    "text": "The dreaded NaN\n\nAs well as a floating point system, IEEE 754 defines Infinity and NaN (Not a Number)\n\n\nnp.array([1, -1, 0]) / 0\n\narray([ inf, -inf,  nan])\n\n\n\nThey behave as you might guess\n\n\n2 * np.inf, 0 * np.inf, np.inf &gt; np.nan\n\n(inf, nan, False)",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#eulers-method",
    "href": "slides/numbers-and-odes.html#eulers-method",
    "title": "Part II Computational Physics",
    "section": "Euler’s method",
    "text": "Euler’s method\n\\[\n\\frac{dx}{dt} = f(x, t)\n\\]\n\nSimplest approach: approximate LHS of ODE\n\n\\[\n\\frac{dx}{dt}\\Bigg|_{t=t_j} \\approx \\frac{x_{j+1} - x_j}{h}\n\\]\n\\[\nx_{j+1} = x_j + hf(x_j, t_j)\n\\]",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#using-scipy",
    "href": "slides/numbers-and-odes.html#using-scipy",
    "title": "Part II Computational Physics",
    "section": "Using SciPy",
    "text": "Using SciPy\n\nComing up with integration schemes is best left to the professionals\nTry integrate module of the SciPy library\nscipy.integrate.solve_ivp provides a versatile API",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/numbers-and-odes.html#hénonheiles-system",
    "href": "slides/numbers-and-odes.html#hénonheiles-system",
    "title": "Part II Computational Physics",
    "section": "Hénon–Heiles system",
    "text": "Hénon–Heiles system\n\nModel chaotic system with origins in stellar dynamics\n\n\\[\n\\begin{align}\n\\dot x &= p_x \\\\\n\\dot p_x &= -x -2\\lambda xy \\\\\n\\dot y &= p_y \\\\\n\\dot p_y &=  - y -\\lambda(x^2-y^2).\n\\end{align}\n\\]\n\nExample of Hamilton’s equations\nPhase space is now four dimensional and impossible to visualize.",
    "crumbs": [
      "Slides",
      "Floating point and ODEs"
    ]
  },
  {
    "objectID": "slides/fourier.html#the-discrete-fourier-transform",
    "href": "slides/fourier.html#the-discrete-fourier-transform",
    "title": "Part II Computational Physics",
    "section": "The discrete Fourier transform",
    "text": "The discrete Fourier transform\n\nChange of basis in a finite dimensional space\nMps signal sampled at \\(N\\) regularly spaced time points to representation at \\(N\\) frequency points \\[\nF_n = \\sum_{j=0}^{N-1} f_j e^{-i\\eta_n j}\n\\] \\(\\eta_n\\equiv \\frac{2\\pi n}{N}\\)\n\\(F_n\\) contain same information as \\(f_j\\), and \\(f_j\\) can be recovered completely by inverting operation",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#ntoinfty-limit",
    "href": "slides/fourier.html#ntoinfty-limit",
    "title": "Part II Computational Physics",
    "section": "\\(N\\to\\infty\\) limit",
    "text": "\\(N\\to\\infty\\) limit\n\n\\(\\eta_n\\) values become dense in range \\((-\\pi,\\pi]\\), with separation \\(\\Delta \\eta = 2\\pi/N\\)\nReplace sum in IDFT integral according to: \\[\n\\sum_{n=0}^{N-1} \\left(\\cdots\\right) \\xrightarrow{N\\to\\infty} N \\int_{0}^{2\\pi} \\frac{d\\eta}{2\\pi}\\left(\\cdots\\right)\n\\] \\[\nf_j = \\int_{0}^{2\\pi} \\frac{d\\eta}{2\\pi}\\,F(\\eta) e^{i\\eta j}\n\\]",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#ntoinfty-with-f_j-fjln",
    "href": "slides/fourier.html#ntoinfty-with-f_j-fjln",
    "title": "Part II Computational Physics",
    "section": "\\(N\\to\\infty\\) with \\(f_j = f(jL/N)\\)",
    "text": "\\(N\\to\\infty\\) with \\(f_j = f(jL/N)\\)\n\n\\(N\\to\\infty\\) limit samples \\(f(x)\\) ever more finely in range (0,L]\nNow DFT becomes an integral \\[\n\\hat f(k) \\equiv \\int_0^L f(x) e^{-ik_n x}\\,dx,\n\\] where \\(k_n =2\\pi n/L\\). Note that \\(k_n x = \\eta_n j\\). \\[\n\\begin{align}\n\\hat f_k &= \\int_0^L f(x) e^{-ik_n x}\\,dx\\nonumber\\\\\nf(x) &= \\frac{1}{L}\\sum_k \\hat f_k e^{ik_n x}\n\\end{align}\n\\]",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#ltoinfty",
    "href": "slides/fourier.html#ltoinfty",
    "title": "Part II Computational Physics",
    "section": "\\(L\\to\\infty\\)",
    "text": "\\(L\\to\\infty\\)\n\nFinally Fourier transform, where we take \\(L\\to\\infty\\), so that inverse transform becomes an integral too \\[\n\\begin{align}\n\\hat{f}(k) & = \\int_{-\\infty}^\\infty f(x) e^{-ik_n x}\\,dx\\nonumber\\\\\nf(x) &= \\int_{-\\infty}^\\infty \\hat f(k) e^{ik_n x}\\,\\frac{dk}{2\\pi}\n\\label{coll_FTTrans}\n\\end{align}\n\\]",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#sec-properties",
    "href": "slides/fourier.html#sec-properties",
    "title": "Part II Computational Physics",
    "section": "Some important properties",
    "text": "Some important properties\n\nSome properties of DFT (and all of the above)\n\n\nIf \\(f_j\\) is real then \\(F_n = \\left[F_{-n}\\right]^*\\).\nIf \\(f_j\\) is even (odd), \\(F_n\\) is even (odd).\n(Ergo) if \\(f_j\\) is real and even, so is \\(F_n\\).",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#higher-dimensions",
    "href": "slides/fourier.html#higher-dimensions",
    "title": "Part II Computational Physics",
    "section": "Higher dimensions",
    "text": "Higher dimensions\n\nGeneralizes to higher dimensions straightforwardly\nIf data lives \\(d\\) dimensions with \\(N_i\\) datapoints along dimension \\(i=1,\\dots d\\) \\[\nF_{\\mathbf{n}} = \\sum_{\\mathbf{n}} f_\\mathbf{j}e^{-i \\boldsymbol{\\eta}_\\mathbf{n}\\cdot \\mathbf{j}}\n\\] \\(\\mathbf{j}=(j_1,\\ldots j_{d})\\) with \\(j_i = 0,\\ldots N_i - 1\\) and \\(\\boldsymbol{\\eta}_\\mathbf{n} = 2\\pi (n_1 / N_1, \\ldots n_d/ N_d)\\) \\(n_i = 0,\\ldots N_i - 1\\)",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#complexity",
    "href": "slides/fourier.html#complexity",
    "title": "Part II Computational Physics",
    "section": "Complexity",
    "text": "Complexity\n\nClear that FFT is going to beat the naive approach\n\\(T(N)\\) is steps required to compute DFT for size \\(N\\) input\nCalculating \\(F^\\text{e}_{n'}\\) and \\(F^\\text{0}_{n'}\\) takes time \\(2T(N/2)\\)\nCombining to evaluate \\(F_n\\) is a further \\(N\\) steps, so\n\n\\[\nT(N) = 2T(N/2) +\\Theta(N)\n\\]\n\nThis implies \\(T(N)=\\Theta(N\\log N)\\)",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#history",
    "href": "slides/fourier.html#history",
    "title": "Part II Computational Physics",
    "section": "History",
    "text": "History\n\nModern invention of FFT is credited to Cooley and Tukey (1965). First to discuss complexity\nDivide and conquer approach anticipated by Danielson and Lanczos (1942), for applications in crystallography\nOG is Carl Friedrich Gauss in 1805 (predating even Fourier) in his astronomical studies\nSee Cooley, Lewis, and Welch (1967) for more on historical background",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#fft-in-python",
    "href": "slides/fourier.html#fft-in-python",
    "title": "Part II Computational Physics",
    "section": "FFT in Python",
    "text": "FFT in Python\n\nFFT available in both NumPy (in the numpy.fft module) and SciPy (in scipy.fft), with a more comprehensive set of functions\nOur definitions are the defaults used in these modules (but always check conventions!)",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#simple-example",
    "href": "slides/fourier.html#simple-example",
    "title": "Part II Computational Physics",
    "section": "Simple example",
    "text": "Simple example\n\nSignal consisting of two sinusoids at 12 Hz and 34 Hz:",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#windowing",
    "href": "slides/fourier.html#windowing",
    "title": "Part II Computational Physics",
    "section": "Windowing",
    "text": "Windowing\n\nSignal a pair of sinusoids, but FFT not just \\(\\delta\\)-functions\n\n\n\n\n\n\n\n\n\n\n\nBecause data is of finite length",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#signal-processing",
    "href": "slides/fourier.html#signal-processing",
    "title": "Part II Computational Physics",
    "section": "Signal processing",
    "text": "Signal processing\n\nTime series data from LIGO and Virgo experiments on gravitational wave detection that led to the 2017 Nobel prize in physics\nSee Abbott et al. (2020) for details, as well as accompanying notebook that describes how analysis is performed in Python",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#partial-differential-equations",
    "href": "slides/fourier.html#partial-differential-equations",
    "title": "Part II Computational Physics",
    "section": "Partial differential equations",
    "text": "Partial differential equations\n\nSpectral methods exploit FFT as part of solver\nExample: time-dependent Schrödinger equation\n\n\\[\ni\\hbar \\frac{\\partial \\psi}{\\partial t} = -\\frac{\\hbar^2}{2m}\\nabla^2 \\psi + V(\\mathbf{r})\\psi\n\\]",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/fourier.html#references",
    "href": "slides/fourier.html#references",
    "title": "Part II Computational Physics",
    "section": "",
    "text": "Abbott, Benjamin P, Rich Abbott, Thomas D Abbott, Sheelu Abraham, Fausto Acernese, Kendall Ackley, Carl Adams, et al. 2020. “A Guide to LIGO–Virgo Detector Noise and Extraction of Transient Gravitational-Wave Signals.” Classical and Quantum Gravity 37 (5): 055002.\n\n\nCooley, James W, Peter AW Lewis, and Peter D Welch. 1967. “Historical Notes on the Fast Fourier Transform.” Proceedings of the IEEE 55 (10): 1675–77.\n\n\nCooley, James W, and John W Tukey. 1965. “An Algorithm for the Machine Calculation of Complex Fourier Series.” Mathematics of Computation 19 (90): 297–301.\n\n\nDanielson, Gordon Charles, and Cornelius Lanczos. 1942. “Some Improvements in Practical Fourier Analysis and Their Application to x-Ray Scattering from Liquids.” Journal of the Franklin Institute 233 (5): 435–52.",
    "crumbs": [
      "Slides",
      "Fast Fourier transform"
    ]
  },
  {
    "objectID": "slides/autodiff.html#supervised-learning",
    "href": "slides/autodiff.html#supervised-learning",
    "title": "Part II Computational Physics",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nPurpose of function is to map \\(\\mathbf{x}\\) to output \\(\\mathbf{y}\\) that represents a set of labels\nLabels represent e.g. different kinds of objects that might appear in images \\[\n\\mathbf{y} = \\mathsf{NN}_\\theta(\\mathbf{x})\n\\]\n\\(\\theta\\) are parameters\nIf family of functions is “big enough” then \\(\\exists\\) function that does “good job”",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#the-cost-function",
    "href": "slides/autodiff.html#the-cost-function",
    "title": "Part II Computational Physics",
    "section": "The cost function",
    "text": "The cost function\n\nDataset of size \\(N\\) consisting of data \\(\\mathbf{x}_i=1,\\ldots N\\) together with labels \\(l_i\\)\nEncode labels in vectors \\(\\mathbf{y}_i\\) to be compared with output of the neural network\nPopular choice is one hot encoding. \\(\\mathbf{y}_i\\) is \\(N_L\\) dimensional vector. Label \\(n\\) encoded as \\((0,0,\\ldots, 1, \\ldots, 0)\\), with \\(1\\) in \\(n\\text{th}\\) place",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#using-a-trained-model",
    "href": "slides/autodiff.html#using-a-trained-model",
    "title": "Part II Computational Physics",
    "section": "Using a trained model",
    "text": "Using a trained model\n\nNeed procedure for turning output \\(\\mathsf{NN}_\\theta(\\mathbf{x})\\) — an \\(N_L\\) dimensional vector — into discrete label\nSimplest way is to find the maximum component and predict corresponding label\n\n\\[\nl_* = \\underset{l}{\\operatorname{argmax}} \\left[\\mathsf{NN}_\\theta(\\mathbf{x})\\right]_l\n\\]",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#evaluating-performance",
    "href": "slides/autodiff.html#evaluating-performance",
    "title": "Part II Computational Physics",
    "section": "Evaluating performance",
    "text": "Evaluating performance\n\nStardard protocol: split dataset into training set and test set\nTraining set used for training model; test set for evaluating it\nAfter training model should perform well on training set, but will perform less well on test set\nDifference between cost function evaluated on test set and training set is a measure of how well the model generalizes to new inputs: generalization error",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#overfitting",
    "href": "slides/autodiff.html#overfitting",
    "title": "Part II Computational Physics",
    "section": "Overfitting",
    "text": "Overfitting\n\nParticular risk when using large neural networks with many parameters\nSufficiently flexible model capable of “memorizing” dataset without “understanding”, leading to poor generalization\n\n\n\n\nSource: Wikipeda",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#gradient-descent",
    "href": "slides/autodiff.html#gradient-descent",
    "title": "Part II Computational Physics",
    "section": "Gradient descent",
    "text": "Gradient descent\n\nSimple algorithm underlying training\nCost function is differentiable function of parameters \\(\\theta\\)\nIdea of gradient descent is to take steps “downhill” i.e. in direction \\(-\\mathcal{C}(\\theta)\\) in high dimensional space of all parameters\nEach step corresponds to an update of the parameters\n\n\\[\n\\theta_i\\longrightarrow \\theta'_i = \\theta_i - \\eta \\frac{\\partial\\mathcal{C}}{\\partial \\theta_i}\n\\]\n\n\\(\\eta\\) is hyperparameter called learning rate",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#why-so-simple",
    "href": "slides/autodiff.html#why-so-simple",
    "title": "Part II Computational Physics",
    "section": "Why so simple?",
    "text": "Why so simple?\n\nAll sophistication lies in how model is defined and how gradients are calculated\nNot a trvial task: ChatGPT has 175 billion parameters!\nMany more sophisticated optimization methods, but often involve more information about model’s dependence on parameters\nNewton’s method requires knowledge of first and second derivatives at each step: too costly to evaluate",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#minibatches",
    "href": "slides/autodiff.html#minibatches",
    "title": "Part II Computational Physics",
    "section": "Minibatches",
    "text": "Minibatches\n\nRecall cost defined as average over dataset\n\n\\[\n\\mathcal{C}(\\theta) = \\frac{1}{2N}\\sum_{i=1}^N \\lVert\\mathbf{y}_i-\\mathsf{NN}_\\theta(\\mathbf{x}_i)\\rVert^2\n\\]\n\nFor large datasets of high dimensional data (e.g. images) not practical to calculate gradient of cost using entire dataset\nUsual procedure is to split data up into minibatches\nPerform each step of gradient descent by evaluating gradient only on batch",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#the-network",
    "href": "slides/autodiff.html#the-network",
    "title": "Part II Computational Physics",
    "section": "The network",
    "text": "The network\n\nSo far \\(\\mathsf{NN}_\\theta\\) just a function \\(\\mathsf{NN}_\\theta:\\mathbb{R}^{N_D}\\longrightarrow \\mathbb{R}^{N_L}\\) with lots of parameters \\(\\theta\\)\nWhat is this function, and why is it a “neural network”?",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#defining-fj",
    "href": "slides/autodiff.html#defining-fj",
    "title": "Part II Computational Physics",
    "section": "Defining \\(f^{(j)}\\)",
    "text": "Defining \\(f^{(j)}\\)\n\nShould be simple, but still allow each output component to depend on all input components\n\n\\[\n\\left[f(\\mathbf{x})\\right]_\\alpha = \\phi\\left(\\sum_{\\beta=1}^{N_\\text{in}} w_{\\alpha\\beta}x_\\beta + b_\\alpha\\right),\\qquad \\alpha = 1,\\ldots N_\\text{out}\n\\]\n\n\\(w\\in \\mathbb{R}^{N_\\text{out}\\times N_\\text{in}}\\) are weights; \\(\\mathbf{b}\\in\\mathbb{R}^{N_\\text{out}}\\) are biases\nThese are parameters of this layer: modified during training\n\\(\\phi:\\mathbb{R}\\longrightarrow\\mathbb{R}\\) activation function",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#why-network",
    "href": "slides/autodiff.html#why-network",
    "title": "Part II Computational Physics",
    "section": "Why network?",
    "text": "Why network?\n\\[\nf(\\mathbf{x}) = \\phi(w\\cdot\\mathbf{x} + \\mathbf{b}).\n\\]\n\nRepresented graphically as\n\n\n\n\n\n\n\nFigure 1: Nielsen (2015)",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#why-neural",
    "href": "slides/autodiff.html#why-neural",
    "title": "Part II Computational Physics",
    "section": "Why neural?",
    "text": "Why neural?\n\nLong been used as a model for what goes on in the brain\nMany differences\n\nAbsence of any particular role for time\nReal neural networks are not DAGs!\n\nDAG property plays a decisive role in training of artificial neural networks",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#summary-so-far",
    "href": "slides/autodiff.html#summary-so-far",
    "title": "Part II Computational Physics",
    "section": "Summary so far",
    "text": "Summary so far\n\\[\n\\mathcal{C}(\\theta) = \\frac{1}{2N}\\sum_{i=1}^N \\lVert\\mathbf{y}_i-\\mathsf{NN}_\\theta(\\mathbf{x}_i)\\rVert^2\n\\]\n\\[\n\\theta_i\\longrightarrow \\theta'_i = \\theta_i - \\eta \\frac{\\partial\\mathcal{C}}{\\partial \\theta_i}\n\\]\n\\[\n\\mathsf{NN}_\\theta = f_\\theta^{(L)} \\circ f_\\theta^{(L-1)} \\cdots \\circ f_\\theta^{(2)} \\circ f_\\theta^{(1)}\n\\]",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#automatic-differentiation",
    "href": "slides/autodiff.html#automatic-differentiation",
    "title": "Part II Computational Physics",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\n\nTo perform gradient descent have to calculate \\(\\partial\\mathcal{C}/\\partial \\theta_i\\)\nCan be calculated efficiently, using algorithm called backpropagation\nBackprop an example of automatic differentiation",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#what-ad-is-not",
    "href": "slides/autodiff.html#what-ad-is-not",
    "title": "Part II Computational Physics",
    "section": "What AD is not",
    "text": "What AD is not\n\nOften people guess…\n\n\\[\n\\frac{\\partial\\mathcal{C}}{\\partial \\theta_i} \\approx \\frac{\\mathcal{C}(\\theta_i+\\Delta\\theta_i)- \\mathcal{C}(\\theta_i)}{\\Delta \\theta_i}\n\\tag{1}\\]\n\nBut this is numerical differentiation\nNecessary if you only have access to \\(\\mathcal{C}(\\theta)\\) as a black box function\nAD is different: uses knowledge about how function \\(\\mathcal{C}\\) is formed by composing many simpler functions",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#evaluating-the-derivatives",
    "href": "slides/autodiff.html#evaluating-the-derivatives",
    "title": "Part II Computational Physics",
    "section": "Evaluating the derivatives",
    "text": "Evaluating the derivatives\n\\[\n\\theta = (w^{(1)}, \\mathbf{b}^{(1)},\\ldots, w^{(L)}, \\mathbf{b}^{(L)})\n\\]\n\\[\n\\mathsf{NN}_\\theta = f_{w^{(L)}, \\mathbf{b}^{(L)}}^{(L)} \\circ f_{w^{(L-1)}, \\mathbf{b}^{(L-1)}}^{(L-1)} \\cdots \\circ f_{w^{(2)}, \\mathbf{b}^{(2)}}^{(2)} \\circ f_{w^{(1)}, \\mathbf{b}^{(1)}}^{(1)}\n\\]\n\nDenote input to \\(l\\)th layer as \\[\n\\mathbf{z}^{(l)} \\equiv w^{(l)} \\cdot \\mathbf{x}^{(l)} + \\mathbf{b}^{(l)}\n\\] and the output as \\(\\mathbf{a}^{(l)}\\) (“a” for activation)\n\n\\[\n\\mathbf{a}^{(l)} = \\phi(\\mathbf{z}^{(l)})\n\\]",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#forward-accumulation",
    "href": "slides/autodiff.html#forward-accumulation",
    "title": "Part II Computational Physics",
    "section": "Forward accumulation",
    "text": "Forward accumulation\n\\[\n\\frac{\\partial \\mathsf{NN}_\\theta(\\mathbf{x})}{\\partial \\mathbf{b}^{(l)}} = \\frac{\\partial f^{(L)}}{\\partial \\mathbf{x}^{(L)}}\\cdot \\frac{\\partial f^{(L-1)}}{\\partial \\mathbf{x}^{(L-1)}} \\cdots  \\frac{\\partial f^{(l)}}{\\partial \\mathbf{z}^{(l)}}\n\\]\n\nGo from right to left\nStarting from input \\(\\mathbf{x}\\): evaluate \\(\\mathbf{z}^{(l)}\\)\nOnce we reach \\(f^{(l)}\\) keep track of a matrix as well as \\(\\mathbf{z}^{(l')}\\)\nMatrix is initialized with components \\(\\phi'(\\mathbf{z}^{(l)})\\delta_{jk}\\). Then acted on by each of the Jacobians until we get to the final layer",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#backpropagation",
    "href": "slides/autodiff.html#backpropagation",
    "title": "Part II Computational Physics",
    "section": "Backpropagation",
    "text": "Backpropagation\n\nGo from left to right\nHave to have evaluate and store \\(\\mathbf{z}^{(l')}\\) with \\(l'=1,\\ldots L\\) before we can do anything, as the Jacobians depend on these values\nThis is the forward pass",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#implementation",
    "href": "slides/autodiff.html#implementation",
    "title": "Part II Computational Physics",
    "section": "Implementation",
    "text": "Implementation\n\nPopular libraries include PyTorch, TensorFlow, and Jax\nFun to take a look at how backpropagation is actually implemented in code\nTry micrograd by Andrej Karpathy\nHe also has a YouTube video where he explains it in detail",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/autodiff.html#references",
    "href": "slides/autodiff.html#references",
    "title": "Part II Computational Physics",
    "section": "",
    "text": "Li, Hao, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. 2018. “Visualizing the Loss Landscape of Neural Nets.” Advances in Neural Information Processing Systems 31.\n\n\nNielsen, Michael A. 2015. Neural Networks and Deep Learning. Vol. 25. Determination press San Francisco, CA, USA. http://neuralnetworksanddeeplearning.com.\n\n\nZhang, Chiyuan, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2021. “Understanding Deep Learning (Still) Requires Rethinking Generalization.” Communications of the ACM 64 (3): 107–15.",
    "crumbs": [
      "Slides",
      "Autodiff and neural nets"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#sampling-from-a-distribution",
    "href": "slides/monte-carlo.html#sampling-from-a-distribution",
    "title": "Part II Computational Physics",
    "section": "Sampling from a distribution",
    "text": "Sampling from a distribution\n\nSuppose we have a source of samples of random variable \\(X\\) described by a particular probability density function \\(p_X\\)\nCommon shorthand notation is \\(x\\sim p_X\\)\nBy definition probability of drawing a sample in the region \\([x, x+dx]\\) is \\(p_X(x)dx\\)",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#boxmuller-transform",
    "href": "slides/monte-carlo.html#boxmuller-transform",
    "title": "Part II Computational Physics",
    "section": "Box–Muller transform",
    "text": "Box–Muller transform\n\nTake two independent samples from a standard uniform distribution \\(u_{1,2}\\) and form \\[\n\\begin{align}\nx &= \\sqrt{-2\\log u_1}\\cos(2\\pi u_2)\\\\\ny &= \\sqrt{-2\\log u_1}\\sin(2\\pi u_2).\n\\end{align}\n\\] \\(x\\) and \\(y\\) are independent samples from a standard normal distribution.",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#monte-carlo-integration",
    "href": "slides/monte-carlo.html#monte-carlo-integration",
    "title": "Part II Computational Physics",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\nDumb way to find \\(\\pi\\)\n\nmax_samples = 10000\ninside = 0\nareas = []\nfor sample in range(1, max_samples + 1):\n    x = random.uniform(-1, 1)\n    y = random.uniform(-1, 1)\n    \n    if x ** 2 + y ** 2 &lt;= 1:\n        inside += 1\n    areas.append(4 * inside / sample)\n\nplt.plot(np.arange(1, max_samples + 1), areas)\nplt.plot(np.arange(1, max_samples + 1), np.pi * np.ones(max_samples), linestyle='dashed')\nplt.show()",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#importance-sampling",
    "href": "slides/monte-carlo.html#importance-sampling",
    "title": "Part II Computational Physics",
    "section": "Importance sampling",
    "text": "Importance sampling\n\nIf our function \\(f(\\mathbf{x})\\) has regions where it is very small, there is not much point in sampling its value there\nIf we can sample from a distribution where samples tend to fall in the region where \\(f(\\mathbf{x})\\) is large, it will probably be better to use that",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#sec-mcmc",
    "href": "slides/monte-carlo.html#sec-mcmc",
    "title": "Part II Computational Physics",
    "section": "Markov chain Monte Carlo",
    "text": "Markov chain Monte Carlo\n\nSuppose you want to generate configurations at random (i.e. with a uniform distribution) from a “gas” of hard disks\n\n\n\n\nCoins in a shoe box (gas of hard disks)",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#markov-chains",
    "href": "slides/monte-carlo.html#markov-chains",
    "title": "Part II Computational Physics",
    "section": "Markov chains",
    "text": "Markov chains\nYou know the random walk, perhaps as a model for diffusion\n\nAt each step make a move in a random direction, independently of your earlier moves\nAfter many steps these random moves gives rise to a distribution of possible locations\nA random walk is the simplest example of a Markov chain",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "slides/monte-carlo.html#mcmc-updates-for-the-ising-model",
    "href": "slides/monte-carlo.html#mcmc-updates-for-the-ising-model",
    "title": "Part II Computational Physics",
    "section": "MCMC updates for the Ising model",
    "text": "MCMC updates for the Ising model\n\nSimple proposal: pick each spin in turn in some order and try to flip it.\nForm of \\(p(\\sigma)\\) means that, although we cannot compute the probabilities explicitly, we can calculate ratios\nFor two configurations that differ only by \\(\\sigma_n=\\pm 1\\) we have \\[\n\\begin{align}\n\\frac{p(\\sigma_n=1|\\sigma_{m\\neq n})}{p(\\sigma_n=-1|\\sigma_{m\\neq n})} &= \\exp\\left[-2\\beta \\left(h_n+\\sum_{m\\neq n} J_{mn}\\sigma_m\\right)\\right]\\\\\n&\\equiv \\exp\\left[-\\beta\\Delta \\mathcal{E}\\right]\n\\end{align}\n\\] where \\(\\Delta \\mathcal{E}\\) is the energy difference",
    "crumbs": [
      "Slides",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course outline",
    "section": "",
    "text": "These are the materials for the Part II Physics course Computational Physics, taught in Lent Term 2025 at the University of Cambridge.",
    "crumbs": [
      "Notes",
      "Course outline"
    ]
  },
  {
    "objectID": "index.html#computing-project",
    "href": "index.html#computing-project",
    "title": "Course outline",
    "section": "1.1 Computing Project",
    "text": "1.1 Computing Project\nAdditionally, you may choose to offer a Computational Physics project for one unit of further work. This involves choosing a problem from the project list. You will analyse the problem, write and test Python code to investigate it, then write up your work in a report. \nStudents may start their project work once the project list is published by 17th February. The deadline for submission of the project report is 16:00 on the first Monday of Full Easter term (1st May 2023).",
    "crumbs": [
      "Notes",
      "Course outline"
    ]
  },
  {
    "objectID": "index.html#these-notes",
    "href": "index.html#these-notes",
    "title": "Course outline",
    "section": "4.1 These notes…",
    "text": "4.1 These notes…\n…were prepared using Quarto. Each chapter should be thought of as a Jupyter notebook (actually, they are Jupyter notebooks), so you’ll probably only see import numpy as np once in each chapter, for example.\nThe code used to generate this site is in this GitHub repo. Please use issues to submit any typos and discussions to discuss the content.\nIn several places I’ve used examples from an earlier version of the course by David Buscher.",
    "crumbs": [
      "Notes",
      "Course outline"
    ]
  },
  {
    "objectID": "slides/getting-going.html#goals",
    "href": "slides/getting-going.html#goals",
    "title": "Getting going",
    "section": "Goals",
    "text": "Goals\nIn this course you will learn\n\nAbout the Python scientific stack (based on NumPy)\nIts use in implementing some common algorithms in computational physics\nBasic ideas of computational complexity used in the analysis of algorithms",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#prerequisites",
    "href": "slides/getting-going.html#prerequisites",
    "title": "Getting going",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nAssume a knowledge of the Python language, including variables, control flow, and writing and using functions\nRefer to last year’s IB course (which had an excellent handout)…\n…and of course the internet\nFor an absolutely bare bones intro to Python try the first half of this tutorial",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#computational-physics.tripos.org",
    "href": "slides/getting-going.html#computational-physics.tripos.org",
    "title": "Getting going",
    "section": "computational-physics.tripos.org",
    "text": "computational-physics.tripos.org\n\nLecture notes (in progress)\nThese slides (if you want them)\nCode at github.com/AustenLamacraft/part-ii-computational-physics\nSubmit typos to the GH repo issues and use discussions to discuss…",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#housekeeping",
    "href": "slides/getting-going.html#housekeeping",
    "title": "Getting going",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nEight lectures. Mondays and Fridays at 10.00 in the Pippard\nAfter the lectures: four computing exercises\nTo be completed in the last four weeks of full Lent term; one per week\nExercises count for 0.2 units or further work, or roughly 2% of your final mark for the year\nEach exercise should only take you a few hours.",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#schedule",
    "href": "slides/getting-going.html#schedule",
    "title": "Getting going",
    "section": "Schedule",
    "text": "Schedule\n\nFirst lecture: Monday 23th January\nLast lecture: Friday 17th February\nFirst exercise: Friday 17th February – Friday 24th February\nSecond exercise: Friday 24th February – Friday 3rd March\nThird exercise: Friday 3rd March – Friday 10th March\nFourth exercise: Friday 10th March – Friday 17th March (last day of full Lent term)",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#computing-project",
    "href": "slides/getting-going.html#computing-project",
    "title": "Getting going",
    "section": "Computing Project",
    "text": "Computing Project\n\nYou may choose to offer a Computational Physics project for one unit of further work\nChoose a problem from the project list. Analyse the problem, write and test Python code to investigate it, then write up your work in a report\nProject list is published by 17th February\nDeadline for submission of the project report is 16:00 on the first Monday of Full Easter term (1st May 2023)",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#finding-your-way",
    "href": "slides/getting-going.html#finding-your-way",
    "title": "Getting going",
    "section": "Finding your way",
    "text": "Finding your way\n\nEveryone finds their own workflow for coding (language, editor, etc.)\nThis is a roundup of some popular tools in the Python ecosystem",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#your-coding-environment",
    "href": "slides/getting-going.html#your-coding-environment",
    "title": "Getting going",
    "section": "Your coding environment",
    "text": "Your coding environment\n\nYou will need to install the Python language (or run online)\nI recommend the Anaconda distribution\nComes with all parts of the toolkit we’ll need such as Jupyter notebooks and the major libraries NumPy and SciPy",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#ipython",
    "href": "slides/getting-going.html#ipython",
    "title": "Getting going",
    "section": "IPython",
    "text": "IPython\n\nIf you the above with python nice colour scheme is absent\nThis is called syntax highlighting and provides a visual guide to the syntax of the language\nIPython is an interactive shell that provides syntax highlighting and much more\nIf you have installed IPython (it comes with Anaconda) you can start it from the command line with ipython",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#helpful-features-of-ipython",
    "href": "slides/getting-going.html#helpful-features-of-ipython",
    "title": "Getting going",
    "section": "Helpful features of IPython:",
    "text": "Helpful features of IPython:\n\nTab completion: hit tab to autocomplete. Particularly useful for viewing all properties or methods of an object:\n\n\n\nTyping ?obj or obj? prints detailed information about the object obj (?? provides additional detail)",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#running-a-python-program",
    "href": "slides/getting-going.html#running-a-python-program",
    "title": "Getting going",
    "section": "Running a Python program",
    "text": "Running a Python program\n\nPython code in a file with a .py extension can be run from the command line with\n\npython hello_world.py\nor\npython -m hello_world\n\nIn the latter case -m option tells interpreter to look for a module called hello_world",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#importing-code",
    "href": "slides/getting-going.html#importing-code",
    "title": "Getting going",
    "section": "Importing code",
    "text": "Importing code\n\nA Python module is a file containing definition and statements\nBreaking long code into modules is good practice for writing clear and reusable software\nUsers may not want to see the details of a function in order to be able to us it",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#packages",
    "href": "slides/getting-going.html#packages",
    "title": "Getting going",
    "section": "Packages",
    "text": "Packages\n\nA collection of modules in a folder is called a package\nYou can import a package in the same way and access all the modules using the same . notation i.e. package.module1, package.module2, etc..\nSince explicit namespaces are preferred to avoid ambiguity use shorthands for the package or module you are importing:\n\n\nimport numpy as np\nnp.arange(10)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\n(You can call it what you like, of course!)",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#installing-libraries",
    "href": "slides/getting-going.html#installing-libraries",
    "title": "Getting going",
    "section": "Installing libraries",
    "text": "Installing libraries\n\n99% of the code you run will have been written by somebody else in the form of a library\nPackage installation is handled by the command line utilities pip or conda, the latter being the package manager for the Anaconda distribution\nIf you have NumPy and SciPy installed you won’t need to worry about this too much",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#editors",
    "href": "slides/getting-going.html#editors",
    "title": "Getting going",
    "section": "Editors",
    "text": "Editors\n\nModern editors come with a huge number of tools that make writing code much easier\nSyntax highlighting, code completion, parameter information and documentation popups as you type\nThese go under the general heading IntelliSense\nThe latest hotness is GitHub Copilot: AI code suggestions\n(imo) these are all part of a continuum of productivity enhancements that enable people to write better code faster. Try them out!\nI use Visual Studio Code",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/getting-going.html#notebooks",
    "href": "slides/getting-going.html#notebooks",
    "title": "Getting going",
    "section": "Notebooks",
    "text": "Notebooks\n\nSoftware developers write .py files, modules and packages\nScientists and others doing more exploratory work tend to favour a Notebook format that mixes code, text, and plots\nDominant option is Jupyter notebook, which comes with the Anaconda distribution\nStart from command line with jupyter notebook (or from the Anaconda Navigator application)\nOpens a notebook as a web page in your browser, where it can be edited and saved. The default extension is .ipynb",
    "crumbs": [
      "Slides",
      "Getting going"
    ]
  },
  {
    "objectID": "slides/complexity.html#first-example-multiplication",
    "href": "slides/complexity.html#first-example-multiplication",
    "title": "Part II Computational Physics",
    "section": "First example: multiplication",
    "text": "First example: multiplication\n\nBig numbers harder than small numbers. How much harder?\n\n\n\n\n\n\n\n\n\n\n\n\n×\n1\n3\n2\n2\n3\n1\n\n\n\n\n_\n_\n3\n_\n2\n6\n1\n4\n9\n2\n6\n3\n\n\n3\n9\n4\n8\n3",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#defining-complexity",
    "href": "slides/complexity.html#defining-complexity",
    "title": "Part II Computational Physics",
    "section": "Defining complexity",
    "text": "Defining complexity\n\nThe complexity of a problem refers to this scaling of the number of steps involved\nDifficulty of particular task (or calculation) may vary considerably — \\(100\\times 100\\) is easy, for example\nInstead ask about how a particular general algorithm performs on a class of tasks\nIn CS multiplication of \\(n\\) digit numbers is a problem. Particular pair of \\(n\\) digit numbers is an instance\nAbove algorithm for multiplication that has quadratic complexity, or “\\(O(n^2)\\) complexity” (say “order \\(n\\) squared”).",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#best-worst-average-case",
    "href": "slides/complexity.html#best-worst-average-case",
    "title": "Part II Computational Physics",
    "section": "Best / worst / average case",
    "text": "Best / worst / average case\n\nConsider search: finding an item in an (unordered) list of length \\(n\\). How hard is this?\nHave to check every item until you find the one you are looking for, so this suggests the complexity is \\(O(n)\\)\nCould be lucky and get it first try (or in first ten tries). The best case complexity of search is \\(O(1)\\).\nWorst thing that could happen is that the sought item is last: the worst case complexity is \\(O(n)\\)\nOn average, find your item near the middle of the list on attempt \\(\\sim n/2\\), so the average case complexity is \\(O(n/2)\\). This is the same as \\(O(n)\\) (constants don’t matter)",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#polynomial-complexity",
    "href": "slides/complexity.html#polynomial-complexity",
    "title": "Part II Computational Physics",
    "section": "Polynomial complexity",
    "text": "Polynomial complexity\n\nYou’ve already learnt a lot of algorithms in mathematics (even if you don’t think of them this way)\nLet’s revisit some them through lens of computational complexity",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#matrix-vector-multiplication",
    "href": "slides/complexity.html#matrix-vector-multiplication",
    "title": "Part II Computational Physics",
    "section": "Matrix-vector multiplication",
    "text": "Matrix-vector multiplication\n\nMultiplying a \\(n\\)-dimensional vector by a \\(n\\times n\\) matrix?\n\n\\[\n\\begin{align}\n\\sum_{j=1}^n M_{ij}v_j\n\\end{align}\n\\]\n\nSum contains \\(n\\) terms, and have to perform \\(n\\) such sums\nThus the complexity of this operation is \\(O(n^2)\\).",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#matrix-matrix-multiplication",
    "href": "slides/complexity.html#matrix-matrix-multiplication",
    "title": "Part II Computational Physics",
    "section": "Matrix-matrix multiplication",
    "text": "Matrix-matrix multiplication\n\\[\n\\sum_{j} A_{ij}B_{jk}\n\\]\n\nInvolves \\(n\\) terms for each of the \\(n^2\\) assignments of \\(i\\) and \\(k\\). Complexity: \\(O(n^3)\\)",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#better-than-linear",
    "href": "slides/complexity.html#better-than-linear",
    "title": "Part II Computational Physics",
    "section": "Better than linear?",
    "text": "Better than linear?\n\nSeems obvious that for search you can’t do better than linear\nWhat if the list is ordered? (numerical for numbers, or lexicographic for strings)\nExtra structure allows gives binary search that you may have seen before\nLook in middle of list and see if item you seek should be in the top half or bottom half\nTake the relevant half and divide it in half again to determine which quarter of the list your item is in, and so on",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#exponentiation-by-squaring",
    "href": "slides/complexity.html#exponentiation-by-squaring",
    "title": "Part II Computational Physics",
    "section": "Exponentiation by squaring",
    "text": "Exponentiation by squaring\n\nExponentiation is problem of raising a number \\(b\\) (the base) to the \\(n\\)th power\nMultiply the number by itself \\(n\\) times: linear scaling\nThere’s a quicker way, since \\[\n\\begin{align}\nb^2 &= b\\cdot b\\\\\nb^4 &= b^2\\cdot b^2\\\\\nb^4 &= b^4\\cdot b^4\n\\end{align}\n\\]\nOnly have to do three multiplications!",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#exponential-complexity",
    "href": "slides/complexity.html#exponential-complexity",
    "title": "Part II Computational Physics",
    "section": "Exponential complexity",
    "text": "Exponential complexity\n\nFibonacci numbers \\[\n0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233 ...\n\\]\n\n\\[\n\\text{Fib}(n) = \\text{Fib}(n-1) + \\text{Fib}(n-2)\n\\]\n\n\\(\\text{Fib}(n)\\) is defined in terms of lower values of \\(n\\), so a recursive definition possible",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#sorting",
    "href": "slides/complexity.html#sorting",
    "title": "Part II Computational Physics",
    "section": "Sorting",
    "text": "Sorting\n\nTurning a list or array into a sorted list (conventionally in ascending order):\n\n\nrandom_array = np.random.randint(0,100, 10)\nsorted(random_array)\n\n[30, 36, 44, 45, 52, 64, 73, 80, 95, 95]\n\n\n\nWhat is Python actually doing?\nMany sorting algorithms. See Wikipedia for an extensive list",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#bubble-sort",
    "href": "slides/complexity.html#bubble-sort",
    "title": "Part II Computational Physics",
    "section": "Bubble sort",
    "text": "Bubble sort\n\nRepeatedly pass through array, comparing neighbouring pairs of elements and switching them if they are out of order\nAfter first pass the largest element is in the rightmost position (largest index)\nSecond pass can finish before reaching last element, as it is already in place\nAfter second pass final two elements are correctly ordered\nContinue until array is sorted\nAnimation of bubble sort",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#quicksort",
    "href": "slides/complexity.html#quicksort",
    "title": "Part II Computational Physics",
    "section": "Quicksort",
    "text": "Quicksort\n\nUses two key ideas:\n\nPossible in \\(O(n)\\) steps to partition an array into those elements larger (or equal) and those elements smaller than a given value (called the pivot).\nActing recursively on each partition requires only \\(O(\\log n)\\) partitions to completely sort array",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#divide-and-conquer",
    "href": "slides/complexity.html#divide-and-conquer",
    "title": "Part II Computational Physics",
    "section": "Divide and conquer",
    "text": "Divide and conquer\n\nQuicksort, binary search, and exponentiation by squaring are all examples of divide and conquer algorithms\nAchieve performance by breaking task into two (or more) sub-problems of same type",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/complexity.html#karatsuba-algorithm",
    "href": "slides/complexity.html#karatsuba-algorithm",
    "title": "Part II Computational Physics",
    "section": "Karatsuba algorithm",
    "text": "Karatsuba algorithm\n\nRecall “obvious” method for multiplication has quadratic complexity\nTry a divide and conquer type approach by splitting an \\(n\\)-digit number as follows \\[\nx = x_1 B^m + x_0\n\\]\n\\(B\\) is base and \\(m=\\lceil n\\rceil\\)\nIn base 10 \\(x=12345\\) is written as \\(12 * 1000 + 345\\)",
    "crumbs": [
      "Slides",
      "Algorithms and computational complexity"
    ]
  },
  {
    "objectID": "slides/linear.html#linear-algebra-with-numpy",
    "href": "slides/linear.html#linear-algebra-with-numpy",
    "title": "Part II Computational Physics",
    "section": "Linear algebra with NumPy",
    "text": "Linear algebra with NumPy\n\nMultiplying matrices is easy in NumPy using np.matmul\n@ operator gives shortcut\n\n\nimport numpy as np\nA = np.random.rand(3, 3)\nB = np.random.rand(3, 3)\nnp.matmul(A, B), A @ B\n\n(array([[0.64405657, 0.71384765, 0.29837612],\n        [1.18686062, 1.33454843, 0.59619047],\n        [1.6478261 , 1.57803648, 0.85193837]]),\n array([[0.64405657, 0.71384765, 0.29837612],\n        [1.18686062, 1.33454843, 0.59619047],\n        [1.6478261 , 1.57803648, 0.85193837]]))",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#power-method",
    "href": "slides/linear.html#power-method",
    "title": "Part II Computational Physics",
    "section": "Power method",
    "text": "Power method\n\nBetter methods available if only want largest (or smallest) eigenvalue and eigenvector (e.g. QM ground state)\nSimplest is Power method\n\nStart from arbitrary vector \\(\\mathbf{b}_0\\)\nMultiply repeatedly by matrix \\(A\\)\nResult tends to dominant eigenvector (largest magnitude eigenvalue)",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#pagerank",
    "href": "slides/linear.html#pagerank",
    "title": "Part II Computational Physics",
    "section": "PageRank",
    "text": "PageRank\n\nGoogle’s PageRank algorithm assesses relative importance of webpages based on structure of links between them\n\n\n\n\nLarry Page",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#sparsity",
    "href": "slides/linear.html#sparsity",
    "title": "Part II Computational Physics",
    "section": "Sparsity",
    "text": "Sparsity\n\nMany matrices that we meet in physical applications are sparse, meaning that most of elements are zero\n\n\\[\n\\left[-\\frac{\\hbar^2}{2m}\\frac{d^2}{dx^2} + V(x)\\right]\\psi(x) = E\\psi(x)\n\\]\n\\[\n\\frac{d^2}{dx^2} \\sim \\frac{1}{\\Delta x^2}\\begin{pmatrix}\n-2 &  1 & 0 & 0 & 0 & \\cdots & 1 \\\\\n1 &  -2 & 1 & 0 & 0 & \\cdots & 0 \\\\\n0 &  1 & -2 & 1 & 0 & \\cdots & 0 \\\\\n\\cdots &  \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\\n1 &  0 & 0 & \\cdots & 0 & 1 & -2\n\\end{pmatrix}\n\\]",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#singular-value-decomposition",
    "href": "slides/linear.html#singular-value-decomposition",
    "title": "Part II Computational Physics",
    "section": "Singular value decomposition",
    "text": "Singular value decomposition\n\nOften faced with need to truncate large matrices in some way due to limits of finite storage space or processing time\nWhat is “right” way to perform truncation?\nSingular value decomposition (SVD) is natural in some settings: statistics, signal processing, quantum mechanics…",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#geometrical-interpretation",
    "href": "slides/linear.html#geometrical-interpretation",
    "title": "Part II Computational Physics",
    "section": "Geometrical interpretation",
    "text": "Geometrical interpretation\n\nColumns of \\(V\\) define an orthonormal basis \\(\\mathbf{v}_i\\in \\mathbb{C}^n\\) (\\(i=1,\\ldots n\\))\n\\(U\\) defines a basis \\(\\mathbf{u}_i\\in \\mathbb{C}^m\\) \\(i=1,\\ldots m\\)\nIf we act on \\(\\mathbf{v}_i\\) with \\(M\\) (to the left) we get \\(\\sigma_i \\mathbf{u}_i\\)",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#svd-in-quantum-mechanics",
    "href": "slides/linear.html#svd-in-quantum-mechanics",
    "title": "Part II Computational Physics",
    "section": "SVD in quantum mechanics",
    "text": "SVD in quantum mechanics\n\nSVD arises naturally in QM of composite systems (with two subsystems)\nExample: two spins \\(\\mathbf{S}_A\\) and \\(\\mathbf{S}_B\\)\nHilbert space of each spin has dimension \\(n_{A,B}\\equiv 2S_{A,B}+1\\), where \\(\\mathbf{S}_{A,B}^2=S_{A,B}(S_{A,B}+1)\\) (e.g. 2 for spin-1/2).",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#other-applications-of-svd",
    "href": "slides/linear.html#other-applications-of-svd",
    "title": "Part II Computational Physics",
    "section": "Other applications of SVD",
    "text": "Other applications of SVD\n\nApplications of SVD in recommender systems, described in this blog post",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#many-body-physics-tensor-methods",
    "href": "slides/linear.html#many-body-physics-tensor-methods",
    "title": "Part II Computational Physics",
    "section": "Many body physics & tensor methods",
    "text": "Many body physics & tensor methods\n\nWe saw that state of a quantum system composed of two subsystems represented as a matrix \\(\\psi_{ab}\\)\nGeneralizes to \\(N\\) subsystems: wavefunction may a tensor of rank \\(N\\): \\(\\psi_{a_1,\\ldots a_N}\\)\nEach index \\(a_i\\) ranges over dimension of Hilbert space of corresponding subsystem",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#penrose-tensor-notation",
    "href": "slides/linear.html#penrose-tensor-notation",
    "title": "Part II Computational Physics",
    "section": "Penrose tensor notation",
    "text": "Penrose tensor notation\n\nGraphical notation due to Roger Penrose\nRank \\(N\\) tensor is represented as blob with \\(N\\) legs:\n\n\n\n\nThe tensor notation. Source: Glen Evenbly",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/linear.html#example-ground-state-of-spin-chain",
    "href": "slides/linear.html#example-ground-state-of-spin-chain",
    "title": "Part II Computational Physics",
    "section": "Example: ground state of spin chain",
    "text": "Example: ground state of spin chain\n\nSimplest example: Heisenberg chain for spin-1/2:\n\n\\[\nH = \\sum_{j=1}^N \\left[\\sigma^x_j \\sigma^x_{j+1} + \\sigma^y_j \\sigma^y_{j+1} + \\sigma^z_j \\sigma^z_{j+1} \\right]\n\\]\n\n\\(\\sigma^{x,y,z}\\) are usual Pauli matrices and subscript \\(j\\) means that matrix acts only the \\(j\\)th index of the wavefunction\nUsually impose periodic boundary conditions: \\(\\sigma^a_{j+N}=\\sigma^a_j\\)",
    "crumbs": [
      "Slides",
      "Linear algebra"
    ]
  },
  {
    "objectID": "slides/numpy.html#preamble-objects-in-python",
    "href": "slides/numpy.html#preamble-objects-in-python",
    "title": "Part II Computational Physics",
    "section": "Preamble: objects in Python",
    "text": "Preamble: objects in Python\n\nEverything in Python is an object\nFor example [1,2,3] is a list:\n\n\nmy_list = [1, 2, 3]\ntype(my_list)\n\nlist\n\n\n\nObject is container for properties and methods (functions associated with object), accessed with . syntax.\ne.g. lists have append method:\n\n\nmy_list.append(\"boop\")\nmy_list\n\n[1, 2, 3, 'boop']",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#arrays",
    "href": "slides/numpy.html#arrays",
    "title": "Part II Computational Physics",
    "section": "Arrays",
    "text": "Arrays\n\nFundamental object in NumPy is Array (or ndarray), multidimensional version of a list\nIn plain old Python a matrix would be a list of lists.\n\n\ndata = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n\n\ndata[i] represents each row:\n\n\ndata[1]\n\n[4, 5, 6]",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#indexing",
    "href": "slides/numpy.html#indexing",
    "title": "Part II Computational Physics",
    "section": "Indexing",
    "text": "Indexing\n\nmy_array\n\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12]])\n\n\n\nArrays can be indexed, similar to lists\n\n\nprint(my_array[0], my_array[1], my_array[3][1])\n\n[1 2 3] [4 5 6] 11\n\n\n\nBetter syntax for the last one\n\n\nmy_array[3,1]\n\n11",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#shape",
    "href": "slides/numpy.html#shape",
    "title": "Part II Computational Physics",
    "section": "Shape",
    "text": "Shape\n\nA fundamental property of an array is shape:\n\n\n# [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\nmy_array.shape\n\n(4, 3)\n\n\n\n\nFirst a number of [ corresponding to the rank of the array (two in the above example)\nThen number of entries giving rightmost (innermost) dimension in shape before closing ] (3 here)\nAfter a number of 1D arrays [...] equal to the next innermost dimension (4 here), we have another closing ], and so on",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#other-ways-to-make-arrays",
    "href": "slides/numpy.html#other-ways-to-make-arrays",
    "title": "Part II Computational Physics",
    "section": "Other ways to make arrays",
    "text": "Other ways to make arrays\n\nNumPy has lots of methods to create arrays\n\n\na = np.zeros((2,2))\nprint(a)\nb = np.ones((2,2))\nprint(b)\nc = np.full((2,2), 5)\nprint(c)\nd = np.random.random((2,2)) # random numbers uniformly in [0.0, 1.0)\nprint(d)\neye = np.eye(2) # Identity matrix\nprint(eye)\n\n[[0. 0.]\n [0. 0.]]\n[[1. 1.]\n [1. 1.]]\n[[5 5]\n [5 5]]\n[[0.88033089 0.21886361]\n [0.82283125 0.64978079]]\n[[1. 0.]\n [0. 1.]]",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#shape-shifting",
    "href": "slides/numpy.html#shape-shifting",
    "title": "Part II Computational Physics",
    "section": "Shape shifting",
    "text": "Shape shifting\n\nnumpy.reshape to change the shape of an array\nnumpy.expand_dims to insert new axes of length one.\nnumpy.squeeze (the opposite) to remove new axes of length one.",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#dtype",
    "href": "slides/numpy.html#dtype",
    "title": "Part II Computational Physics",
    "section": "dtype",
    "text": "dtype\n\nArrays have dtype property that gives datatype\nIf array was created from data, this will be inferred\n\n\nmy_array.dtype\n\ndtype('int64')\n\n\n\nFunctions constructing arrays have optional dtype\n\n\nmy_float_array = np.array([1,2,3], dtype=np.float64)\nmy_float_array.dtype\n\ndtype('float64')\n\n\n\nImportantly, complex numbers are supported\n\n\nmy_float_array = np.array([1.1 + 2.3j,2.2,3.6])\nmy_float_array.dtype\n\ndtype('complex128')",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#examples-of-array-like-data",
    "href": "slides/numpy.html#examples-of-array-like-data",
    "title": "Part II Computational Physics",
    "section": "Examples of array-like data",
    "text": "Examples of array-like data\n\nPosition, velocity, or acceleration of particle will be three dimensional vectors, so have shape (3,)\nWith \\(N\\) particles could use a \\(3N\\) dimensional vector\nBetter: an array of shape (N,3). First index indexes particle number and second particle coordinate.\n\\(N\\times M\\) matrix has shape (N,M)\nRiemann curvature tensor in General Relativity \\(R_{abcd}\\) has shape (4,4,4,4)",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#mathematical-operations-with-arrays",
    "href": "slides/numpy.html#mathematical-operations-with-arrays",
    "title": "Part II Computational Physics",
    "section": "Mathematical operations with arrays",
    "text": "Mathematical operations with arrays\n\nOn lists\n\n\n2 * [1, 2, 3]\n\n[1, 2, 3, 1, 2, 3]\n\n\n\nIn numerical applications what we really want is\n\n\n2 * np.array([1, 2, 3])\n\narray([2, 4, 6])",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#broadcasting",
    "href": "slides/numpy.html#broadcasting",
    "title": "Part II Computational Physics",
    "section": "Broadcasting…",
    "text": "Broadcasting…\n\n…is a powerful protocol for combining arrays of different shapes, generalizing this kind of thing\n\n\nnp.array([1, 2, 3]) + 2.3\n\narray([3.3, 4.3, 5.3])",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#plotting-with-matplotlib",
    "href": "slides/numpy.html#plotting-with-matplotlib",
    "title": "Part II Computational Physics",
    "section": "Plotting with Matplotlib",
    "text": "Plotting with Matplotlib\n\nVarious specialized Python plotting libraries\n“entry-level” option is Matplotlib\npyplot module provides a plotting system that is similar to MATLAB (I’m told)\n\n\nimport matplotlib.pyplot as plt\n\n\nProbably the second most common import you will make!",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#example-playing-with-images",
    "href": "slides/numpy.html#example-playing-with-images",
    "title": "Part II Computational Physics",
    "section": "Example: playing with images",
    "text": "Example: playing with images\n\nPixels in an image encoded as a triple of RGB values in the range [0,255] i.e. 8 bits of type uint8 (the “u” is for “unsigned”)\nTinting an image gives a nice example of broadcasting",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "slides/numpy.html#saving-and-loading-data",
    "href": "slides/numpy.html#saving-and-loading-data",
    "title": "Part II Computational Physics",
    "section": "Saving and loading data",
    "text": "Saving and loading data\n\nAt some point you’ll probably want to save and load data\nNumPy comes with its own save and load functions and associated binary format .npy\nThe benefit of using these is that after loading you get back a NumPy array ready to be used",
    "crumbs": [
      "Slides",
      "NumPy and friends"
    ]
  },
  {
    "objectID": "notes/assignments.html",
    "href": "notes/assignments.html",
    "title": "1 Assignments",
    "section": "",
    "text": "Autocorrelation times of various algorithms. Scaling with system size."
  },
  {
    "objectID": "notes/assignments.html#ising-model",
    "href": "notes/assignments.html#ising-model",
    "title": "1 Assignments",
    "section": "",
    "text": "Autocorrelation times of various algorithms. Scaling with system size."
  },
  {
    "objectID": "notes/monte-carlo.html",
    "href": "notes/monte-carlo.html",
    "title": "Monte Carlo methods",
    "section": "",
    "text": "Many physical phenomena, notably those falling within the domains of statistical mechanics and quantum theory, depend in an essential way on randomness. The simulation of these phenomena therefore requires algorithms that incorporate random (or pseudo-random) elements in the most efficient way.",
    "crumbs": [
      "Notes",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "notes/monte-carlo.html#monte-carlo-integration",
    "href": "notes/monte-carlo.html#monte-carlo-integration",
    "title": "Monte Carlo methods",
    "section": "2.1 Monte Carlo integration",
    "text": "2.1 Monte Carlo integration\nThe technique is exemplified by the following fairly dumb way of estimating \\(\\pi\\)\n\nmax_samples = 10000\ninside = 0\nareas = []\nfor sample in range(1, max_samples + 1):\n    x = random.uniform(-1, 1)\n    y = random.uniform(-1, 1)\n    \n    if x ** 2 + y ** 2 &lt;= 1:\n        inside += 1\n    areas.append(4 * inside / sample)\n\nplt.plot(np.arange(1, max_samples + 1), areas)\nplt.plot(np.arange(1, max_samples + 1), np.pi * np.ones(max_samples), linestyle='dashed')\nplt.show()\n\n\n\n\n\n\n\n\nIn terms of integration, you can think of this as a way to compute the integral of a function which is one inside the unit disc, and zero outside it.\nAlthough it’s a silly method, this does illustrate one important feature of Monte Carlo methods in general: that the relative error with \\(N\\) samples is typically \\(\\propto N^{-1/2}\\) (thus at the 1% level for \\(10^4\\) samples) because the variance of a sum of \\(N\\) iid variables is \\(\\propto N^{1/2}\\).\nThe general setting of Monte Carlo integration is as follows. Suppose we have a multidimensional integral to evaluate over some domain \\(D\\)\n\\[\nI(f,D) = \\int_D f(\\mathbf{x}) d\\mathbf{x}\n\\]\nIf we can sample points uniformly within \\(D\\), then an estimate for the integral is\n\\[\nI(f,D) = \\frac{V_D}{N}\\sum_{i=1}^N f(\\mathbf{x}_i)\n\\]\nwhere \\(N\\) is the number of samples and \\(V_D\\) is the (hyper-)volume of \\(D\\). Why does this work? Because the uniform distribution has constant probability density \\(1/V_D\\) so the average of \\(f(\\mathbf{x}_i)\\) with respect to this uniform distribution is simply related to the integral we are trying to calculate\n\\[\n\\bar f = \\frac{1}{V_D}\\int f(\\mathbf{x})d\\mathbf{x}.\n\\]\nBy taking many samples and averaging \\(f(\\mathbf{x}_i)\\) we can estimate this average. In the simple example that we started with \\(f(\\mathbf{x})\\) would be a “top hat” function that is one inside the circle. As in that example, the relative error is \\(\\propto N^{-1/2}\\), whatever the dimension.\nFor this reason Monte Carlo integration comes into its own for high dimensional problems. For low dimensional integrals the quadrature methods in scipy.integrate are preferable:\n\nfrom scipy import integrate\nintegrate.quadrature(np.cos, 0, np.pi / 2)\n\n(0.9999999999999536, 3.9611425250996035e-11)\n\n\nAs for ODE solvers, there is a lot of detail in the implementation to do with how intervals are chosen, and so on.",
    "crumbs": [
      "Notes",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "notes/monte-carlo.html#importance-sampling",
    "href": "notes/monte-carlo.html#importance-sampling",
    "title": "Monte Carlo methods",
    "section": "2.2 Importance sampling",
    "text": "2.2 Importance sampling\nMonte Carlo integration is not restricted to sampling from the uniform distribution. If our function \\(f(\\mathbf{x})\\) has regions where it is very small, there is not much point in sampling its value there. If there is a distribution we can sample from where samples tend to fall in the region where \\(f(\\mathbf{x})\\) is large, it will probably be better to use that. In this case we calculate the weighted average using the probability density \\(p_\\text{sample}(\\mathbf{x})\\) from where the samples are drawn\n\\[\nI(f,D, p_\\text{sample}) = \\frac{1}{N}\\sum_{i=1}^N \\frac{f(\\mathbf{x}_i)}{p_\\text{sample}(\\mathbf{x}_i)}\n\\]\nThe reason this works is that the average of one of the terms in the sum is just the integral we want\n\\[\n\\overline{\\frac{f(\\mathbf{x})}{p_\\text{sample}(\\mathbf{x})}} = \\int \\frac{f(\\mathbf{x})}{p_\\text{sample}(\\mathbf{x})} p_\\text{sample}(\\mathbf{x})d\\mathbf{x} = \\int f(\\mathbf{x})d\\mathbf{x}\n\\]\nThe benefit of this approach is that it can lead to a drastic reduction in the variance of the estimator. To take an extreme example: if \\(f(\\mathbf{x})\\propto p_\\text{sample}(\\mathbf{x})\\), and even a single sample leads to perfect estimate with no uncertainty! This observation is not useful, if you knew \\(p_\\text{sample}(\\mathbf{x})\\) you would know the constant factor by which \\(f(\\mathbf{x})\\) differs, but it illustrates the point about variance reduction.\nThis general technique is called Importance sampling. To apply the above approach, one needs both an explicit form for \\(p_\\text{sample}(\\mathbf{x})\\) and the ability to generate samples, which is rather restrictive. There are many elaborations of the basic idea, however, including multiple distributions as well as adaptive sampling to “discover” the right region for sampling.",
    "crumbs": [
      "Notes",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "notes/monte-carlo.html#sec-mcmc",
    "href": "notes/monte-carlo.html#sec-mcmc",
    "title": "Monte Carlo methods",
    "section": "2.3 Markov chain Monte Carlo",
    "text": "2.3 Markov chain Monte Carlo\nSuppose you want to generate configurations at random (i.e. with a uniform distribution) from a “gas” of hard disks 2.\n\n\n\nCoins in a shoe box (gas of hard disks). From Krauth (1998)\n\n\nIt’s harder than it looks! The first guess you might have is to start adding coins at random, and if you get an overlap, try again until you don’t. Obviously this will become inefficient as the box fills up, and most attempts fail. Worse, it doesn’t in fact yield a uniform distribution! 3\nHere’s an approach that works:\n\nExample 1 (Metropolis algorithm for hard disks)  \n\nFix the number of disks and an initial configuration (some regular lattice configuration, say).\nPick a disk at random and attempt (or propose) to move it by a small random amount (i.e. random direction; random small magnitude).\nIf this results in the moved disk intersecting another, reject the move, leaving the disk where it is. Otherwise, accept the move.\nRepeat 2. and 3. many times.\n\n\n.\nThis is the simplest example of the Metropolis–Hastings algorithm, the first Markov chain Monte Carlo (MCMC) algorithm.\nMore generally, the goal of MCMC is to come up with a sequential random process (a Markov chain) that generates (usually after many steps) a sample from a particular distribution.\nYou’ve all heard of a random walk, perhaps as a model for diffusion. At each step you make a move in a random direction, independently of your earlier moves. After many steps these random moves gives rise to a distribution of possible locations. A random walk is the simplest example of a Markov chain.\nMore generally, a Markov chain is a sequence of random variables \\(X_n\\) with each having a distribution that is is conditional on the value of the previous one, and so is defined in terms of transition probabilities \\(p(X_{n}=x_n|X_{n-1}=x_{n-1})\\) (hence they form a “chain”). I’m going to immediately drop this cumbersome notation in favour of \\(p(x_n|x_{n-1})\\), a function of \\(x_n\\) and \\(x_{n-1}\\), but in general the function giving the transition probabilities can be different at each step (the random variables could all be different).\nThe probability of a particular sequence \\(X_1=x_1\\ldots X_n=x_n\\) is therefore\n\\[\np(x_n|x_{n-1})p(x_{n-1}|x_{n-2})\\cdots p(x_2|x_{1})p^{(1)}(x_1)\n\\]\n\\(X_1\\) has no “parent” so is not conditional on any other value.\nSuppose we don’t care about the earlier values and just want to know the marginal distribution \\(p^{(n)}(x_n)\\) of the final variable. For a random walk this is easy, as \\(x_n\\) typically represents a displacement that is a sum of iid increments. In general this is not the case, however, as the marginal distribution is\n\\[\np^{(n)}(x_n)=\\sum_{x_{n-1},\\ldots x_1}p(x_n|x_{n-1})p(x_{n-1}|x_{n-2})\\cdots p(x_2|x_{1})p^{(1)}(x_1)\n\\]\n(I’m writing all these expressions for discrete random variables, but the continuous version involving probability density functions is straightforward)\nThe sums are over all possible values that the random variables might take in the state space of the problem. These could be finite or infinite in number.\nThings are not as bad as they appear, however, as the marginal distribution can be interpreted as the result of acting \\(n-1\\) times on the vector of values of \\(p^{(1)}_j\\equiv p^{(1)}(j)\\) with the transition matrix with elements \\(\\mathsf{P}_{jk}=p(j|k)\\)\n\\[\n\\mathbf{p}^{(n)} = \\mathsf{P}^{n-1}\\mathbf{p}^{(1)}.\n\\]\nIn a single step the marginal probabilities are updated as\n\\[\n\\mathbf{p}^{(n)} = \\mathsf{P}^{n}\\mathbf{p}^{(n-1)}.\n\\]\n\\(\\mathsf{P}\\) has some structure. The matrix elements are positive, as they represent probabilities, and each row sums to one\n\\[\n\\sum_j \\mathsf{P}_{jk} = 1.\n\\]\nSuch matrices are called stochastic.\nAlthough \\(p^{(n)}\\) — the probability distribution at the \\(n\\)th step — changes from step to step, you might expect that after many steps it tends to converge to a stationary distribution \\(p^{(n)}\\to\\boldsymbol{\\pi}\\). If it exists, this distribution must satisfy\n\\[\n\\boldsymbol{\\pi} = \\mathsf{P}\\boldsymbol{\\pi}.\n\\tag{1}\\]\nIn other words, it is an eigenvector of \\(\\mathsf{P}\\) with eigenvalue one. This property is guaranteed by the Perron–Frobenius theorem 4.\nThus \\(\\mathsf{P}\\) determines \\(\\boldsymbol{\\pi}\\). MCMC turns this idea on its head and asks: if there is some \\(\\boldsymbol{\\pi}\\) that I would like to generate samples from, can I find a \\(\\mathsf{P}\\) that has it as a stationary distribution?\nThere is a trivial answer to this question. Sure, take \\(\\mathsf{P}_{jk}=\\boldsymbol{\\pi}_j\\). That is, jump straight to the stationary distribution no matter what the starting state. But we are interested in highly complicated distributions over large state spaces (think the Boltzmann distribution for a statistical mechanical system comprised of billions of particles). Thus what we really want is to be able to approach such a complicated distribution by making many transitions with simple distributions.\nOne more idea is useful before returning to concrete algorithms. The quantity\n\\[\n\\mathsf{P}_{jk}\\pi_k = p(j|k)\\pi_k = p(j,k)\n\\]\nis the joint distribution of seeing state \\(k\\) followed by state \\(j\\) in the stationary distribution. A reversible Markov chain is one where \\(p(j,k)=p(k,j)\\). Roughly, you can’t tell the direction of time because any transition is equally likely to happen forward in time as backward. Random physical processes that respect time reversal symmetry are often modeled as reversible Markov processes.\nCombining reversibility with the definition of the stationary state yields the condition of detailed balance\n\\[\n\\mathsf{P}_{jk}\\pi_k = \\pi_j\\mathsf{P}_{kj}.\n\\tag{2}\\]\nThis condition is stronger than the condition Equation 1 for a stationary state. This makes it easier to check: you don’t have to do a sum over a state space index. The Metropolis algorithm Example 1 for the hard disk problem satisfies detailed balance for a stationary distribution that is constant when disks don’t intersect and zero when they do.\nWhen the stationary distribution \\(\\boldsymbol{\\pi}\\) has more structure, designing an appropriate transition matrix is harder. The idea is to generalize the hard disk approach by separating the transition into a proposal distribution \\(p_\\text{prop}(j|k)\\) and an acceptance distribution \\(p_\\text{acc}(a=0,1|j\\leftarrow k)\\) that gives the probability of a move from \\(k\\) to \\(j\\) being accepted (\\(a=1\\)) or rejected (\\(a=0\\)). The probability of moving from \\(k\\) to \\(j\\) is then\n\\[\np(j|k) = p_\\text{acc}(a=1|j\\leftarrow k) p_\\text{prop}(j|k).\n\\]\nSubstituting this into the detailed balance condition Equation 2 gives \\[\n\\frac{p_\\text{acc}(a=1|j\\leftarrow k)}{p_\\text{acc}(a=1|k\\leftarrow j)} = \\frac{\\pi_j}{\\pi_k}\\frac{p_\\text{prop}(k|j)}{p_\\text{prop}(j|k)}.\n\\]\nAny \\(p_\\text{acc}\\) that satisfies this relation for all \\(j\\) and \\(k\\) will do the job. The Metropolis choice is\n\\[\np_\\text{acc}(a=1|j \\leftarrow k) = \\min\\left(1,  \\frac{\\pi_j}{\\pi_k}\\frac{p_\\text{prop}(k|j)}{p_\\text{prop}(j|k)}\\right).\n\\tag{3}\\]\nThis gives an extremely general algorithm, one of the top ten in applied mathematics, according to one list:\n\nExample 2 (Metropolis algorithm)  \n\nStarting from state \\(k\\) sample a next state \\(j\\) from the proposal distribution \\(p_\\text{prop}(j|k)\\).\nAccept the proposal with probability \\(p_\\text{acc}(a=1|j \\leftarrow k)\\) and move to state \\(j\\). Otherwise reject the proposal and stay in state \\(k\\).\nRepeat 1. and 2. many times.\n\n\nMCMC has the benefit of being embarrassingly parallel. If you want to average something over \\(\\boldsymbol{\\pi}\\), just run the algorithm many times independently and average the results. This is perfect for parallel computing.\nThe Metropolis algorithm has an Achilles’ heel, however. To perform a move one has to sample from \\(p_\\text{prop}(j|k)\\) and from \\(p_\\text{acc}(a|j \\leftarrow k)\\). The proposal therefore has to be tractable, like the small shift in position for the hard disk case. This may however, mean that that many of the \\(j\\)s suggested correspond to very small \\(\\pi_j\\), and therefore a very low acceptance probability (c.f. Equation 3). For example, in the hard disk case at high density many proposed moves will give rise to overlap of disks and be rejected. This means that many steps are required to have one successful update of the simulation. This kind of slowdown is a common feature of MCMC methods applied to complex distributions.\nWe’ll see some more examples of MCMC algorithms for statistical mechanical problems in Section 3, and ways in which this problem can be avoided.",
    "crumbs": [
      "Notes",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "notes/monte-carlo.html#mcmc-updates-for-the-ising-model",
    "href": "notes/monte-carlo.html#mcmc-updates-for-the-ising-model",
    "title": "Monte Carlo methods",
    "section": "3.1 MCMC updates for the Ising model",
    "text": "3.1 MCMC updates for the Ising model\nHow does MCMC work in practice for the Ising model? To apply the Metropolis alogorithm Example 2 we can use a simple proposal: pick each spin in turn in some order and try to flip it.\nThe form of \\(p(\\sigma)\\) means that, although we cannot compute the probabilities explicitly, we can calculate ratios, which is all we need for Metropolis. For two configurations that differ only by \\(\\sigma_n=\\pm 1\\) we have\n\\[\n\\begin{align}\n\\frac{p(\\sigma_n=1|\\sigma_{m\\neq n})}{p(\\sigma_n=-1|\\sigma_{m\\neq n})} &= \\exp\\left[-2\\beta \\left(h_n+\\sum_{m\\neq n} J_{mn}\\sigma_m\\right)\\right]\\\\\n&\\equiv \\exp\\left[-\\beta\\Delta \\mathcal{E}\\right],\n\\end{align}\n\\]\nwhere \\(\\Delta \\mathcal{E}\\) is the energy difference between two configurations.\nOne alternative to Metropolis is the Heat bath algorithm (or Glauber dynamics or Gibbs sampling) 6. The idea behind the name is that, since we can calculate the influence of the spin’s environment (the “bath”), we can just choose the spin’s orientation with the corresponding probabilities. Since there are only two probabilities the ratio is all we need and we get\n\\[\np(\\sigma_n=\\pm 1|\\sigma_{m\\neq n}) = \\frac{1}{1+ e^{\\pm\\beta \\Delta \\mathcal{E}}}.\n\\tag{5}\\]\nThe algorithm is then:\n\nExample 3 (Heat bath algorithm)  \n\nPick a spin \\(n\\). 7\nCompute \\(\\Delta E\\), the energy difference between \\(\\sigma_n=\\pm 1\\).\nSet \\(\\sigma_n=\\pm 1\\) with probabilities given by Equation 5.\nRepeat 1-3 many times\n\n\nWhat happens if we try and come up with more complicated proposals, flipping many spins at once? For Metropolis, the problem is that without a cleverly designed proposal we will be suggesting moves that are likely to be rejected. For the heat bath algorithm, the more spins we flip, the more complicated the evaluation of the corresponding probabilities (\\(2^n\\) outcomes if we flip \\(n\\) spins).\nThe good news is that we can do better — much better — than the above algorithms. The Wolff algorithm is one example. This proposes a cluster of spins of the same orientation to be flipped by adding adjacent spins to an initially random chosen spin with probability \\(p_\\text{add}\\). It turns out that for the nearest neighbour Ising model with Ferromagnetic coupling \\(J&lt;0\\) the “magic” value \\(p_\\text{add}=1-e^{2\\beta J}\\) is rejection free: the probability to flip the whole cluster is always one. This makes for an extremely fast algorithm that is not subject to the usual critical slowing down at phase transitions.\n\n\nIsing model code\nclass IsingModel:\n    def __init__(self, L):\n        self.L = L\n        self.spins = np.random.choice(a=[1, -1], size=(L, L))\n        stagger = np.empty(self.L, dtype = bool)\n        stagger[::2] = True\n        stagger[1::2] = False\n        self.mask = np.logical_xor(stagger[:, np.newaxis], stagger[np.newaxis, :])\n\n    def gibbs_update(self, beta, sublattice):\n        fields = np.roll(self.spins, 1, 0) + np.roll(self.spins, -1, 0) + np.roll(self.spins, 1, 1) + np.roll(self.spins, -1, 1)\n        delta_E = 2 * fields\n        spin_up_probabilities = 1 / (1 + np.exp(- beta * delta_E))\n        new_spins = 2 * (np.random.rand(self.L, self.L) &lt; spin_up_probabilities) - 1\n        self.spins = np.choose(np.logical_xor(sublattice, self.mask), [self.spins, new_spins])\n\n    def glauber_update(self, beta):\n        x, y = np.random.randint(self.L, size=2)\n        fields = 0\n        for neighbour in [((x + 1) % self.L, y), ((x - 1) % self.L, y), (x, (y + 1) % self.L), (x, (y - 1) % self.L)]:\n            fields += self.spins[neighbour]\n        delta_E = 2 * fields\n        spin_up_probability = 1 / (1 + np.exp(- beta * delta_E))        \n        if np.random.rand() &lt; spin_up_probability:\n            self.spins[x, y] = 1\n        else:\n            self.spins[x, y] = -1\n\n    def wolff_update(self, beta):\n        initial_x, initial_y = np.random.randint(self.L, size=2)\n        initial_spin = self.spins[initial_x, initial_y]\n        cluster = deque([(initial_x, initial_y)])\n        add_prob = 1 - np.exp(-2 * beta)\n\n        while len(cluster) != 0:\n            x, y = cluster.popleft()\n            if self.spins[x, y] == initial_spin:\n                self.spins[x, y] *= -1\n                for neighbour in (((x + 1) % self.L, y), ((x - 1) % self.L, y), (x, (y + 1) % self.L), (x, (y - 1) % self.L)):\n                    if self.spins[neighbour] == initial_spin:\n                        if np.random.rand() &lt; add_prob:\n                            cluster.append(neighbour)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Glauber dynamics, Block Gibbs sampling and Wolff updates compared. Change the temperature using the slider. The centre of the slider corresponds to the critical temperature \\(k_\\text{B}T = 2|J|/\\log(1+\\sqrt{2})\\sim 2.269|J|\\).",
    "crumbs": [
      "Notes",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "notes/monte-carlo.html#footnotes",
    "href": "notes/monte-carlo.html#footnotes",
    "title": "Monte Carlo methods",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA common shorthand notation is \\(x\\sim p_X\\).↩︎\nThis is in fact the original motivation for the development of the technique, see Metropolis et al. (1953).↩︎\nFor a discussion of what goes wrong in a simple discrete model of rods in 1D, see Section 2.2.1 of Krauth (2006). ↩︎\nThere is an important caveat. If there are two or more subsets of the state space that are not connected by finite transition probabilities, the probability distribution in each subset evolves independently and there is not a unique stationary distribution. When there is, we say that the Markov chain is ergodic and the corresponding transition matrix is irreducible.↩︎\nFor a classical gas of point particles this would correspond to specifying all the positions and velocities, for example.↩︎\nMultiple names are sign that a technique was re-discovered by different communities who don’t talk to each other.↩︎\nThis can be done deterministically (e.g. sequentially or in alternating blocks when the model is defined on a bipartite graph) — which is what is normally called Gibbs sampling — or at random, which corresponds to Glauber dynamics.↩︎",
    "crumbs": [
      "Notes",
      "Monte Carlo methods"
    ]
  },
  {
    "objectID": "notes/intro.html",
    "href": "notes/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Science is what we understand well enough to explain to a computer. Art is everything else we do.\nDonald Knuth\n\nComputation saturates every corner of physics these days, much as it saturates every corner of everything. Even if we restrict ourselves to the senses most relevant to physicists, the word computation covers a terrific variety of ideas. From the prosaic to the lofty, I could be talking about:\n\nThe tools we use to do computation. Physical hardware, editors, notebooks, etc.\nThe languages we use to write code in order to perform computations.\nThe use of tools to generate documents (e.g. using \\(\\LaTeX\\)) or disseminate knowledge (online).\nThe automated gathering and analysis of experimental data.\nThe numerical techniques that we use to solve particular problems in theoretical physics and mathematics.\nThe limits of what we can achieve with finite resources including time and space (memory). That is, how hard — or complex — are the computational tasks we wish to perform? Can we quantify this?\nThe question of whether physical processes are really the same things as computations. That is: are all processes that happen in the physical universe computable in principal (perhaps on a quantum computer)? This is roughly what is meant by (physical) Church–Turing thesis. This brings us full circle to the first item on the list.\n\nIn this course we’ll have to touch on all of these, except the last one (it’s only eight lectures). Most of the concrete techniques we’ll look at will come from computational physics (i.e. mathematical modelling of physical processes), rather than data analysis, but that’s mostly because of my background.\nFor theoretical physics, computation is used to deal with the awkward fact that physical theories are generally not tractable. You can’t solve Maxwell’s equations, the Navier–Stokes equation, or Schrödinger’s equation in any but the simplest situations. To be blunt, this means that your knowledge of physics, while very nice, is not all that useful unless you can write a program to solve more complicated problems. Sorry.\nOn the plus side — as the above quote from Donald Knuth suggests — thinking about how to put a piece of physics you think you know into functioning code is a fantastic way to deepen your understanding of the physics itself. Every symbol and every operation has to mean and do exactly what it should for you to succeed.\nIt’s important to understand that this need to apply our mathematical descriptions of nature in more general settings was the principal driving force behind the invention of the computer in the first place. If you’d like to learn more about the early history of electronic computers I’d recommend Dyson (2012).\nIf you’d like to get into the theory of computation more deeply, I can’t recommend Moore and Mertens (2011) highly enough.\n\n\n\n\nReferences\n\nDyson, George. 2012. Turing’s Cathedral: The Origins of the Digital Universe. Vintage.\n\n\nMoore, Cristopher, and Stephan Mertens. 2011. The Nature of Computation. Oxford University Press.",
    "crumbs": [
      "Notes",
      "Introduction"
    ]
  },
  {
    "objectID": "notes/autodiff.html",
    "href": "notes/autodiff.html",
    "title": "Automatic differentiation and neural networks",
    "section": "",
    "text": "In this lecture we are going to look at the algorithms that underlie the training of neural networks, which are the dominant model in the field of machine learning.",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#sec-cost",
    "href": "notes/autodiff.html#sec-cost",
    "title": "Automatic differentiation and neural networks",
    "section": "1.1 The cost function",
    "text": "1.1 The cost function\nLet’s discuss the idea of training as optimization in a bit more detail. We suppose that we have a large dataset of size \\(N\\) that consists of data \\(\\mathbf{x}_i=1,\\ldots N\\) together with labels \\(l_i\\). The first step is to encode our labels in vectors \\(\\mathbf{y}_i\\) that can be compared with the output of the neural network. A popular choice is one hot encoding. \\(\\mathbf{y}_i\\) is an \\(N_L\\) dimensional vector, where \\(N_L\\) is the number of labels, and label \\(n\\) is encoded as \\((0,0,\\ldots, 1, \\ldots, 0)\\), with the \\(1\\) in the \\(n\\)th place.\nWe would like to train the network (choose the parameters \\(\\theta\\)) so that \\(\\mathsf{NN}_\\theta(\\mathbf{x}_i)\\) is close to the corresponding \\(\\mathbf{y}_i\\) that represents the label. In order to quantify this we introduce a cost or loss function that quantifies the difference. A simple example is the quadratic cost\n\\[\n\\mathcal{C}(\\theta) = \\frac{1}{2N}\\sum_{i=1}^N \\lVert\\mathbf{y}_i-\\mathsf{NN}_\\theta(\\mathbf{x}_i)\\rVert^2.\n\\tag{1}\\]\nIn other words, we use the usual square norm in \\(\\mathbb{R}^{N_L}\\) of the distance between the network output and encoded label. Note also that we average over the training data, because sometimes our network may not perform so well, confusing different labels:\n\n\n\nMuffin or chihuahua?\n\n\nThe idea is now to minimize \\(\\mathcal{C}(\\theta)\\) over the parameters of the network. The rest of this lecture concerns the practicalities of how this is done. When it comes to using the model for identifying previously unseen data, we need a procedure for turning the output \\(\\mathsf{NN}_\\theta(\\mathbf{x})\\) — an \\(N_L\\) dimensional vector — into a discrete label. If the network has been defined so that the components of the output are non-negative, and recalling that the labels were encoded as one hot vectors, the simplest way to do this is to find the maximum component and make the prediction that the corresponding label is the correct one. This is written as\n\\[\nl_* = \\underset{l}{\\operatorname{argmax}} \\left[\\mathsf{NN}_\\theta(\\mathbf{x})\\right]_l.\n\\]\nWhen evaluating the performance of a machine learning model there is a standard protocol that involves splitting the dataset into training set and a test set, where the former is used for training the model and the latter for evaluating it. After training the model it should perform well on the training set, but will generally perform less well on the test set, which contains data that the model has never seen. The difference between the cost function evaluated on the test set and the training set is a measure of how well the model generalizes to new inputs and is known as the generalization error.\nA particular risk when using large neural networks with many parameters is the problem of overfitting. A sufficiently flexible model is capable of effectively “memorizing” the dataset, without “understanding” the labelling, leading to poor generalization.\n\n\n\nSimple illustration of overfitting, from Wikipeda. The black line represents a “reasonable” model that does a decent job of distinguishing between the two labels in the data (red and blue), while the green line represents an “unreasonable” model that does a better job.\n\n\nA particularly vivid example appears in Zhang et al. (2021). They showed that popular computer vision models can be trained on randomly labelled data (where the labels have no connection to the image) to achieve perfect accuracy on the training set. Of course, the resulting performance on the test set was no better than random guessing. This is a natural consequence of overparameterization — having more parameters than data points in your training data — and shows that much of the success in training models with good generalization is down to the details of how the training is done (for example, by stopping before the training error gets too low).",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#sec-grad",
    "href": "notes/autodiff.html#sec-grad",
    "title": "Automatic differentiation and neural networks",
    "section": "1.2 Gradient descent",
    "text": "1.2 Gradient descent\nLeaving these questions aside, the basic idea underlying training is an extremely simple algorithm called gradient descent. If our network \\(\\mathsf{NN}_\\theta\\) is designed appropriately, our cost function Equation 1 is a differentiable function of the parameters \\(\\theta\\). The minimum cost that we seek therefore corresponds to a stationary point where \\(\\nabla_\\theta \\mathcal{C}(\\theta)|_{\\theta_*}=0\\). The idea of gradient descent is to take steps “downhill” i.e. in the direction \\(-\\mathcal{C}(\\theta)\\) in the high dimensional space of all the parameters, where each step corresponds to an update of the parameters according to\n\\[\n\\theta_i\\longrightarrow \\theta'_i = \\theta_i - \\eta \\frac{\\partial\\mathcal{C}}{\\partial \\theta_i}\n\\tag{2}\\]\nwhere \\(\\eta\\) is a hyperparameter2 called the learning rate. Choosing the learning rate is an important part of the craft of training models: too large and the first order approximation underlying Equation 2 breaks down and the cost may end up increasing; too small and the network will take too long to train. Often a learning rate schedule is used where the rate is adjusted during training to optimize convergence. You might guess that starting off with a large learning rate and then reducing it is the right way to go, and this is correct, but people do all sort of exotic things.\nYou might find it surprising that such a simple approach plays such an important role in machine learning. All of the sophistication lies in how the model is defined (Section 1.3) and how the gradients are calculated (Section 2): for a complicated function with many parameters 3 this is a highly nontrivial task. While there are plenty of more sophisticated optimization methods they often involve more information about the model’s dependence on its parameters, and this is more costly to evaluate. For example Newton’s method — which you may have encountered before — requires knowledge of first and second derivatives at each step, and this is normally less practical.\nAnother issue that relates to scale concerns the definition of our cost function Equation 1 as an average over the dataset. For large datasets consisting of high dimensional data (e.g. images) it is usually not practical to calculate the gradient of the cost using the entire dataset. The usual procedure is then to split the data up into batches (usually called minibatches, confusingly), and perform each step of gradient descent by evaluating the gradient only on the batch, moving on to a new batch at the next step. Eventually this will lead to all the data in the dataset being used, which is usually known as one epoch of training. Training a model can involve many epochs (passes through the dataset).\nBecause each step only uses part of the data, the gradients calculated are going to be more “noisy” than the “true” gradients involving the whole dataset. Because of this, training by gradient descent with minibatches is known as stochastic gradient descent. It is generally thought that the noise introduced by minibatching plays a role in improving the generalization performance of neural networks.",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#sec-nn",
    "href": "notes/autodiff.html#sec-nn",
    "title": "Automatic differentiation and neural networks",
    "section": "1.3 The network",
    "text": "1.3 The network\nSo far we have said nothing at all about \\(\\mathsf{NN}_\\theta\\) except that it is a function \\(\\mathsf{NN}_\\theta:\\mathbb{R}^{N_D}\\longrightarrow \\mathbb{R}^{N_L}\\) from the space of data to the space of labels, and it has lots of parameters. What is this function, and why is it called a “neural network”? In this section we’ll define \\(\\mathsf{NN}_\\theta\\) and say something about the origins of the idea in neuroscience.\nLeaving biology aside for the moment, we know that \\(\\mathsf{NN}_\\theta\\) must be complicated. We want it to take high dimensional inputs and somehow interpret them, outputting a label which synthesizes lots of high-level features in the data (e.g. in images the network must detect edges, shapes, and their relation). How can we make a complicated function?\nThe answer is that we do it by composing lots of simpler functions\n\\[\n\\mathsf{NN}_\\theta = f_\\theta^{(L)} \\circ f_\\theta^{(L-1)} \\cdots \\circ f_\\theta^{(2)} \\circ f_\\theta^{(1)}\n\\tag{3}\\]\nThe function \\(f^{(1)}\\) is a map \\(f^{(1)}:\\mathbb{R}^{N_D}\\longrightarrow \\mathbb{R}^{h_{1}}\\), where \\(h_1\\) is usually called the width of the first hidden layer (we’ll shortly draw a picture to show where this terminology comes from). \\(f^{(j)}\\) are maps \\(f^{(j)}:\\mathbb{R}^{h_{j-1}}\\longrightarrow \\mathbb{R}^{h_{j}}\\) for \\(j=2, \\ldots L-1\\), and finally the output layer is \\(f^{(L)}:\\mathbb{R}^{h_{L-1}}\\longrightarrow \\mathbb{R}^{N_L}\\). The dimensions \\(h_j\\) are hyperparameters of the model.\nWe now have to define the intermediate functions \\(f^{(j)}\\). Although we have said they should be simple, we still want to allow the possibility that each of the output components depends on all of the input components. The usual recipe is\n\\[\n\\left[f(\\mathbf{x})\\right]_\\alpha = \\phi\\left(\\sum_{\\beta=1}^{N_\\text{in}} w_{\\alpha\\beta}x_\\beta + b_\\alpha\\right),\\qquad \\alpha = 1,\\ldots N_\\text{out}\n\\tag{4}\\]\nHere the matrix \\(w\\in \\mathbb{R}^{N_\\text{out}\\times N_\\text{in}}\\) contains the weights and the vector \\(\\mathbf{b}\\in\\mathbb{R}^{N_\\text{out}}\\) contains the biases. These are the parameters of (this layer of) the network and will be modified during training. The function \\(\\phi:\\mathbb{R}\\longrightarrow\\mathbb{R}\\) is called the activation function. There are several popular choices, including the sigmoid\n\\[\n\\sigma(x) = \\frac{1}{1+e^{-x}},\n\\]\nprobably more familiar to you as the Fermi-Dirac distribution, and the ReLU function \\(\\max(0,x)\\) 4.\nEquation 4 is sometimes written more compactly as\n\\[\nf(\\mathbf{x}) = \\phi(w\\cdot\\mathbf{x} + \\mathbf{b}).\n\\]\nYou should understand this expression in the sense of vectorized functions (like NumPy’s ufuncs): \\(\\phi()\\) is applied to each element of \\(w\\cdot\\mathbf{x} + \\mathbf{b}\\).\nActivation functions should be differentiable but nonlinear. A linear function would mean that the function compositions in Equation 3 collapse into matrix multiplications, producing a single overall weight matrix and bias vector. There wouldn’t be any point having separate functions: one would do the same job.\nThe result of composing functions like this many times, each with their own set of weights and biases, is a highly complex function. The term deep learning, which you will often here these days in the context of neural networks, refers to models with many function applications, or layers, which is the source of the networks’ expressiveness.\n\n\n\nA two dimensional section through the cost function (“loss landscape”) of a neural network from Li et al. (2018).\n\n\nThe network that we have described so far is called fully connected, because in Equation 4 the matrix of weights means that every input dimension is coupled to every output dimension. Most of the innovation in neural networks over the past decade has been in creating and refining architectures that exploit the structure of the data in some way. For example, in a network to be used for computer vision (image recognition), it makes sense that the model “knows” that two input pixels are near or far from each other. This means that the input dimensions corresponding to two nearby pixels should be treated differently at the outset (i.e. before training) than two separated pixels. Also, the way the network responds to an image should not be strongly dependent on translations of that image. This implies that the weight matrices \\(w\\) should have some structure to them. In the case of vision this lead to the convolutional neural network, where the \\(w\\)’s act like convolutions, exploiting translational invariance but still retaining many parameters. We won’t go any further into these different architectures in this lecture.\n\n1.3.1 Why neural?\nYou may still be wondering where the network is, let alone the neurons. I’ve decide to present the neural network model in an ahistorical way, but if you look at other presentations you will tend to see the function Equation 4 represented graphically as\n\n\n\n\n\n\nFigure 1: A single artifical neuron. From Nielsen (2015).\n\n\n\nwhich reflects the dependence of the output on the inputs (and not much else). The result of composing several such functions then looks like this:\n\n\n\nAn artifical neural network. From Nielsen (2015).\n\n\nThis is the network we have been talking about all along! Specifically, it is a network called a directed acylic graph (DAG), meaning that the connections have a direction to them (input to output) and there are no loops.\nNeural networks have long been used as a model for what goes on in the brain, with Figure 1 playing the role of the neuron. There are many differences, however, including the absence of any particular role for time5, and the fact that (real) neural networks are not DAGs! This latter property plays a decisive role in the training of artificial neural networks, as we’ll see in the next section. In general, I feel that neural networks have outgrown their biological inspiration, which is the reason I’ve downplayed it here.",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#evaluating-the-derivatives",
    "href": "notes/autodiff.html#evaluating-the-derivatives",
    "title": "Automatic differentiation and neural networks",
    "section": "2.1 Evaluating the derivatives",
    "text": "2.1 Evaluating the derivatives\nLet’s just plow on and evaluate \\(\\partial\\mathcal{C}/\\partial \\theta_i\\). Remember that the parameters are the set of weights and biases in each layer:\n\\[\n\\theta = (w^{(1)}, \\mathbf{b}^{(1)},\\ldots, w^{(L)}, \\mathbf{b}^{(L)}).\n\\]\nThe function \\(\\mathsf{NN}_\\theta\\) can therefore more precisely be written as\n\\[\n\\mathsf{NN}_\\theta = f_{w^{(L)}, \\mathbf{b}^{(L)}}^{(L)} \\circ f_{w^{(L-1)}, \\mathbf{b}^{(L-1)}}^{(L-1)} \\cdots \\circ f_{w^{(2)}, \\mathbf{b}^{(2)}}^{(2)} \\circ f_{w^{(1)}, \\mathbf{b}^{(1)}}^{(1)}.\n\\tag{7}\\]\nEvaluating the derivative with respect to weights and biases in layer \\(l\\) is therefore going to involve applying the chain rule to Equation 7. In the following we’re going to denote the input to the \\(l\\)th layer as\n\\[\n\\mathbf{z}^{(l)} \\equiv w^{(l)} \\cdot \\mathbf{x}^{(l)} + \\mathbf{b}^{(l)}\n\\]\nand the output as \\(\\mathbf{a}^{(l)}\\) (“a” for activation). Thus the layer is written in vectorized form as\n\\[\n\\mathbf{a}^{(l)} = \\phi(\\mathbf{z}^{(l)}).\n\\]\nLet’s evaluate the derivative of \\(\\mathsf{NN}_\\theta(\\mathbf{x})\\) with some fixed input with respect to the biases \\(\\mathbf{b}^{(l)}\\) in the \\(l\\)th layer. One thing to note in passing is that the cost functions we consider are simple sums (averages) over different data \\(\\mathbf{x}_i\\), so the derivatives are too.\nA straightforward application of the chain rule gives\n\\[\n\\frac{\\partial \\mathsf{NN}_\\theta(\\mathbf{x})}{\\partial \\mathbf{b}^{(l)}} = \\frac{\\partial f^{(L)}}{\\partial \\mathbf{x}^{(L)}}\\cdot \\frac{\\partial f^{(L-1)}}{\\partial \\mathbf{x}^{(L-1)}} \\cdots  \\frac{\\partial f^{(l)}}{\\partial \\mathbf{z}^{(l)}}\n\\tag{8}\\]\nbecause \\(d\\mathbf{z}^{(l)}=d\\mathbf{b}^{(l)}\\). In this expression\n\\[\n\\frac{\\partial f_j^{(l')}}{\\partial x_k^{(l')}} = \\phi'(z^{(l')}_j)w^{(l')}_{jk} \\qquad l'=l+1,\\ldots L\n\\tag{9}\\]\nis the Jacobian matrix of each layer and the final factor is\n\\[\n\\frac{\\partial f_j^{(l)}}{\\partial z_k^{(l)}} =  \\phi'(z^{(l)}_j)\\delta_{jk}.\n\\]\nWe find a similar expression for the derivative with respect to the weights in the \\(l\\)th layer. These expressions all involve the deriviative of the activation function. When AD is implemented in code, the definition of any function is always supplemented with the derivative of that function.\nIn Equation 8 the matrices are composed by matrix multiplication. How should they be evaluated? There are two possibilities:",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#forward-accumulation",
    "href": "notes/autodiff.html#forward-accumulation",
    "title": "Automatic differentiation and neural networks",
    "section": "2.2 Forward accumulation",
    "text": "2.2 Forward accumulation\nWe go from right to left. Starting from the input \\(\\mathbf{x}\\), we evaluate \\(\\mathbf{z}^{(l)}\\) by evaluating the first \\(l-1\\) functions, passing the output from each to the input of the next. Once we reach \\(f^{(l)}\\), we have to start keeping track of a matrix as well as the values \\(\\mathbf{z}^{(l')}\\). This matrix is initialized with components \\(\\phi'(\\mathbf{z}^{(l)})\\delta_{jk}\\). It is then acted on by each of the Jacobians in Equation 9 until we get to the final layer. This procedure is called forward accumulation.\nThe advantage of forward accumulation is that during evaluation we only have to store the current \\(\\mathbf{z}^{(l')}\\) and the corresponding matrix. The disadvantage is that we are dealing with matrix multiplication. For matrices \\(M_1\\in \\mathbb{R}^{N_1\\times N_2}\\) and \\(M_2\\in \\mathbb{R}^{N_2\\times N_3}\\) matrix multiplication \\(M_1\\cdot M_2\\) is \\(O(N_1 N_2 N_3)\\). Since we are interested in models with large numbers of parameters in each layer, this is a problem.",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#backpropagation",
    "href": "notes/autodiff.html#backpropagation",
    "title": "Automatic differentiation and neural networks",
    "section": "2.3 Backpropagation",
    "text": "2.3 Backpropagation\nThe alternative is that we go from left to right. Instantly we see a problem: we have to have evaluate and store all the \\(\\mathbf{z}^{(l')}\\) with \\(l'=1,\\ldots L\\) before we can do anything, as the Jacobians depend on these values. This is called the forward pass.\nNow remember that we’re actually interested in calculating \\(\\partial\\mathcal{C}/\\partial w^{(l)_k}\\). For a single data point our cost function is\n\\[\nC_i(\\theta) \\equiv \\frac{1}{2}\\lVert\\mathbf{y}_i-\\mathsf{NN}_\\theta(\\mathbf{x}_i)\\rVert^2,\n\\tag{10}\\]\nand so\n\\[\n\\frac{\\partial C_i}{\\partial b^{(l)}_k} = -\\left(\\mathbf{y_i} - \\mathsf{NN}_\\theta(\\mathbf{x}_i)\\right) \\cdot \\frac{\\partial \\mathsf{NN}_\\theta(\\mathbf{x_i})}{\\partial b^{(l)}_k}.\n\\]\nThis means that going from left to right involves only matrix-vector multiplications rather than matrix-matrix mutiplications. We start with the (row) vector \\(\\left(\\mathbf{y_i} - \\mathsf{NN}_\\theta(\\mathbf{x}_i)\\right)^T\\) and act on the right with the Jacobians. This reduces the complexity of the evaluation by a factor equal to the number of biases in the \\(l\\)th layer.\nIn AD this is known as backward accumulation. For the special case of neural networks it’s usually called backpropagation. Going backwards reduces the time complexity in favour additional space (i.e. memory) complexity, as we have to store \\(\\mathbf{z}^{l'}\\) for each layer. This trade-off is usually worth it, and essentially all large neural networks these days are trained using backpropagation.",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/autodiff.html#footnotes",
    "href": "notes/autodiff.html#footnotes",
    "title": "Automatic differentiation and neural networks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a slight exaggeration, but what people often do these days is augment symbolic approaches with neural approaches.↩︎\nThe term parameter is normally reserved for the \\(\\theta\\)’s that appear in the definition of the model. Numbers like the learning rate that describe how the model is trained are usually referred to as hyperparameters.↩︎\nGPT-3, the model from OpenAI underlying ChatGPT, has 175 billion parameters!↩︎\nNote that you don’t have to use the same activation function throughout. Typically the output layer of a network used for classification uses the softmax function to output probabilities over the labels.↩︎\nSpiking neural networks are a model in which time plays a more serious role.↩︎",
    "crumbs": [
      "Notes",
      "Automatic differentiation and neural networks"
    ]
  },
  {
    "objectID": "notes/linear.html",
    "href": "notes/linear.html",
    "title": "Linear algebra",
    "section": "",
    "text": "Numerical linear algebra is a huge topic. Here we’ll confine ourselves to how common operations are performed in NumPy and SciPy, and some applications in physics and elsewhere.",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/linear.html#pagerank",
    "href": "notes/linear.html#pagerank",
    "title": "Linear algebra",
    "section": "2.1 PageRank",
    "text": "2.1 PageRank\nOne interesting application of these ideas is Google’s PageRank algorithm (Page et al. (1999)) to assess the relative importance of webpages based on structure of links between them1.\n\n\n\nLarry Page is happy he learnt about Markov chains\n\n\nPageRank imagines a web crawler that probabilistically navigates between pages according to a transition matrix \\(\\mathsf{P}\\). The stationary distribution \\(\\boldsymbol{\\pi}\\) satisfying \\[\n\\mathsf{P}\\boldsymbol{\\pi} = \\boldsymbol{\\pi}\n\\]\ncan then be interpreted as giving a ranking, with page \\(j\\) more important than page \\(k\\) if \\(\\boldsymbol{\\pi}_j&gt;\\boldsymbol{\\pi}_k\\).\nA problem arises with this approach if the Markov chain is nonergodic, meaning that the state space breaks up into several independent components, leading to a nonunique stationary state. For example, if\n\\[\n\\begin{equation}\n\\mathsf{P}=\\begin{pmatrix}\n0 & 1 & 0 & 0 \\\\\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0\n\\end{pmatrix}\n\\end{equation}\n\\]\nthen the first two pages and the last two do not link to each other, so\n\\[\n\\boldsymbol{\\pi} = \\begin{pmatrix}\n\\pi_1 \\\\\n\\pi_1 \\\\\n\\pi_2 \\\\\n\\pi_2\n\\end{pmatrix}\n\\]\nis a stationary state for any \\(\\pi_{1,2}\\).\nThe way out of this problem is to modify the Markov chain slightly to restore ergodicity and give a unique stationary state. At each step the crawler either moves as before with probability \\(\\alpha\\) (followed by making a choice about which link to follow) or moves with probability \\(1-\\alpha\\) to a random webpage. In this way the transition matrix of the overall Markov chain becomes\n\\[\n\\alpha\\mathsf{P} + (1-\\alpha)\\mathbf{t} \\mathbf{e}^T\n\\]\nwhere \\(\\mathbf{e}^T= (1, 1, \\ldots 1)\\) and \\(\\mathbf{t}\\) is a “teleporting” vector (usually \\((1, 1, \\ldots 1)/N\\)) giving the probability of teleporting to each of the webpages. Since this matrix has positive (i.e. \\(&gt;0\\)) entries the Perron–Frobenius theorem is restored and there is a unique stationary state (and hence ranking).\nA further modification is required to teleport away from “dangling” webpages without any outgoing links).",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/linear.html#sparsity",
    "href": "notes/linear.html#sparsity",
    "title": "Linear algebra",
    "section": "2.2 Sparsity",
    "text": "2.2 Sparsity\nThe power method is the basis of more sophisticated algorithms such as Lanczos iteration: they are all based on the idea that matrix-vector products are to be preferred over matrix-matrix products, and provide only incomplete information about the eigenvalues and eigenvectors.\nFurther economies are possible when dealing with sparse matrices, meaning that most of the elements are zero (i.e. the density of non-zero elements goes to zero as the matrix size increases). Many matrices that we meet in physical applications (as well as in the above example of links between webpages) are sparse. For example, consider discretizing the Laplacian that appears in the Schrödinger equation:\n\\[\n\\left[-\\frac{\\hbar^2}{2m}\\frac{d^2}{dx^2} + V(x)\\right]\\psi(x) = E\\psi(x)\n\\]\n\\[\n\\frac{d^2}{dx^2} \\sim \\frac{1}{\\Delta x^2}\\begin{pmatrix}\n-2 &  1 & 0 & 0 & 0 & \\cdots & 1 \\\\\n1 &  -2 & 1 & 0 & 0 & \\cdots & 0 \\\\\n0 &  1 & -2 & 1 & 0 & \\cdots & 0 \\\\\n\\cdots &  \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots \\\\\n1 &  0 & 0 & \\cdots & 0 & 1 & -2\n\\end{pmatrix}.\n\\]\n(periodic boundary conditions) There’s no point iterating over a whole row to multiply this matrix into a vector representing the wavefunction if most of the elements are zero!\nThe basic idea behind sparse matrix algebra is that you should only need to store the non-zero values of a matrix (and their locations), and there are a variety of data structures to do so. Many of these are implemented in the scipy.sparse module, and allow matrix operations from scipy.sparse.linalg to be performed efficiently.\nThe alternative approach to building the sparse matrix explicitly is to pass the matrix operations in scipy.sparse.linalg a function which performs the matrix-vector multiplication. This is done by instantiating a LinearOperator with the function. We’ll see an example of this approach in Section 4.",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/linear.html#svd-in-quantum-mechanics",
    "href": "notes/linear.html#svd-in-quantum-mechanics",
    "title": "Linear algebra",
    "section": "3.1 SVD in quantum mechanics",
    "text": "3.1 SVD in quantum mechanics\nSVD arises naturally in the quantum mechanics of composite systems: those that can be regarded as formed of two subsystems. For a simple, finite dimensional example, suppose that our system consists of two spins \\(\\mathbf{S}_A\\) and \\(\\mathbf{S}_B\\). The Hilbert space of each spin has dimension \\(n_{A,B}\\equiv 2S_{A,B}+1\\), where \\(\\mathbf{S}_{A,B}\\cdot\\mathbf{S}_{A,B}=S_{A,B}(S_{A,B}+1)\\) (e.g. 2 for spin-1/2).\nA general state of our system lives in a \\(n_A\\times n_B\\) dimensional Hilbert space and can be written in terms of basis vectors \\(\\ket{a}_A\\) and \\(\\ket{b}_B\\) for the A and B subsystems2 as\n\\[\n\\ket{\\Psi_{AB}} = \\sum_{a=1}^{n_A}\\sum_{b=1}^{n_B} \\psi_{ab}\\ket{a}_A\\ket{b}_B.\n\\tag{1}\\]\nWe can regard the components \\(\\psi_{ab}\\) as a matrix and perform an SVD. As discussed above, this is equivalent to finding new orthonormal bases \\(\\ket{\\tilde n}_{A,B}\\) for the two spaces such that the action of \\(\\psi_{ab}\\) on a basis vector of one subsystem maps it to a basis vector of the other, together with a rescaling. In this basis, the state \\(\\ket{\\Psi_{AB}}\\) can be written\n\\[\n\\ket{\\Psi_{AB}} = \\sum_{n=1}^{\\min(n_A,n_B)} \\lambda_n\\ket{\\tilde n}_A\\ket{\\tilde n}_B.\n\\]\nNote there is a single sum, c.f. the double sum in Equation 1. This is called a Schmidt decomposition, although it is really just a restatement of the SVD.\nThe singular values — sometimes called the Schmidt coefficients in this case — quantify the entanglement of the state (see the 2022 Nobel prize). If there is only one nonzero singular value the state is a product state and there are no correlations between the two subsystems. Note that his might not have been evident in the original form Equation 1.\nAs a simple example consider the Bell state of two spin-1/2 subsystems. One example is\n\\[\n\\begin{equation}\n\\left|\\Psi^{+}\\right\\rangle=\\frac{1}{\\sqrt{2}}\\left(|0\\rangle_A \\otimes|1\\rangle_B+|1\\rangle_A \\otimes|0\\rangle_B\\right).\n\\end{equation}\n\\]\nThese are already written in Schmidt form and the two singular values are both \\(\\frac{1}{\\sqrt{2}}\\), indicating maximal entanglement.",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/linear.html#other-applications-of-svd",
    "href": "notes/linear.html#other-applications-of-svd",
    "title": "Linear algebra",
    "section": "3.2 Other applications of SVD",
    "text": "3.2 Other applications of SVD\nYou might find it interesting to read about the applications of SVD in recommender systems, as described in this blog post by Simon Funk.",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/linear.html#example-ground-state-of-a-spin-chain",
    "href": "notes/linear.html#example-ground-state-of-a-spin-chain",
    "title": "Linear algebra",
    "section": "4.1 Example: ground state of a spin chain",
    "text": "4.1 Example: ground state of a spin chain\nSpin chains are among the simplest quantum mechanical many body models. The Hamiltonian couples the spins along the chain, with nearest neighbour couplings in the simplest case. The simplest such model is the Heisenberg chain for spin-1/2:\n\\[\nH = \\sum_{j=1}^N \\left[\\sigma^x_j \\sigma^x_{j+1} + \\sigma^y_j \\sigma^y_{j+1} + \\sigma^z_j \\sigma^z_{j+1} \\right],\n\\]\nwhere \\(\\sigma^{x,y,z}\\) are the usual Pauli matrices and the subscript \\(j\\) means that the matrix acts only the \\(j\\)th index of the wavefunction. Usually we impose periodic boundary conditions, so that \\(\\sigma^a_{j+N}=\\sigma^a_j\\). In the tensor diagram notation we have\n\n\n\nState and Hamiltonian of a spin chain. Source: Glen Evenbly\n\n\nThe number of components of the wavefunction \\(\\psi_{a_1,\\ldots a_N}\\) is \\(2^N\\), which is responsible for the exponential growth of the complexity with increasing \\(N\\). Treating the eigenvalue problem\n\\[\nH\\ket{\\Psi} = E\\ket{\\Psi}\n\\]\nin terms of matrix-vector multiplication with complexity \\(O(2^{2N})\\) would be a very bad idea. Instead, we should take advantage of the structure of the problem, using the sparse structure of the Hamiltonian. \\(H\\) consists of a sum of local terms, each acting on only a neighbouring pair of sites. We are going to define a function that acts on the wavefunction with each of the local Hamiltonians \\(h_{j,j+1}\\) (this implementation uses np.tensordot rather than np.einsum):\n\n# by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 6/2019\n\ndef doApplyHam(psiIn: np.ndarray,\n               hloc: np.ndarray,\n               N: int,\n               usePBC: bool):\n  \"\"\"\n  Applies local Hamiltonian, given as sum of nearest neighbor terms, to\n  an input quantum state.\n  Args:\n    psiIn: vector of length d**N describing the quantum state.\n    hloc: array of ndim=4 describing the nearest neighbor coupling.\n    N: the number of lattice sites.\n    usePBC: sets whether to include periodic boundary term.\n  Returns:\n    np.ndarray: state psi after application of the Hamiltonian.\n  \"\"\"\n  d = hloc.shape[0]\n  psiOut = np.zeros(psiIn.size)\n  for k in range(N - 1):\n    # apply local Hamiltonian terms to sites [k,k+1]\n    psiOut += np.tensordot(hloc.reshape(d**2, d**2),\n                           psiIn.reshape(d**k, d**2, d**(N - 2 - k)),\n                           axes=[[1], [1]]).transpose(1, 0, 2).reshape(d**N)\n\n  if usePBC:\n    # apply periodic term\n    psiOut += np.tensordot(hloc.reshape(d, d, d, d),\n                           psiIn.reshape(d, d**(N - 2), d),\n                           axes=[[2, 3], [2, 0]]\n                           ).transpose(1, 2, 0).reshape(d**N)\n\n  return psiOut\n\nThe complexity of this step is \\(O(N 2^N)\\). The \\(2^N\\) arises from the tensor contractions over the indices of a pair of sites for each assignment of the remaining \\(N-2\\) indices (\\(2^{N-2}\\) assignments). This is still exponential, but exponentially better than \\(O(4^N)\\)!\nWe then use this to instantiate a LinearOperator which is passed into our eigenvalue solver (scipy.sparse.linalg.eigsh)\n\n\"\"\"\nby Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 06/2020\n\"\"\"\n\nfrom scipy.sparse.linalg import LinearOperator, eigsh\nfrom timeit import default_timer as timer\n\n# Simulation parameters\nmodel = 'XX'  # select 'XX' model of 'ising' model\nNsites = 18  # number of lattice sites\nusePBC = True  # use periodic or open boundaries\nnumval = 1  # number of eigenstates to compute\n\n# Define Hamiltonian (quantum XX model)\nd = 2  # local dimension\nsX = np.array([[0, 1.0], [1.0, 0]])\nsY = np.array([[0, -1.0j], [1.0j, 0]])\nsZ = np.array([[1.0, 0], [0, -1.0]])\nsI = np.array([[1.0, 0], [0, 1.0]])\nif model == 'XX':\n  hloc = (np.real(np.kron(sX, sX) + np.kron(sY, sY))).reshape(2, 2, 2, 2)\n  EnExact = -4 / np.sin(np.pi / Nsites)  # Note: only for PBC\nelif model == 'ising':\n  hloc = (-np.kron(sX, sX) + 0.5 * np.kron(sZ, sI) + 0.5 * np.kron(sI, sZ)\n          ).reshape(2, 2, 2, 2)\n  EnExact = -2 / np.sin(np.pi / (2 * Nsites))  # Note: only for PBC\n\n\n# cast the Hamiltonian 'H' as a linear operator\ndef doApplyHamClosed(psiIn):\n  return doApplyHam(psiIn, hloc, Nsites, usePBC)\n\n\nH = LinearOperator((2**Nsites, 2**Nsites), matvec=doApplyHamClosed)\n\n# do the exact diag\nstart_time = timer()\nEnergy, psi = eigsh(H, k=numval, which='SA')\ndiag_time = timer() - start_time\n\n# check with exact energy\nEnErr = Energy[0] - EnExact  # should equal to zero\n\nprint('NumSites: %d, Time: %1.2f, Energy: %e, EnErr: %e' %\n      (Nsites, diag_time, Energy[0], EnErr))\n\nNumSites: 18, Time: 2.95, Energy: -2.303508e+01, EnErr: 0.000000e+00\n\n\nThe two models tested here are in fact the XX and Quantum Ising models — which have a slightly different form — because there is a simple expression for the exact ground state energy.\nI encourage you to check out Glen Evenbly’s site is you’d like to learn more about these methods.",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/linear.html#footnotes",
    "href": "notes/linear.html#footnotes",
    "title": "Linear algebra",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA similar algorithm apparently suggests who to follow on Twitter (Gupta et al. (2013)). As the web became increasingly dynamic the original PageRank algorithm presumably faded in relevance, though according to this blog post some version of it survives at Google.↩︎\nFor example, the usual eigenvectors of \\(S_{A,B}^z\\) in the case of spins.↩︎\nI have to point out that the word “rank” is used for two totally different things: the rank of a matrix (discussed in Section 3) and the rank of a tensor (number of indices, or length of the shape tuple) as used when discussing the shape of NumPy arrays in the NumPy lecture, or when you learnt about tensors (so a matrix has tensor rank 2: perhaps it’s easier to stick with “second rank tensor”). To make matters worse, there is something else called tensor rank which generalizes the idea of the matrix rank to tensors. Sorry.↩︎",
    "crumbs": [
      "Notes",
      "Linear algebra"
    ]
  },
  {
    "objectID": "notes/ode.html",
    "href": "notes/ode.html",
    "title": "Solving differential equations with SciPy",
    "section": "",
    "text": "Newton’s fundamental discovery, the one which he considered necessary to keep secret and published only in the form of an anagram, consists of the following: Data aequatione quotcunque fluentes quantitates involvente, fluxiones invenire; et vice versa. In contemporary mathematical language, this means: “It is useful to solve differential equations”.\nVladimir Arnold, Geometrical Methods in the Theory of Ordinary Differential Equations\nWhile Arnold (and Newton) are of course right the problem is that solving differential equations is not possible in general. Even the simplest example of a first order ordinary differential equation (ODE) in a single variable\n\\[\n\\frac{dx}{dt} = f(x, t)\n\\tag{1}\\]\ncannot be solved for general \\(f(x,t)\\) 1. Of course, formulating a physical (or whatever) system in terms of differential equations represents a nontrivial step on the road to understanding it, but a lot remains to be done.\nNumerical analysis of differential equations is a colossal topic in applied mathematics and we are barely going to scratch the surface. The important thing is to be able to access existing solvers (and implement your own if necessary) and crucially to understand their limitations.",
    "crumbs": [
      "Notes",
      "Solving differential equations with SciPy"
    ]
  },
  {
    "objectID": "notes/ode.html#truncation-error",
    "href": "notes/ode.html#truncation-error",
    "title": "Solving differential equations with SciPy",
    "section": "1.1 Truncation error",
    "text": "1.1 Truncation error\nIn making the approximation Equation 2 we make an \\(O(h^2)\\) local truncation error. To integrate for a fixed time the number of steps required is proportional to \\(h^{-1}\\), which means that the worst case error at fixed time (the global truncation error) is \\(O(h)\\). For this reason Euler’s method is called first order. More sophisticated methods are typically higher order: the SciPy function scipy.integrate.solve_ivp uses a fifth order method by default.\nThe midpoint method is a simple example of a higher order integration scheme\n\\[\n\\begin{align}\nk_1 &\\equiv h f(x_j,t_j) \\\\\nk_2 &\\equiv h f(x_i + k_1/2, t_j + h/2) \\\\\nx_{j+1} &= x_j + k_2 +O(h^3)\n\\end{align}\n\\]\nThe \\(O(h^2)\\) error cancels! The downside is that we have two function evaluations to perform per step, but this is often worthwhile.",
    "crumbs": [
      "Notes",
      "Solving differential equations with SciPy"
    ]
  },
  {
    "objectID": "notes/ode.html#rounding-error",
    "href": "notes/ode.html#rounding-error",
    "title": "Solving differential equations with SciPy",
    "section": "1.2 Rounding error",
    "text": "1.2 Rounding error\nIf you had unlimited computer time you might think you could make the step size \\(h\\) ever smaller in order to make the updates more accurate. This ignores the machine precision \\(\\epsilon\\). The rounding error is roughly \\(\\epsilon x_j\\), and if the \\(N\\propto h^{-1}\\) errors in successive steps can be treated as independent random variables, the relative total rounding error will be \\(\\propto \\sqrt{N}\\epsilon=\\frac{\\epsilon}{\\sqrt{h}}\\) and will dominate for \\(h\\) small.",
    "crumbs": [
      "Notes",
      "Solving differential equations with SciPy"
    ]
  },
  {
    "objectID": "notes/ode.html#stability",
    "href": "notes/ode.html#stability",
    "title": "Solving differential equations with SciPy",
    "section": "1.3 Stability",
    "text": "1.3 Stability\nApart from the relatively low accuracy that comes from using a first order method, the Euler method may additionally be unstable, depending on the equation. This can be demonstrated for the linear equation\n\\[\n\\frac{dx}{dt} = kx\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef euler(h, t_max, k=1):\n    \"\"\"\n    Solve the equation x' = k x, with x(0) = 1 using\n    the Euler method. \n\n    Integrate from t=0 to t=t_max using stepsize h for\n    num_steps = t_max / h.\n    \n    Returns two arrays of length num_steps: t, the time coordinate, and x_0, the position.\n    \"\"\"\n    num_steps = int(t_max / h)\n    # Allocate return arrays\n    x = np.zeros(num_steps, dtype=np.float32)\n    t = np.zeros(num_steps, dtype=np.float32)\n    x[0] = 1.0  # Initial condition\n    for i in range(num_steps - 1):\n        x[i+1] = x[i] + k * x[i] * h\n        t[i+1] = t[i] + h  # Time step\n    return t, x\n\nk = -2.3\nt_max = 5\nt, x = euler(1, t_max, k)\nplt.plot(t, x, label=\"h=1 Euler\")\nt, x = euler(0.7, t_max, k)\nplt.plot(t, x, label=\"h=0.7 Euler\")\nt = np.linspace(0, t_max, 100)\nplt.plot(t, np.exp(k * t), label=\"exact solution\")\nplt.title(\"k=-2.3\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFor a linear equation the Euler update Equation 3 is a simple rescaling\n\\[\nx_{j+1} = x_j(1 + hk)\n\\]\nso the region of stability is \\(|1 + hk|\\leq 1\\). You can check that the backward Euler method Equation 4 eliminates the instability for \\(k&lt;0\\).",
    "crumbs": [
      "Notes",
      "Solving differential equations with SciPy"
    ]
  },
  {
    "objectID": "notes/ode.html#footnotes",
    "href": "notes/ode.html#footnotes",
    "title": "Solving differential equations with SciPy",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe’ll refer to \\(t\\) as the time in the following, as this is the most common setting in physics.↩︎\nAs featured in Hidden Figures.↩︎",
    "crumbs": [
      "Notes",
      "Solving differential equations with SciPy"
    ]
  }
]